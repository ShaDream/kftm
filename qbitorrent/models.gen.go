// Package qbitorrent provides primitives to interact with the openapi HTTP API.
//
// Code generated by github.com/oapi-codegen/oapi-codegen/v2 version v2.4.1 DO NOT EDIT.
package qbitorrent

import (
	"encoding/json"
	"fmt"

	"github.com/oapi-codegen/runtime"
	openapi_types "github.com/oapi-codegen/runtime/types"
)

const (
	SidScopes = "sid.Scopes"
)

// Defines values for AddTorrentsCommonFirstLastPiecePrio.
const (
	AddTorrentsCommonFirstLastPiecePrioFalse AddTorrentsCommonFirstLastPiecePrio = "false"
	AddTorrentsCommonFirstLastPiecePrioTrue  AddTorrentsCommonFirstLastPiecePrio = "true"
)

// Defines values for AddTorrentsCommonPaused.
const (
	AddTorrentsCommonPausedFalse AddTorrentsCommonPaused = "false"
	AddTorrentsCommonPausedTrue  AddTorrentsCommonPaused = "true"
)

// Defines values for AddTorrentsCommonRootFolder.
const (
	AddTorrentsCommonRootFolderFalse AddTorrentsCommonRootFolder = "false"
	AddTorrentsCommonRootFolderTrue  AddTorrentsCommonRootFolder = "true"
	AddTorrentsCommonRootFolderUnset AddTorrentsCommonRootFolder = "unset"
)

// Defines values for AddTorrentsCommonSequentialDownload.
const (
	AddTorrentsCommonSequentialDownloadFalse AddTorrentsCommonSequentialDownload = "false"
	AddTorrentsCommonSequentialDownloadTrue  AddTorrentsCommonSequentialDownload = "true"
)

// Defines values for AddTorrentsCommonSkipChecking.
const (
	AddTorrentsCommonSkipCheckingFalse AddTorrentsCommonSkipChecking = "false"
	AddTorrentsCommonSkipCheckingTrue  AddTorrentsCommonSkipChecking = "true"
)

// Defines values for AddTorrentsFilesFirstLastPiecePrio.
const (
	AddTorrentsFilesFirstLastPiecePrioFalse AddTorrentsFilesFirstLastPiecePrio = "false"
	AddTorrentsFilesFirstLastPiecePrioTrue  AddTorrentsFilesFirstLastPiecePrio = "true"
)

// Defines values for AddTorrentsFilesPaused.
const (
	AddTorrentsFilesPausedFalse AddTorrentsFilesPaused = "false"
	AddTorrentsFilesPausedTrue  AddTorrentsFilesPaused = "true"
)

// Defines values for AddTorrentsFilesRootFolder.
const (
	AddTorrentsFilesRootFolderFalse AddTorrentsFilesRootFolder = "false"
	AddTorrentsFilesRootFolderTrue  AddTorrentsFilesRootFolder = "true"
	AddTorrentsFilesRootFolderUnset AddTorrentsFilesRootFolder = "unset"
)

// Defines values for AddTorrentsFilesSequentialDownload.
const (
	AddTorrentsFilesSequentialDownloadFalse AddTorrentsFilesSequentialDownload = "false"
	AddTorrentsFilesSequentialDownloadTrue  AddTorrentsFilesSequentialDownload = "true"
)

// Defines values for AddTorrentsFilesSkipChecking.
const (
	AddTorrentsFilesSkipCheckingFalse AddTorrentsFilesSkipChecking = "false"
	AddTorrentsFilesSkipCheckingTrue  AddTorrentsFilesSkipChecking = "true"
)

// Defines values for AddTorrentsURLsFirstLastPiecePrio.
const (
	AddTorrentsURLsFirstLastPiecePrioFalse AddTorrentsURLsFirstLastPiecePrio = "false"
	AddTorrentsURLsFirstLastPiecePrioTrue  AddTorrentsURLsFirstLastPiecePrio = "true"
)

// Defines values for AddTorrentsURLsPaused.
const (
	AddTorrentsURLsPausedFalse AddTorrentsURLsPaused = "false"
	AddTorrentsURLsPausedTrue  AddTorrentsURLsPaused = "true"
)

// Defines values for AddTorrentsURLsRootFolder.
const (
	AddTorrentsURLsRootFolderFalse AddTorrentsURLsRootFolder = "false"
	AddTorrentsURLsRootFolderTrue  AddTorrentsURLsRootFolder = "true"
	AddTorrentsURLsRootFolderUnset AddTorrentsURLsRootFolder = "unset"
)

// Defines values for AddTorrentsURLsSequentialDownload.
const (
	AddTorrentsURLsSequentialDownloadFalse AddTorrentsURLsSequentialDownload = "false"
	AddTorrentsURLsSequentialDownloadTrue  AddTorrentsURLsSequentialDownload = "true"
)

// Defines values for AddTorrentsURLsSkipChecking.
const (
	False AddTorrentsURLsSkipChecking = "false"
	True  AddTorrentsURLsSkipChecking = "true"
)

// Defines values for MainLogType.
const (
	MainLogTypeN1 MainLogType = 1
	MainLogTypeN2 MainLogType = 2
	MainLogTypeN4 MainLogType = 4
	MainLogTypeN8 MainLogType = 8
)

// Defines values for PreferencesBittorrentProtocol.
const (
	PreferencesBittorrentProtocolN0 PreferencesBittorrentProtocol = 0
	PreferencesBittorrentProtocolN1 PreferencesBittorrentProtocol = 1
	PreferencesBittorrentProtocolN2 PreferencesBittorrentProtocol = 2
)

// Defines values for PreferencesDyndnsService.
const (
	PreferencesDyndnsServiceN0 PreferencesDyndnsService = 0
	PreferencesDyndnsServiceN1 PreferencesDyndnsService = 1
)

// Defines values for PreferencesEncryption.
const (
	PreferencesEncryptionN0 PreferencesEncryption = 0
	PreferencesEncryptionN1 PreferencesEncryption = 1
	PreferencesEncryptionN2 PreferencesEncryption = 2
)

// Defines values for PreferencesMaxRatioAct.
const (
	PreferencesMaxRatioActN0 PreferencesMaxRatioAct = 0
	PreferencesMaxRatioActN1 PreferencesMaxRatioAct = 1
)

// Defines values for PreferencesProxyType.
const (
	PreferencesProxyTypeMinus1 PreferencesProxyType = -1
	PreferencesProxyTypeN0     PreferencesProxyType = 0
	PreferencesProxyTypeN1     PreferencesProxyType = 1
	PreferencesProxyTypeN2     PreferencesProxyType = 2
	PreferencesProxyTypeN3     PreferencesProxyType = 3
	PreferencesProxyTypeN4     PreferencesProxyType = 4
	PreferencesProxyTypeN5     PreferencesProxyType = 5
)

// Defines values for PreferencesScanDirs0.
const (
	PreferencesScanDirs0N0 PreferencesScanDirs0 = 0
	PreferencesScanDirs0N1 PreferencesScanDirs0 = 1
)

// Defines values for PreferencesSchedulerDays.
const (
	PreferencesSchedulerDaysN0 PreferencesSchedulerDays = 0
	PreferencesSchedulerDaysN1 PreferencesSchedulerDays = 1
	PreferencesSchedulerDaysN2 PreferencesSchedulerDays = 2
	PreferencesSchedulerDaysN3 PreferencesSchedulerDays = 3
	PreferencesSchedulerDaysN4 PreferencesSchedulerDays = 4
	PreferencesSchedulerDaysN5 PreferencesSchedulerDays = 5
	PreferencesSchedulerDaysN6 PreferencesSchedulerDays = 6
	PreferencesSchedulerDaysN7 PreferencesSchedulerDays = 7
	PreferencesSchedulerDaysN8 PreferencesSchedulerDays = 8
	PreferencesSchedulerDaysN9 PreferencesSchedulerDays = 9
)

// Defines values for PreferencesUploadChokingAlgorithm.
const (
	PreferencesUploadChokingAlgorithmN0 PreferencesUploadChokingAlgorithm = 0
	PreferencesUploadChokingAlgorithmN1 PreferencesUploadChokingAlgorithm = 1
	PreferencesUploadChokingAlgorithmN2 PreferencesUploadChokingAlgorithm = 2
)

// Defines values for PreferencesUploadSlotsBehavior.
const (
	PreferencesUploadSlotsBehaviorN0 PreferencesUploadSlotsBehavior = 0
	PreferencesUploadSlotsBehaviorN1 PreferencesUploadSlotsBehavior = 1
)

// Defines values for PreferencesUtpTcpMixedMode.
const (
	PreferencesUtpTcpMixedModeN0 PreferencesUtpTcpMixedMode = 0
	PreferencesUtpTcpMixedModeN1 PreferencesUtpTcpMixedMode = 1
)

// Defines values for SearchJobStatusStatus.
const (
	SearchJobStatusStatusRunning SearchJobStatusStatus = "Running"
	SearchJobStatusStatusStopped SearchJobStatusStatus = "Stopped"
)

// Defines values for SearchResultsStatus.
const (
	SearchResultsStatusRunning SearchResultsStatus = "Running"
	SearchResultsStatusStopped SearchResultsStatus = "Stopped"
)

// Defines values for SetPreferencesBittorrentProtocol.
const (
	SetPreferencesBittorrentProtocolN0 SetPreferencesBittorrentProtocol = 0
	SetPreferencesBittorrentProtocolN1 SetPreferencesBittorrentProtocol = 1
	SetPreferencesBittorrentProtocolN2 SetPreferencesBittorrentProtocol = 2
)

// Defines values for SetPreferencesDyndnsService.
const (
	SetPreferencesDyndnsServiceN0 SetPreferencesDyndnsService = 0
	SetPreferencesDyndnsServiceN1 SetPreferencesDyndnsService = 1
)

// Defines values for SetPreferencesEncryption.
const (
	SetPreferencesEncryptionN0 SetPreferencesEncryption = 0
	SetPreferencesEncryptionN1 SetPreferencesEncryption = 1
	SetPreferencesEncryptionN2 SetPreferencesEncryption = 2
)

// Defines values for SetPreferencesMaxRatioAct.
const (
	SetPreferencesMaxRatioActN0 SetPreferencesMaxRatioAct = 0
	SetPreferencesMaxRatioActN1 SetPreferencesMaxRatioAct = 1
)

// Defines values for SetPreferencesProxyType.
const (
	SetPreferencesProxyTypeMinus1 SetPreferencesProxyType = -1
	SetPreferencesProxyTypeN0     SetPreferencesProxyType = 0
	SetPreferencesProxyTypeN1     SetPreferencesProxyType = 1
	SetPreferencesProxyTypeN2     SetPreferencesProxyType = 2
	SetPreferencesProxyTypeN3     SetPreferencesProxyType = 3
	SetPreferencesProxyTypeN4     SetPreferencesProxyType = 4
	SetPreferencesProxyTypeN5     SetPreferencesProxyType = 5
)

// Defines values for SetPreferencesScanDirs0.
const (
	SetPreferencesScanDirs0N0 SetPreferencesScanDirs0 = 0
	SetPreferencesScanDirs0N1 SetPreferencesScanDirs0 = 1
)

// Defines values for SetPreferencesSchedulerDays.
const (
	SetPreferencesSchedulerDaysN0 SetPreferencesSchedulerDays = 0
	SetPreferencesSchedulerDaysN1 SetPreferencesSchedulerDays = 1
	SetPreferencesSchedulerDaysN2 SetPreferencesSchedulerDays = 2
	SetPreferencesSchedulerDaysN3 SetPreferencesSchedulerDays = 3
	SetPreferencesSchedulerDaysN4 SetPreferencesSchedulerDays = 4
	SetPreferencesSchedulerDaysN5 SetPreferencesSchedulerDays = 5
	SetPreferencesSchedulerDaysN6 SetPreferencesSchedulerDays = 6
	SetPreferencesSchedulerDaysN7 SetPreferencesSchedulerDays = 7
	SetPreferencesSchedulerDaysN8 SetPreferencesSchedulerDays = 8
	SetPreferencesSchedulerDaysN9 SetPreferencesSchedulerDays = 9
)

// Defines values for SetPreferencesUploadChokingAlgorithm.
const (
	SetPreferencesUploadChokingAlgorithmN0 SetPreferencesUploadChokingAlgorithm = 0
	SetPreferencesUploadChokingAlgorithmN1 SetPreferencesUploadChokingAlgorithm = 1
	SetPreferencesUploadChokingAlgorithmN2 SetPreferencesUploadChokingAlgorithm = 2
)

// Defines values for SetPreferencesUploadSlotsBehavior.
const (
	SetPreferencesUploadSlotsBehaviorN0 SetPreferencesUploadSlotsBehavior = 0
	SetPreferencesUploadSlotsBehaviorN1 SetPreferencesUploadSlotsBehavior = 1
)

// Defines values for SetPreferencesUtpTcpMixedMode.
const (
	SetPreferencesUtpTcpMixedModeN0 SetPreferencesUtpTcpMixedMode = 0
	SetPreferencesUtpTcpMixedModeN1 SetPreferencesUtpTcpMixedMode = 1
)

// Defines values for TorrentInfoState.
const (
	TorrentInfoStateAllocating         TorrentInfoState = "allocating"
	TorrentInfoStateCheckingDL         TorrentInfoState = "checkingDL"
	TorrentInfoStateCheckingResumeData TorrentInfoState = "checkingResumeData"
	TorrentInfoStateCheckingUP         TorrentInfoState = "checkingUP"
	TorrentInfoStateDownloading        TorrentInfoState = "downloading"
	TorrentInfoStateError              TorrentInfoState = "error"
	TorrentInfoStateForcedDL           TorrentInfoState = "forcedDL"
	TorrentInfoStateForcedUP           TorrentInfoState = "forcedUP"
	TorrentInfoStateMetaDL             TorrentInfoState = "metaDL"
	TorrentInfoStateMissingFiles       TorrentInfoState = "missingFiles"
	TorrentInfoStateMoving             TorrentInfoState = "moving"
	TorrentInfoStatePausedDL           TorrentInfoState = "pausedDL"
	TorrentInfoStatePausedUP           TorrentInfoState = "pausedUP"
	TorrentInfoStateQueuedDL           TorrentInfoState = "queuedDL"
	TorrentInfoStateQueuedUP           TorrentInfoState = "queuedUP"
	TorrentInfoStateStalledDL          TorrentInfoState = "stalledDL"
	TorrentInfoStateStalledUP          TorrentInfoState = "stalledUP"
	TorrentInfoStateUnknown            TorrentInfoState = "unknown"
	TorrentInfoStateUploading          TorrentInfoState = "uploading"
)

// Defines values for TorrentsFilesPriority.
const (
	TorrentsFilesPriorityN0 TorrentsFilesPriority = 0
	TorrentsFilesPriorityN1 TorrentsFilesPriority = 1
	TorrentsFilesPriorityN6 TorrentsFilesPriority = 6
	TorrentsFilesPriorityN7 TorrentsFilesPriority = 7
)

// Defines values for TorrentsTrackersStatus.
const (
	TorrentsTrackersStatusN0 TorrentsTrackersStatus = 0
	TorrentsTrackersStatusN1 TorrentsTrackersStatus = 1
	TorrentsTrackersStatusN2 TorrentsTrackersStatus = 2
	TorrentsTrackersStatusN3 TorrentsTrackersStatus = 3
	TorrentsTrackersStatusN4 TorrentsTrackersStatus = 4
)

// Defines values for TorrentsFilePrioPostFormdataBodyPriority.
const (
	TorrentsFilePrioPostFormdataBodyPriorityN0 TorrentsFilePrioPostFormdataBodyPriority = 0
	TorrentsFilePrioPostFormdataBodyPriorityN1 TorrentsFilePrioPostFormdataBodyPriority = 1
	TorrentsFilePrioPostFormdataBodyPriorityN6 TorrentsFilePrioPostFormdataBodyPriority = 6
	TorrentsFilePrioPostFormdataBodyPriorityN7 TorrentsFilePrioPostFormdataBodyPriority = 7
)

// Defines values for TorrentsInfoPostFormdataBodyFilter.
const (
	TorrentsInfoPostFormdataBodyFilterActive             TorrentsInfoPostFormdataBodyFilter = "active"
	TorrentsInfoPostFormdataBodyFilterAll                TorrentsInfoPostFormdataBodyFilter = "all"
	TorrentsInfoPostFormdataBodyFilterCompleted          TorrentsInfoPostFormdataBodyFilter = "completed"
	TorrentsInfoPostFormdataBodyFilterDownloading        TorrentsInfoPostFormdataBodyFilter = "downloading"
	TorrentsInfoPostFormdataBodyFilterErrored            TorrentsInfoPostFormdataBodyFilter = "errored"
	TorrentsInfoPostFormdataBodyFilterInactive           TorrentsInfoPostFormdataBodyFilter = "inactive"
	TorrentsInfoPostFormdataBodyFilterPaused             TorrentsInfoPostFormdataBodyFilter = "paused"
	TorrentsInfoPostFormdataBodyFilterResumed            TorrentsInfoPostFormdataBodyFilter = "resumed"
	TorrentsInfoPostFormdataBodyFilterSeeding            TorrentsInfoPostFormdataBodyFilter = "seeding"
	TorrentsInfoPostFormdataBodyFilterStalled            TorrentsInfoPostFormdataBodyFilter = "stalled"
	TorrentsInfoPostFormdataBodyFilterStalledDownloading TorrentsInfoPostFormdataBodyFilter = "stalled_downloading"
	TorrentsInfoPostFormdataBodyFilterStalledUploading   TorrentsInfoPostFormdataBodyFilter = "stalled_uploading"
)

// AddTorrentsCommon defines model for AddTorrentsCommon.
type AddTorrentsCommon struct {
	// AutoTMM Whether Automatic Torrent Management should be used
	AutoTMM *bool `json:"autoTMM,omitempty"`

	// Category Category for the torrent
	Category *string `json:"category,omitempty"`

	// Cookie Cookie sent to download the .torrent file
	Cookie *string `json:"cookie,omitempty"`

	// DlLimit Set torrent download speed limit. Unit in bytes/second
	DlLimit *int64 `json:"dlLimit,omitempty"`

	// FirstLastPiecePrio Prioritize download first last piece. Possible values are `true`, `false` (default)
	FirstLastPiecePrio *AddTorrentsCommonFirstLastPiecePrio `json:"firstLastPiecePrio,omitempty"`

	// Paused Add torrents in the paused state. Possible values are `true`, `false` (default)
	Paused *AddTorrentsCommonPaused `json:"paused,omitempty"`

	// RatioLimit Set torrent share ratio limit
	RatioLimit *float32 `json:"ratioLimit,omitempty"`

	// Rename Rename torrent
	Rename *string `json:"rename,omitempty"`

	// RootFolder Create the root folder. Possible values are `true`, `false`, unset (default)
	RootFolder *AddTorrentsCommonRootFolder `json:"root_folder,omitempty"`

	// Savepath Download folder
	Savepath *string `json:"savepath,omitempty"`

	// SeedingTimeLimit Set torrent seeding time limit. Unit in seconds
	SeedingTimeLimit *int64 `json:"seedingTimeLimit,omitempty"`

	// SequentialDownload Enable sequential download. Possible values are `true`, `false` (default)
	SequentialDownload *AddTorrentsCommonSequentialDownload `json:"sequentialDownload,omitempty"`

	// SkipChecking Skip hash checking. Possible values are `true`, `false` (default)
	SkipChecking *AddTorrentsCommonSkipChecking `json:"skip_checking,omitempty"`

	// Tags Tags for the torrent, split by ','
	Tags *[]string `json:"tags,omitempty"`

	// UpLimit Set torrent upload speed limit. Unit in bytes/second
	UpLimit *int64 `json:"upLimit,omitempty"`
}

// AddTorrentsCommonFirstLastPiecePrio Prioritize download first last piece. Possible values are `true`, `false` (default)
type AddTorrentsCommonFirstLastPiecePrio string

// AddTorrentsCommonPaused Add torrents in the paused state. Possible values are `true`, `false` (default)
type AddTorrentsCommonPaused string

// AddTorrentsCommonRootFolder Create the root folder. Possible values are `true`, `false`, unset (default)
type AddTorrentsCommonRootFolder string

// AddTorrentsCommonSequentialDownload Enable sequential download. Possible values are `true`, `false` (default)
type AddTorrentsCommonSequentialDownload string

// AddTorrentsCommonSkipChecking Skip hash checking. Possible values are `true`, `false` (default)
type AddTorrentsCommonSkipChecking string

// AddTorrentsFiles defines model for AddTorrentsFiles.
type AddTorrentsFiles struct {
	// AutoTMM Whether Automatic Torrent Management should be used
	AutoTMM *bool `json:"autoTMM,omitempty"`

	// Category Category for the torrent
	Category *string `json:"category,omitempty"`

	// Cookie Cookie sent to download the .torrent file
	Cookie *string `json:"cookie,omitempty"`

	// DlLimit Set torrent download speed limit. Unit in bytes/second
	DlLimit *int64 `json:"dlLimit,omitempty"`

	// FirstLastPiecePrio Prioritize download first last piece. Possible values are `true`, `false` (default)
	FirstLastPiecePrio *AddTorrentsFilesFirstLastPiecePrio `json:"firstLastPiecePrio,omitempty"`

	// Paused Add torrents in the paused state. Possible values are `true`, `false` (default)
	Paused *AddTorrentsFilesPaused `json:"paused,omitempty"`

	// RatioLimit Set torrent share ratio limit
	RatioLimit *float32 `json:"ratioLimit,omitempty"`

	// Rename Rename torrent
	Rename *string `json:"rename,omitempty"`

	// RootFolder Create the root folder. Possible values are `true`, `false`, unset (default)
	RootFolder *AddTorrentsFilesRootFolder `json:"root_folder,omitempty"`

	// Savepath Download folder
	Savepath *string `json:"savepath,omitempty"`

	// SeedingTimeLimit Set torrent seeding time limit. Unit in seconds
	SeedingTimeLimit *int64 `json:"seedingTimeLimit,omitempty"`

	// SequentialDownload Enable sequential download. Possible values are `true`, `false` (default)
	SequentialDownload *AddTorrentsFilesSequentialDownload `json:"sequentialDownload,omitempty"`

	// SkipChecking Skip hash checking. Possible values are `true`, `false` (default)
	SkipChecking *AddTorrentsFilesSkipChecking `json:"skip_checking,omitempty"`

	// Tags Tags for the torrent, split by ','
	Tags *[]string `json:"tags,omitempty"`

	// Torrents Raw data of torrent file. `torrents` can be presented multiple times.
	Torrents *[]openapi_types.File `json:"torrents,omitempty"`

	// UpLimit Set torrent upload speed limit. Unit in bytes/second
	UpLimit *int64 `json:"upLimit,omitempty"`
}

// AddTorrentsFilesFirstLastPiecePrio Prioritize download first last piece. Possible values are `true`, `false` (default)
type AddTorrentsFilesFirstLastPiecePrio string

// AddTorrentsFilesPaused Add torrents in the paused state. Possible values are `true`, `false` (default)
type AddTorrentsFilesPaused string

// AddTorrentsFilesRootFolder Create the root folder. Possible values are `true`, `false`, unset (default)
type AddTorrentsFilesRootFolder string

// AddTorrentsFilesSequentialDownload Enable sequential download. Possible values are `true`, `false` (default)
type AddTorrentsFilesSequentialDownload string

// AddTorrentsFilesSkipChecking Skip hash checking. Possible values are `true`, `false` (default)
type AddTorrentsFilesSkipChecking string

// AddTorrentsURLs defines model for AddTorrentsURLs.
type AddTorrentsURLs struct {
	// AutoTMM Whether Automatic Torrent Management should be used
	AutoTMM *bool `json:"autoTMM,omitempty"`

	// Category Category for the torrent
	Category *string `json:"category,omitempty"`

	// Cookie Cookie sent to download the .torrent file
	Cookie *string `json:"cookie,omitempty"`

	// DlLimit Set torrent download speed limit. Unit in bytes/second
	DlLimit *int64 `json:"dlLimit,omitempty"`

	// FirstLastPiecePrio Prioritize download first last piece. Possible values are `true`, `false` (default)
	FirstLastPiecePrio *AddTorrentsURLsFirstLastPiecePrio `json:"firstLastPiecePrio,omitempty"`

	// Paused Add torrents in the paused state. Possible values are `true`, `false` (default)
	Paused *AddTorrentsURLsPaused `json:"paused,omitempty"`

	// RatioLimit Set torrent share ratio limit
	RatioLimit *float32 `json:"ratioLimit,omitempty"`

	// Rename Rename torrent
	Rename *string `json:"rename,omitempty"`

	// RootFolder Create the root folder. Possible values are `true`, `false`, unset (default)
	RootFolder *AddTorrentsURLsRootFolder `json:"root_folder,omitempty"`

	// Savepath Download folder
	Savepath *string `json:"savepath,omitempty"`

	// SeedingTimeLimit Set torrent seeding time limit. Unit in seconds
	SeedingTimeLimit *int64 `json:"seedingTimeLimit,omitempty"`

	// SequentialDownload Enable sequential download. Possible values are `true`, `false` (default)
	SequentialDownload *AddTorrentsURLsSequentialDownload `json:"sequentialDownload,omitempty"`

	// SkipChecking Skip hash checking. Possible values are `true`, `false` (default)
	SkipChecking *AddTorrentsURLsSkipChecking `json:"skip_checking,omitempty"`

	// Tags Tags for the torrent, split by ','
	Tags *[]string `json:"tags,omitempty"`

	// UpLimit Set torrent upload speed limit. Unit in bytes/second
	UpLimit *int64 `json:"upLimit,omitempty"`

	// Urls URLs separated with newlines
	Urls *string `json:"urls,omitempty"`
}

// AddTorrentsURLsFirstLastPiecePrio Prioritize download first last piece. Possible values are `true`, `false` (default)
type AddTorrentsURLsFirstLastPiecePrio string

// AddTorrentsURLsPaused Add torrents in the paused state. Possible values are `true`, `false` (default)
type AddTorrentsURLsPaused string

// AddTorrentsURLsRootFolder Create the root folder. Possible values are `true`, `false`, unset (default)
type AddTorrentsURLsRootFolder string

// AddTorrentsURLsSequentialDownload Enable sequential download. Possible values are `true`, `false` (default)
type AddTorrentsURLsSequentialDownload string

// AddTorrentsURLsSkipChecking Skip hash checking. Possible values are `true`, `false` (default)
type AddTorrentsURLsSkipChecking string

// BuildInfo The response is a JSON object containing the following fields
type BuildInfo struct {
	Bitness    *int32  `json:"bitness,omitempty"`
	Boost      *string `json:"boost,omitempty"`
	Libtorrent *string `json:"libtorrent,omitempty"`
	Openssl    *string `json:"openssl,omitempty"`
	Qt         *string `json:"qt,omitempty"`
}

// Category defines model for Category.
type Category struct {
	Category string `json:"category"`
	SavePath string `json:"savePath"`
}

// Hashes defines model for Hashes.
type Hashes struct {
	Hashes []string `json:"hashes"`
}

// MainData The response is a JSON object with the following possible fields
type MainData struct {
	// Categories Info for categories added since last request
	Categories *map[string]TorrentsCategory `json:"categories,omitempty"`

	// CategoriesRemoved List of categories removed since last request
	CategoriesRemoved *[]string `json:"categories_removed,omitempty"`

	// FullUpdate Whether the response contains all the data or partial data
	FullUpdate *bool `json:"full_update,omitempty"`

	// Rid Response ID
	Rid *int64 `json:"rid,omitempty"`

	// ServerState The response is a JSON object with the following fields
	//
	// In addition to the above in partial data requests (see [Get partial data](https://github.com/qbittorrent/qBittorrent/wiki/WebUI-API-(qBittorrent-4.1)#get-partial-data) for more info):
	ServerState *TransferInfo `json:"server_state,omitempty"`

	// Tags List of tags added since last request
	Tags *[]string `json:"tags,omitempty"`

	// TagsRemoved List of tags removed since last request
	TagsRemoved *[]string `json:"tags_removed,omitempty"`

	// Torrents Property: torrent hash, value: same as [torrent list](https://github.com/qbittorrent/qBittorrent/wiki/WebUI-API-(qBittorrent-4.1)#get-torrent-list)
	Torrents *map[string]TorrentInfo `json:"torrents,omitempty"`

	// TorrentsRemoved List of hashes of torrents removed since last request
	TorrentsRemoved *[]string `json:"torrents_removed,omitempty"`
}

// MainLog defines model for MainLog.
type MainLog struct {
	// Id ID of the message
	Id *int64 `json:"id,omitempty"`

	// Message Text of the message
	Message *string `json:"message,omitempty"`

	// Timestamp Milliseconds since epoch
	Timestamp *int64 `json:"timestamp,omitempty"`

	// Type Type of the message: Log::NORMAL: `1`, Log::INFO: `2`, Log::WARNING: `4`, Log::CRITICAL: `8`
	Type *MainLogType `json:"type,omitempty"`
}

// MainLogType Type of the message: Log::NORMAL: `1`, Log::INFO: `2`, Log::WARNING: `4`, Log::CRITICAL: `8`
type MainLogType int32

// PeersLog defines model for PeersLog.
type PeersLog struct {
	// Blocked Whether or not the peer was blocked
	Blocked *bool `json:"blocked,omitempty"`

	// Id ID of the peer
	Id *int64 `json:"id,omitempty"`

	// Ip IP of the peer
	Ip *string `json:"ip,omitempty"`

	// Reason Reason of the block
	Reason *string `json:"reason,omitempty"`

	// Timestamp Milliseconds since epoch
	Timestamp *int64 `json:"timestamp,omitempty"`
}

// Preferences Possible fields:
type Preferences struct {
	// AddTrackers List of trackers to add to new torrent
	AddTrackers *string `json:"add_trackers,omitempty"`

	// AddTrackersEnabled Enable automatic adding of trackers to new torrents
	AddTrackersEnabled *bool `json:"add_trackers_enabled,omitempty"`

	// AltDlLimit Alternative global download speed limit in KiB/s
	AltDlLimit *int64 `json:"alt_dl_limit,omitempty"`

	// AltUpLimit Alternative global upload speed limit in KiB/s
	AltUpLimit *int64 `json:"alt_up_limit,omitempty"`

	// AlternativeWebuiEnabled True if an alternative WebUI should be used
	AlternativeWebuiEnabled *bool `json:"alternative_webui_enabled,omitempty"`

	// AlternativeWebuiPath File path to the alternative WebUI
	AlternativeWebuiPath *string `json:"alternative_webui_path,omitempty"`

	// AnnounceIp TODO
	AnnounceIp *string `json:"announce_ip,omitempty"`

	// AnnounceToAllTiers True always announce to all tiers
	AnnounceToAllTiers *bool `json:"announce_to_all_tiers,omitempty"`

	// AnnounceToAllTrackers True always announce to all trackers in a tier
	AnnounceToAllTrackers *bool `json:"announce_to_all_trackers,omitempty"`

	// AnonymousMode If true anonymous mode will be enabled; read more [here](https://github.com/qbittorrent/qBittorrent/wiki/Anonymous-Mode); this option is only available in qBittorent built against libtorrent version 0.16.X and higher
	AnonymousMode *bool `json:"anonymous_mode,omitempty"`

	// AsyncIoThreads Number of asynchronous I/O threads
	AsyncIoThreads *int64 `json:"async_io_threads,omitempty"`

	// AutoDeleteMode TODO
	AutoDeleteMode *int `json:"auto_delete_mode,omitempty"`

	// AutoTmmEnabled True if Automatic Torrent Management is enabled by default
	AutoTmmEnabled *bool `json:"auto_tmm_enabled,omitempty"`

	// AutorunEnabled True if external program should be run after torrent has finished downloading
	AutorunEnabled *bool `json:"autorun_enabled,omitempty"`

	// AutorunProgram Program path/name/arguments to run if `autorun_enabled` is enabled; path is separated by slashes; you can use `%f` and `%n` arguments, which will be expanded by qBittorent as path_to_torrent_file and torrent_name (from the GUI; not the .torrent file name) respectively
	AutorunProgram *string `json:"autorun_program,omitempty"`

	// BannedIPs List of banned IPs
	BannedIPs *string `json:"banned_IPs,omitempty"`

	// BittorrentProtocol Bittorrent Protocol to use (see list of possible values below)
	//
	// | Value | Description |
	// | ----- | ----------- |
	// | 0     | TCP and μTP |
	// | 1     | TCP         |
	// | 2     | μTP         |
	BittorrentProtocol *PreferencesBittorrentProtocol `json:"bittorrent_protocol,omitempty"`

	// BypassAuthSubnetWhitelist (White)list of ipv4/ipv6 subnets for which webui authentication should be bypassed; list entries are separated by commas
	BypassAuthSubnetWhitelist *[]string `json:"bypass_auth_subnet_whitelist,omitempty"`

	// BypassAuthSubnetWhitelistEnabled True if webui authentication should be bypassed for clients whose ip resides within (at least) one of the subnets on the whitelist
	BypassAuthSubnetWhitelistEnabled *bool `json:"bypass_auth_subnet_whitelist_enabled,omitempty"`

	// BypassLocalAuth True if authentication challenge for loopback address (127.0.0.1) should be disabled
	BypassLocalAuth *bool `json:"bypass_local_auth,omitempty"`

	// CategoryChangedTmmEnabled True if torrent should be relocated when its Category's save path changes
	CategoryChangedTmmEnabled *bool `json:"category_changed_tmm_enabled,omitempty"`

	// CheckingMemoryUse Outstanding memory when checking torrents in MiB
	CheckingMemoryUse *int64 `json:"checking_memory_use,omitempty"`

	// CreateSubfolderEnabled True if a subfolder should be created when adding a torrent
	CreateSubfolderEnabled *bool `json:"create_subfolder_enabled,omitempty"`

	// CurrentInterfaceAddress IP Address to bind to. Empty String means All addresses
	CurrentInterfaceAddress *string `json:"current_interface_address,omitempty"`

	// CurrentNetworkInterface Network Interface used
	CurrentNetworkInterface *string `json:"current_network_interface,omitempty"`

	// Dht True if DHT is enabled
	Dht *bool `json:"dht,omitempty"`

	// DiskCache Disk cache used in MiB
	DiskCache *int64 `json:"disk_cache,omitempty"`

	// DiskCacheTtl Disk cache expiry interval in seconds
	DiskCacheTtl *int64 `json:"disk_cache_ttl,omitempty"`

	// DlLimit Global download speed limit in KiB/s; `-1` means no limit is applied
	DlLimit *int64 `json:"dl_limit,omitempty"`

	// DontCountSlowTorrents If true torrents w/o any activity (stalled ones) will not be counted towards `max_active_*` limits; see [dont_count_slow_torrents](https://www.libtorrent.org/reference-Settings.html#dont_count_slow_torrents) for more information
	DontCountSlowTorrents *bool `json:"dont_count_slow_torrents,omitempty"`

	// DyndnsDomain Your DDNS domain name
	DyndnsDomain *string `json:"dyndns_domain,omitempty"`

	// DyndnsEnabled True if server DNS should be updated dynamically
	DyndnsEnabled *bool `json:"dyndns_enabled,omitempty"`

	// DyndnsPassword Password for DDNS service
	DyndnsPassword *string `json:"dyndns_password,omitempty"`

	// DyndnsService See list of possible values here below
	//
	// | Value | Description |
	// | ----- | ----------- |
	// | 0     | Use DyDNS   |
	// | 1     | Use NOIP    |
	DyndnsService *PreferencesDyndnsService `json:"dyndns_service,omitempty"`

	// DyndnsUsername Username for DDNS service
	DyndnsUsername *string `json:"dyndns_username,omitempty"`

	// EmbeddedTrackerPort Port used for embedded tracker
	EmbeddedTrackerPort *int32 `json:"embedded_tracker_port,omitempty"`

	// EnableCoalesceReadWrite True enables coalesce reads & writes
	EnableCoalesceReadWrite *bool `json:"enable_coalesce_read_write,omitempty"`

	// EnableEmbeddedTracker True enables embedded tracker
	EnableEmbeddedTracker *bool `json:"enable_embedded_tracker,omitempty"`

	// EnableMultiConnectionsFromSameIp True allows multiple connections from the same IP address
	EnableMultiConnectionsFromSameIp *bool `json:"enable_multi_connections_from_same_ip,omitempty"`

	// EnableOsCache True enables os cache
	EnableOsCache *bool `json:"enable_os_cache,omitempty"`

	// EnablePieceExtentAffinity True if the advanced libtorrent option `piece_extent_affinity` is enabled
	EnablePieceExtentAffinity *bool `json:"enable_piece_extent_affinity,omitempty"`

	// EnableUploadSuggestions True enables sending of upload piece suggestions
	EnableUploadSuggestions *bool `json:"enable_upload_suggestions,omitempty"`

	// Encryption See list of possible values here below
	//
	// | Value | Description          |
	// | ----- | -------------------- |
	// | 0     | Prefer encryption    |
	// | 1     | Force encryption on  |
	// | 2     | Force encryption off |
	Encryption *PreferencesEncryption `json:"encryption,omitempty"`

	// ExportDir Path to directory to copy .torrent files to. Slashes are used as path separators
	ExportDir *string `json:"export_dir,omitempty"`

	// ExportDirFin Path to directory to copy .torrent files of completed downloads to. Slashes are used as path separators
	ExportDirFin *string `json:"export_dir_fin,omitempty"`

	// FilePoolSize File pool size
	FilePoolSize *int64 `json:"file_pool_size,omitempty"`

	// IncompleteFilesExt True if ".!qB" should be appended to incomplete files
	IncompleteFilesExt *bool `json:"incomplete_files_ext,omitempty"`

	// IpFilterEnabled True if external IP filter should be enabled
	IpFilterEnabled *bool `json:"ip_filter_enabled,omitempty"`

	// IpFilterPath Path to IP filter file (.dat, .p2p, .p2b files are supported); path is separated by slashes
	IpFilterPath *string `json:"ip_filter_path,omitempty"`

	// IpFilterTrackers True if IP filters are applied to trackers
	IpFilterTrackers *bool `json:"ip_filter_trackers,omitempty"`

	// LimitLanPeers True if `[du]l_limit` should be applied to peers on the LAN
	LimitLanPeers *bool `json:"limit_lan_peers,omitempty"`

	// LimitTcpOverhead True if `[du]l_limit` should be applied to estimated TCP overhead (service data: e.g. packet headers)
	LimitTcpOverhead *bool `json:"limit_tcp_overhead,omitempty"`

	// LimitUtpRate True if `[du]l_limit` should be applied to uTP connections; this option is only available in qBittorent built against libtorrent version 0.16.X and higher
	LimitUtpRate *bool `json:"limit_utp_rate,omitempty"`

	// ListenPort Port for incoming connections
	ListenPort *int32 `json:"listen_port,omitempty"`

	// Locale Currently selected language (e.g. en_GB for English)
	Locale *string `json:"locale,omitempty"`

	// Lsd True if LSD is enabled
	Lsd *bool `json:"lsd,omitempty"`

	// MailNotificationAuthEnabled True if smtp server requires authentication
	MailNotificationAuthEnabled *bool `json:"mail_notification_auth_enabled,omitempty"`

	// MailNotificationEmail e-mail to send notifications to
	MailNotificationEmail *string `json:"mail_notification_email,omitempty"`

	// MailNotificationEnabled True if e-mail notification should be enabled
	MailNotificationEnabled *bool `json:"mail_notification_enabled,omitempty"`

	// MailNotificationPassword Password for smtp authentication
	MailNotificationPassword *string `json:"mail_notification_password,omitempty"`

	// MailNotificationSender e-mail where notifications should originate from
	MailNotificationSender *string `json:"mail_notification_sender,omitempty"`

	// MailNotificationSmtp smtp server for e-mail notifications
	MailNotificationSmtp *string `json:"mail_notification_smtp,omitempty"`

	// MailNotificationSslEnabled True if smtp server requires SSL connection
	MailNotificationSslEnabled *bool `json:"mail_notification_ssl_enabled,omitempty"`

	// MailNotificationUsername Username for smtp authentication
	MailNotificationUsername *string `json:"mail_notification_username,omitempty"`

	// MaxActiveDownloads Maximum number of active simultaneous downloads
	MaxActiveDownloads *int64 `json:"max_active_downloads,omitempty"`

	// MaxActiveTorrents Maximum number of active simultaneous downloads and uploads
	MaxActiveTorrents *int64 `json:"max_active_torrents,omitempty"`

	// MaxActiveUploads Maximum number of active simultaneous uploads
	MaxActiveUploads *int64 `json:"max_active_uploads,omitempty"`

	// MaxConnec Maximum global number of simultaneous connections
	MaxConnec *int64 `json:"max_connec,omitempty"`

	// MaxConnecPerTorrent Maximum number of simultaneous connections per torrent
	MaxConnecPerTorrent *int64 `json:"max_connec_per_torrent,omitempty"`

	// MaxRatio Get the global share ratio limit
	MaxRatio *float32 `json:"max_ratio,omitempty"`

	// MaxRatioAct Action performed when a torrent reaches the maximum share ratio. See list of possible values here below.
	//
	// | Value | Description    |
	// | ----- | -------------- |
	// | 0     | Pause torrent  |
	// | 1     | Remove torrent |
	MaxRatioAct *PreferencesMaxRatioAct `json:"max_ratio_act,omitempty"`

	// MaxRatioEnabled True if share ratio limit is enabled
	MaxRatioEnabled *bool `json:"max_ratio_enabled,omitempty"`

	// MaxSeedingTime Number of minutes to seed a torrent
	MaxSeedingTime *int64 `json:"max_seeding_time,omitempty"`

	// MaxSeedingTimeEnabled True enables max seeding time
	MaxSeedingTimeEnabled *bool `json:"max_seeding_time_enabled,omitempty"`

	// MaxUploads Maximum number of upload slots
	MaxUploads *int64 `json:"max_uploads,omitempty"`

	// MaxUploadsPerTorrent Maximum number of upload slots per torrent
	MaxUploadsPerTorrent *int64 `json:"max_uploads_per_torrent,omitempty"`

	// OutgoingPortsMax Maximal outgoing port (0: Disabled)
	OutgoingPortsMax *int32 `json:"outgoing_ports_max,omitempty"`

	// OutgoingPortsMin Minimal outgoing port (0: Disabled)
	OutgoingPortsMin *int32 `json:"outgoing_ports_min,omitempty"`

	// Pex True if PeX is enabled
	Pex *bool `json:"pex,omitempty"`

	// PreallocateAll True if disk space should be pre-allocated for all files
	PreallocateAll *bool `json:"preallocate_all,omitempty"`

	// ProxyAuthEnabled True proxy requires authentication; doesn't apply to SOCKS4 proxies
	ProxyAuthEnabled *bool `json:"proxy_auth_enabled,omitempty"`

	// ProxyIp Proxy IP address or domain name
	ProxyIp *string `json:"proxy_ip,omitempty"`

	// ProxyPassword Password for proxy authentication
	ProxyPassword *string `json:"proxy_password,omitempty"`

	// ProxyPeerConnections True if peer and web seed connections should be proxified; this option will have any effect only in qBittorent built against libtorrent version 0.16.X and higher
	ProxyPeerConnections *bool `json:"proxy_peer_connections,omitempty"`

	// ProxyPort Proxy port
	ProxyPort *int32 `json:"proxy_port,omitempty"`

	// ProxyTorrentsOnly True if proxy is only used for torrents
	ProxyTorrentsOnly *bool `json:"proxy_torrents_only,omitempty"`

	// ProxyType See list of possible values here below
	//
	// | Value | Description                         |
	// | ----- | ----------------------------------- |
	// | -1    | Proxy is disabled                   |
	// | 0     | Prefer encryption                   |
	// | 1     | HTTP proxy without authentication   |
	// | 2     | SOCKS5 proxy without authentication |
	// | 3     | HTTP proxy with authentication      |
	// | 4     | SOCKS5 proxy with authentication    |
	// | 5     | SOCKS4 proxy without authentication |
	ProxyType *PreferencesProxyType `json:"proxy_type,omitempty"`

	// ProxyUsername Username for proxy authentication
	ProxyUsername *string `json:"proxy_username,omitempty"`

	// QueueingEnabled True if torrent queuing is enabled
	QueueingEnabled *bool `json:"queueing_enabled,omitempty"`

	// RandomPort True if the port is randomly selected
	RandomPort *bool `json:"random_port,omitempty"`

	// RecheckCompletedTorrents True rechecks torrents on completion
	RecheckCompletedTorrents *bool `json:"recheck_completed_torrents,omitempty"`

	// ResolvePeerCountries True resolves peer countries
	ResolvePeerCountries *bool `json:"resolve_peer_countries,omitempty"`

	// RssAutoDownloadingEnabled Enable auto-downloading of torrents from the RSS feeds
	RssAutoDownloadingEnabled *bool `json:"rss_auto_downloading_enabled,omitempty"`

	// RssDownloadRepackProperEpisodes For API ≥ v2.5.1: Enable downloading of repack/proper Episodes
	RssDownloadRepackProperEpisodes *bool `json:"rss_download_repack_proper_episodes,omitempty"`

	// RssMaxArticlesPerFeed Max stored articles per RSS feed
	RssMaxArticlesPerFeed *int64 `json:"rss_max_articles_per_feed,omitempty"`

	// RssProcessingEnabled Enable processing of RSS feeds
	RssProcessingEnabled *bool `json:"rss_processing_enabled,omitempty"`

	// RssRefreshInterval RSS refresh interval
	RssRefreshInterval *int64 `json:"rss_refresh_interval,omitempty"`

	// RssSmartEpisodeFilters For API ≥ v2.5.1: List of RSS Smart Episode Filters
	RssSmartEpisodeFilters *string `json:"rss_smart_episode_filters,omitempty"`

	// SavePath Default save path for torrents, separated by slashes
	SavePath *string `json:"save_path,omitempty"`

	// SavePathChangedTmmEnabled True if torrent should be relocated when the default save path changes
	SavePathChangedTmmEnabled *bool `json:"save_path_changed_tmm_enabled,omitempty"`

	// SaveResumeDataInterval Save resume data interval in min
	SaveResumeDataInterval *int64 `json:"save_resume_data_interval,omitempty"`

	// ScanDirs Property: directory to watch for torrent files, value: where torrents loaded from this directory should be downloaded to (see list of possible values below). Slashes are used as path separators; multiple key/value pairs can be specified
	//
	// | Value                  | Description                       |
	// | ---------------------- | --------------------------------- |
	// | 0                      | Download to the monitored folder  |
	// | 1                      | Download to the default save path |
	// | "/path/to/download/to" | Download to this path             |
	ScanDirs *map[string]Preferences_ScanDirs_AdditionalProperties `json:"scan_dirs,omitempty"`

	// ScheduleFromHour Scheduler starting hour
	ScheduleFromHour *int32 `json:"schedule_from_hour,omitempty"`

	// ScheduleFromMin Scheduler starting minute
	ScheduleFromMin *int32 `json:"schedule_from_min,omitempty"`

	// ScheduleToHour Scheduler ending hour
	ScheduleToHour *int32 `json:"schedule_to_hour,omitempty"`

	// ScheduleToMin Scheduler ending minute
	ScheduleToMin *int32 `json:"schedule_to_min,omitempty"`

	// SchedulerDays Scheduler days. See possible values here below
	//
	// | Value | Description     |
	// | ----- | --------------- |
	// | 0     | Every day       |
	// | 1     | Every weekday   |
	// | 2     | Every weekend   |
	// | 3     | Every Monday    |
	// | 4     | Every Tuesday   |
	// | 5     | Every Wednesday |
	// | 6     | Every Thursday  |
	// | 7     | Every Friday    |
	// | 8     | Every Saturday  |
	// | 9     | Every Sunday    |
	SchedulerDays *PreferencesSchedulerDays `json:"scheduler_days,omitempty"`

	// SchedulerEnabled True if alternative limits should be applied according to schedule
	SchedulerEnabled *bool `json:"scheduler_enabled,omitempty"`

	// SendBufferLowWatermark Send buffer low watermark in KiB
	SendBufferLowWatermark *int64 `json:"send_buffer_low_watermark,omitempty"`

	// SendBufferWatermark Send buffer watermark in KiB
	SendBufferWatermark *int64 `json:"send_buffer_watermark,omitempty"`

	// SendBufferWatermarkFactor Send buffer watermark factor in percent
	SendBufferWatermarkFactor *int32 `json:"send_buffer_watermark_factor,omitempty"`

	// SlowTorrentDlRateThreshold Download rate in KiB/s for a torrent to be considered "slow"
	SlowTorrentDlRateThreshold *int64 `json:"slow_torrent_dl_rate_threshold,omitempty"`

	// SlowTorrentInactiveTimer Seconds a torrent should be inactive before considered "slow"
	SlowTorrentInactiveTimer *int64 `json:"slow_torrent_inactive_timer,omitempty"`

	// SlowTorrentUlRateThreshold Upload rate in KiB/s for a torrent to be considered "slow"
	SlowTorrentUlRateThreshold *int64 `json:"slow_torrent_ul_rate_threshold,omitempty"`

	// SocketBacklogSize Socket backlog size
	SocketBacklogSize *int64 `json:"socket_backlog_size,omitempty"`

	// SslCert For API < v2.0.1: SSL certificate contents (this is a not a path)
	SslCert *string `json:"ssl_cert,omitempty"`

	// SslKey For API < v2.0.1: SSL keyfile contents (this is a not a path)
	SslKey *string `json:"ssl_key,omitempty"`

	// StartPausedEnabled True if torrents should be added in a Paused state
	StartPausedEnabled *bool `json:"start_paused_enabled,omitempty"`

	// StopTrackerTimeout Timeout in seconds for a `stopped` announce request to trackers
	StopTrackerTimeout *int64 `json:"stop_tracker_timeout,omitempty"`

	// TempPath Path for incomplete torrents, separated by slashes
	TempPath *string `json:"temp_path,omitempty"`

	// TempPathEnabled True if folder for incomplete torrents is enabled
	TempPathEnabled *bool `json:"temp_path_enabled,omitempty"`

	// TorrentChangedTmmEnabled True if torrent should be relocated when its Category changes
	TorrentChangedTmmEnabled *bool `json:"torrent_changed_tmm_enabled,omitempty"`

	// UpLimit Global upload speed limit in KiB/s; `-1` means no limit is applied
	UpLimit *int64 `json:"up_limit,omitempty"`

	// UploadChokingAlgorithm Upload choking algorithm used (see list of possible values below)
	//
	// | Value | Description    |
	// | ----- | -------------- |
	// | 0     | Round-robin    |
	// | 1     | Fastest upload |
	// | 2     | Anti-leech     |
	UploadChokingAlgorithm *PreferencesUploadChokingAlgorithm `json:"upload_choking_algorithm,omitempty"`

	// UploadSlotsBehavior Upload slots behavior used (see list of possible values below)
	//
	// | Value | Description       |
	// | ----- | ----------------- |
	// | 0     | Fixed slots       |
	// | 1     | Upload rate based |
	UploadSlotsBehavior *PreferencesUploadSlotsBehavior `json:"upload_slots_behavior,omitempty"`

	// Upnp True if UPnP/NAT-PMP is enabled
	Upnp *bool `json:"upnp,omitempty"`

	// UpnpLeaseDuration UPnP lease duration (0: Permanent lease)
	UpnpLeaseDuration *int64 `json:"upnp_lease_duration,omitempty"`

	// UseHttps True if WebUI HTTPS access is enabled
	UseHttps *bool `json:"use_https,omitempty"`

	// UtpTcpMixedMode μTP-TCP mixed mode algorithm (see list of possible values below)
	//
	// | Value | Description       |
	// | ----- | ----------------- |
	// | 0     | Prefer TCP        |
	// | 1     | Peer proportional |
	UtpTcpMixedMode *PreferencesUtpTcpMixedMode `json:"utp_tcp_mixed_mode,omitempty"`

	// WebUiAddress IP address to use for the WebUI
	WebUiAddress *string `json:"web_ui_address,omitempty"`

	// WebUiBanDuration WebUI access ban duration in seconds
	WebUiBanDuration *int64 `json:"web_ui_ban_duration,omitempty"`

	// WebUiClickjackingProtectionEnabled True if WebUI clickjacking protection is enabled
	WebUiClickjackingProtectionEnabled *bool `json:"web_ui_clickjacking_protection_enabled,omitempty"`

	// WebUiCsrfProtectionEnabled True if WebUI CSRF protection is enabled
	WebUiCsrfProtectionEnabled *bool `json:"web_ui_csrf_protection_enabled,omitempty"`

	// WebUiCustomHttpHeaders For API ≥ v2.5.1: List of custom http headers
	WebUiCustomHttpHeaders *string `json:"web_ui_custom_http_headers,omitempty"`

	// WebUiDomainList Comma-separated list of domains to accept when performing Host header validation
	WebUiDomainList *[]string `json:"web_ui_domain_list,omitempty"`

	// WebUiHostHeaderValidationEnabled True if WebUI host header validation is enabled
	WebUiHostHeaderValidationEnabled *bool `json:"web_ui_host_header_validation_enabled,omitempty"`

	// WebUiHttpsCertPath For API ≥ v2.0.1: Path to SSL certificate
	WebUiHttpsCertPath *string `json:"web_ui_https_cert_path,omitempty"`

	// WebUiHttpsKeyPath For API ≥ v2.0.1: Path to SSL keyfile
	WebUiHttpsKeyPath *string `json:"web_ui_https_key_path,omitempty"`

	// WebUiMaxAuthFailCount Maximum number of authentication failures before WebUI access ban
	WebUiMaxAuthFailCount *int64 `json:"web_ui_max_auth_fail_count,omitempty"`

	// WebUiPort WebUI port
	WebUiPort *int32 `json:"web_ui_port,omitempty"`

	// WebUiSecureCookieEnabled True if WebUI cookie `Secure` flag is enabled
	WebUiSecureCookieEnabled *bool `json:"web_ui_secure_cookie_enabled,omitempty"`

	// WebUiSessionTimeout Seconds until WebUI is automatically signed off
	WebUiSessionTimeout *int64 `json:"web_ui_session_timeout,omitempty"`

	// WebUiUpnp True if UPnP is used for the WebUI port
	WebUiUpnp *bool `json:"web_ui_upnp,omitempty"`

	// WebUiUseCustomHttpHeadersEnabled For API ≥ v2.5.1: Enable custom http headers
	WebUiUseCustomHttpHeadersEnabled *bool `json:"web_ui_use_custom_http_headers_enabled,omitempty"`

	// WebUiUsername WebUI username
	WebUiUsername        *string                `json:"web_ui_username,omitempty"`
	AdditionalProperties map[string]interface{} `json:"-"`
}

// PreferencesBittorrentProtocol Bittorrent Protocol to use (see list of possible values below)
//
// | Value | Description |
// | ----- | ----------- |
// | 0     | TCP and μTP |
// | 1     | TCP         |
// | 2     | μTP         |
type PreferencesBittorrentProtocol int32

// PreferencesDyndnsService See list of possible values here below
//
// | Value | Description |
// | ----- | ----------- |
// | 0     | Use DyDNS   |
// | 1     | Use NOIP    |
type PreferencesDyndnsService int32

// PreferencesEncryption See list of possible values here below
//
// | Value | Description          |
// | ----- | -------------------- |
// | 0     | Prefer encryption    |
// | 1     | Force encryption on  |
// | 2     | Force encryption off |
type PreferencesEncryption int32

// PreferencesMaxRatioAct Action performed when a torrent reaches the maximum share ratio. See list of possible values here below.
//
// | Value | Description    |
// | ----- | -------------- |
// | 0     | Pause torrent  |
// | 1     | Remove torrent |
type PreferencesMaxRatioAct int64

// PreferencesProxyType See list of possible values here below
//
// | Value | Description                         |
// | ----- | ----------------------------------- |
// | -1    | Proxy is disabled                   |
// | 0     | Prefer encryption                   |
// | 1     | HTTP proxy without authentication   |
// | 2     | SOCKS5 proxy without authentication |
// | 3     | HTTP proxy with authentication      |
// | 4     | SOCKS5 proxy with authentication    |
// | 5     | SOCKS4 proxy without authentication |
type PreferencesProxyType int32

// PreferencesScanDirs0 defines model for Preferences.ScanDirs.0.
type PreferencesScanDirs0 int

// PreferencesScanDirs1 defines model for .
type PreferencesScanDirs1 = string

// Preferences_ScanDirs_AdditionalProperties defines model for Preferences.scan_dirs.AdditionalProperties.
type Preferences_ScanDirs_AdditionalProperties struct {
	union json.RawMessage
}

// PreferencesSchedulerDays Scheduler days. See possible values here below
//
// | Value | Description     |
// | ----- | --------------- |
// | 0     | Every day       |
// | 1     | Every weekday   |
// | 2     | Every weekend   |
// | 3     | Every Monday    |
// | 4     | Every Tuesday   |
// | 5     | Every Wednesday |
// | 6     | Every Thursday  |
// | 7     | Every Friday    |
// | 8     | Every Saturday  |
// | 9     | Every Sunday    |
type PreferencesSchedulerDays int32

// PreferencesUploadChokingAlgorithm Upload choking algorithm used (see list of possible values below)
//
// | Value | Description    |
// | ----- | -------------- |
// | 0     | Round-robin    |
// | 1     | Fastest upload |
// | 2     | Anti-leech     |
type PreferencesUploadChokingAlgorithm int32

// PreferencesUploadSlotsBehavior Upload slots behavior used (see list of possible values below)
//
// | Value | Description       |
// | ----- | ----------------- |
// | 0     | Fixed slots       |
// | 1     | Upload rate based |
type PreferencesUploadSlotsBehavior int32

// PreferencesUtpTcpMixedMode μTP-TCP mixed mode algorithm (see list of possible values below)
//
// | Value | Description       |
// | ----- | ----------------- |
// | 0     | Prefer TCP        |
// | 1     | Peer proportional |
type PreferencesUtpTcpMixedMode int32

// RenameTorrentFiles defines model for RenameTorrentFiles.
type RenameTorrentFiles struct {
	// Hash The hash of the torrent
	Hash string `json:"hash"`

	// NewPath The new path to use for the file
	NewPath string `json:"newPath"`

	// OldPath The old path of the torrent
	OldPath string `json:"oldPath"`
}

// RssRuleDef JSON encoded rule definition
//
// Rule definition is JSON encoded dictionary with the following fields:
// | Field                     | Type   | Description                                             |
// | ------------------------- | ------ | ------------------------------------------------------- |
// | enabled                   | bool   | Whether the rule is enabled                             |
// | mustContain               | string | The substring that the torrent name must contain        |
// | mustNotContain            | string | The substring that the torrent name must not contain    |
// | useRegex                  | bool   | Enable regex mode in "mustContain" and "mustNotContain" |
// | episodeFilter             | string | Episode filter definition                               |
// | smartFilter               | bool   | Enable smart episode filter                             |
// | previouslyMatchedEpisodes | list   | The list of episode IDs already matched by smart filter |
// | affectedFeeds             | list   | The feed URLs the rule applied to                       |
// | ignoreDays                | number | Ignore sunsequent rule matches                          |
// | lastMatch                 | string | The rule last match time                                |
// | addPaused                 | bool   | Add matched torrent in paused mode                      |
// | assignedCategory          | string | Assign category to the torrent                          |
// | savePath                  | string | Save torrent to the given directory                     |
type RssRuleDef struct {
	// AddPaused Add matched torrent in paused mode
	AddPaused *bool `json:"addPaused,omitempty"`

	// AffectedFeeds The feed URLs the rule applied to
	AffectedFeeds *[]string `json:"affectedFeeds,omitempty"`

	// AssignedCategory Assign category to the torrent
	AssignedCategory *string `json:"assignedCategory,omitempty"`

	// Enabled Whether the rule is enabled
	Enabled *bool `json:"enabled,omitempty"`

	// EpisodeFilter Episode filter definition
	EpisodeFilter *string `json:"episodeFilter,omitempty"`

	// IgnoreDays Ignore sunsequent rule matches
	IgnoreDays *float32 `json:"ignoreDays,omitempty"`

	// LastMatch The rule last match time
	LastMatch *string `json:"lastMatch,omitempty"`

	// MustContain The substring that the torrent name must contain
	MustContain *string `json:"mustContain,omitempty"`

	// MustNotContain The substring that the torrent name must not contain
	MustNotContain *string `json:"mustNotContain,omitempty"`

	// PreviouslyMatchedEpisodes The list of episode IDs already matched by smart filter
	PreviouslyMatchedEpisodes *[]int64 `json:"previouslyMatchedEpisodes,omitempty"`

	// SavePath Save torrent to the given directory
	SavePath *string `json:"savePath,omitempty"`

	// SmartFilter Enable smart episode filter
	SmartFilter *bool `json:"smartFilter,omitempty"`

	// UseRegex Enable regex mode in "mustContain" and "mustNotContain"
	UseRegex *bool `json:"useRegex,omitempty"`
}

// SearchJob The response is a JSON object with the following fields
type SearchJob struct {
	// Id ID of the search job
	Id *float32 `json:"id,omitempty"`
}

// SearchJobStatus defines model for SearchJobStatus.
type SearchJobStatus struct {
	// Id ID of the search job
	Id *float32 `json:"id,omitempty"`

	// Status Current status of the search job (either `Running` or `Stopped`)
	Status *SearchJobStatusStatus `json:"status,omitempty"`

	// Total Total number of results. If the status is `Running` this number may contineu to increase
	Total *float32 `json:"total,omitempty"`
}

// SearchJobStatusStatus Current status of the search job (either `Running` or `Stopped`)
type SearchJobStatusStatus string

// SearchPlugin defines model for SearchPlugin.
type SearchPlugin struct {
	// Enabled Whether the plugin is enabled
	Enabled *bool `json:"enabled,omitempty"`

	// FullName Full name of the plugin
	FullName *string `json:"fullName,omitempty"`

	// Name Short name of the plugin
	Name *string `json:"name,omitempty"`

	// SupportedCategories List of category objects
	SupportedCategories *[]struct {
		Id   *string `json:"id,omitempty"`
		Name *string `json:"name,omitempty"`
	} `json:"supportedCategories,omitempty"`

	// Url URL of the torrent site
	Url *string `json:"url,omitempty"`

	// Version Installed version of the plugin
	Version *string `json:"version,omitempty"`
}

// SearchResult defines model for SearchResult.
type SearchResult struct {
	// DescrLink URL of the torrent's description page
	DescrLink *string `json:"descrLink,omitempty"`

	// FileName Name of the file
	FileName *string `json:"fileName,omitempty"`

	// FileSize Size of the file in Bytes
	FileSize *float32 `json:"fileSize,omitempty"`

	// FileUrl Torrent download link (usually either .torrent file or magnet link)
	FileUrl *string `json:"fileUrl,omitempty"`

	// NbLeechers Number of leechers
	NbLeechers *float32 `json:"nbLeechers,omitempty"`

	// NbSeeders Number of seeders
	NbSeeders *float32 `json:"nbSeeders,omitempty"`

	// SiteUrl URL of the torrent site
	SiteUrl *string `json:"siteUrl,omitempty"`
}

// SearchResults defines model for SearchResults.
type SearchResults struct {
	Results *[]SearchResult `json:"results,omitempty"`

	// Status Current status of the search job (either `Running` or `Stopped`)
	Status *SearchResultsStatus `json:"status,omitempty"`

	// Total Total number of results. If the status is `Running` this number may continue to increase
	Total *float32 `json:"total,omitempty"`
}

// SearchResultsStatus Current status of the search job (either `Running` or `Stopped`)
type SearchResultsStatus string

// SetPreferences defines model for SetPreferences.
type SetPreferences struct {
	// AddTrackers List of trackers to add to new torrent
	AddTrackers *string `json:"add_trackers,omitempty"`

	// AddTrackersEnabled Enable automatic adding of trackers to new torrents
	AddTrackersEnabled *bool `json:"add_trackers_enabled,omitempty"`

	// AltDlLimit Alternative global download speed limit in KiB/s
	AltDlLimit *int64 `json:"alt_dl_limit,omitempty"`

	// AltUpLimit Alternative global upload speed limit in KiB/s
	AltUpLimit *int64 `json:"alt_up_limit,omitempty"`

	// AlternativeWebuiEnabled True if an alternative WebUI should be used
	AlternativeWebuiEnabled *bool `json:"alternative_webui_enabled,omitempty"`

	// AlternativeWebuiPath File path to the alternative WebUI
	AlternativeWebuiPath *string `json:"alternative_webui_path,omitempty"`

	// AnnounceIp TODO
	AnnounceIp *string `json:"announce_ip,omitempty"`

	// AnnounceToAllTiers True always announce to all tiers
	AnnounceToAllTiers *bool `json:"announce_to_all_tiers,omitempty"`

	// AnnounceToAllTrackers True always announce to all trackers in a tier
	AnnounceToAllTrackers *bool `json:"announce_to_all_trackers,omitempty"`

	// AnonymousMode If true anonymous mode will be enabled; read more [here](https://github.com/qbittorrent/qBittorrent/wiki/Anonymous-Mode); this option is only available in qBittorent built against libtorrent version 0.16.X and higher
	AnonymousMode *bool `json:"anonymous_mode,omitempty"`

	// AsyncIoThreads Number of asynchronous I/O threads
	AsyncIoThreads *int64 `json:"async_io_threads,omitempty"`

	// AutoDeleteMode TODO
	AutoDeleteMode *int `json:"auto_delete_mode,omitempty"`

	// AutoTmmEnabled True if Automatic Torrent Management is enabled by default
	AutoTmmEnabled *bool `json:"auto_tmm_enabled,omitempty"`

	// AutorunEnabled True if external program should be run after torrent has finished downloading
	AutorunEnabled *bool `json:"autorun_enabled,omitempty"`

	// AutorunProgram Program path/name/arguments to run if `autorun_enabled` is enabled; path is separated by slashes; you can use `%f` and `%n` arguments, which will be expanded by qBittorent as path_to_torrent_file and torrent_name (from the GUI; not the .torrent file name) respectively
	AutorunProgram *string `json:"autorun_program,omitempty"`

	// BannedIPs List of banned IPs
	BannedIPs *string `json:"banned_IPs,omitempty"`

	// BittorrentProtocol Bittorrent Protocol to use (see list of possible values below)
	//
	// | Value | Description |
	// | ----- | ----------- |
	// | 0     | TCP and μTP |
	// | 1     | TCP         |
	// | 2     | μTP         |
	BittorrentProtocol *SetPreferencesBittorrentProtocol `json:"bittorrent_protocol,omitempty"`

	// BypassAuthSubnetWhitelist (White)list of ipv4/ipv6 subnets for which webui authentication should be bypassed; list entries are separated by commas
	BypassAuthSubnetWhitelist *[]string `json:"bypass_auth_subnet_whitelist,omitempty"`

	// BypassAuthSubnetWhitelistEnabled True if webui authentication should be bypassed for clients whose ip resides within (at least) one of the subnets on the whitelist
	BypassAuthSubnetWhitelistEnabled *bool `json:"bypass_auth_subnet_whitelist_enabled,omitempty"`

	// BypassLocalAuth True if authentication challenge for loopback address (127.0.0.1) should be disabled
	BypassLocalAuth *bool `json:"bypass_local_auth,omitempty"`

	// CategoryChangedTmmEnabled True if torrent should be relocated when its Category's save path changes
	CategoryChangedTmmEnabled *bool `json:"category_changed_tmm_enabled,omitempty"`

	// CheckingMemoryUse Outstanding memory when checking torrents in MiB
	CheckingMemoryUse *int64 `json:"checking_memory_use,omitempty"`

	// CreateSubfolderEnabled True if a subfolder should be created when adding a torrent
	CreateSubfolderEnabled *bool `json:"create_subfolder_enabled,omitempty"`

	// CurrentInterfaceAddress IP Address to bind to. Empty String means All addresses
	CurrentInterfaceAddress *string `json:"current_interface_address,omitempty"`

	// CurrentNetworkInterface Network Interface used
	CurrentNetworkInterface *string `json:"current_network_interface,omitempty"`

	// Dht True if DHT is enabled
	Dht *bool `json:"dht,omitempty"`

	// DiskCache Disk cache used in MiB
	DiskCache *int64 `json:"disk_cache,omitempty"`

	// DiskCacheTtl Disk cache expiry interval in seconds
	DiskCacheTtl *int64 `json:"disk_cache_ttl,omitempty"`

	// DlLimit Global download speed limit in KiB/s; `-1` means no limit is applied
	DlLimit *int64 `json:"dl_limit,omitempty"`

	// DontCountSlowTorrents If true torrents w/o any activity (stalled ones) will not be counted towards `max_active_*` limits; see [dont_count_slow_torrents](https://www.libtorrent.org/reference-Settings.html#dont_count_slow_torrents) for more information
	DontCountSlowTorrents *bool `json:"dont_count_slow_torrents,omitempty"`

	// DyndnsDomain Your DDNS domain name
	DyndnsDomain *string `json:"dyndns_domain,omitempty"`

	// DyndnsEnabled True if server DNS should be updated dynamically
	DyndnsEnabled *bool `json:"dyndns_enabled,omitempty"`

	// DyndnsPassword Password for DDNS service
	DyndnsPassword *string `json:"dyndns_password,omitempty"`

	// DyndnsService See list of possible values here below
	//
	// | Value | Description |
	// | ----- | ----------- |
	// | 0     | Use DyDNS   |
	// | 1     | Use NOIP    |
	DyndnsService *SetPreferencesDyndnsService `json:"dyndns_service,omitempty"`

	// DyndnsUsername Username for DDNS service
	DyndnsUsername *string `json:"dyndns_username,omitempty"`

	// EmbeddedTrackerPort Port used for embedded tracker
	EmbeddedTrackerPort *int32 `json:"embedded_tracker_port,omitempty"`

	// EnableCoalesceReadWrite True enables coalesce reads & writes
	EnableCoalesceReadWrite *bool `json:"enable_coalesce_read_write,omitempty"`

	// EnableEmbeddedTracker True enables embedded tracker
	EnableEmbeddedTracker *bool `json:"enable_embedded_tracker,omitempty"`

	// EnableMultiConnectionsFromSameIp True allows multiple connections from the same IP address
	EnableMultiConnectionsFromSameIp *bool `json:"enable_multi_connections_from_same_ip,omitempty"`

	// EnableOsCache True enables os cache
	EnableOsCache *bool `json:"enable_os_cache,omitempty"`

	// EnablePieceExtentAffinity True if the advanced libtorrent option `piece_extent_affinity` is enabled
	EnablePieceExtentAffinity *bool `json:"enable_piece_extent_affinity,omitempty"`

	// EnableUploadSuggestions True enables sending of upload piece suggestions
	EnableUploadSuggestions *bool `json:"enable_upload_suggestions,omitempty"`

	// Encryption See list of possible values here below
	//
	// | Value | Description          |
	// | ----- | -------------------- |
	// | 0     | Prefer encryption    |
	// | 1     | Force encryption on  |
	// | 2     | Force encryption off |
	Encryption *SetPreferencesEncryption `json:"encryption,omitempty"`

	// ExportDir Path to directory to copy .torrent files to. Slashes are used as path separators
	ExportDir *string `json:"export_dir,omitempty"`

	// ExportDirFin Path to directory to copy .torrent files of completed downloads to. Slashes are used as path separators
	ExportDirFin *string `json:"export_dir_fin,omitempty"`

	// FilePoolSize File pool size
	FilePoolSize *int64 `json:"file_pool_size,omitempty"`

	// IncompleteFilesExt True if ".!qB" should be appended to incomplete files
	IncompleteFilesExt *bool `json:"incomplete_files_ext,omitempty"`

	// IpFilterEnabled True if external IP filter should be enabled
	IpFilterEnabled *bool `json:"ip_filter_enabled,omitempty"`

	// IpFilterPath Path to IP filter file (.dat, .p2p, .p2b files are supported); path is separated by slashes
	IpFilterPath *string `json:"ip_filter_path,omitempty"`

	// IpFilterTrackers True if IP filters are applied to trackers
	IpFilterTrackers *bool `json:"ip_filter_trackers,omitempty"`

	// LimitLanPeers True if `[du]l_limit` should be applied to peers on the LAN
	LimitLanPeers *bool `json:"limit_lan_peers,omitempty"`

	// LimitTcpOverhead True if `[du]l_limit` should be applied to estimated TCP overhead (service data: e.g. packet headers)
	LimitTcpOverhead *bool `json:"limit_tcp_overhead,omitempty"`

	// LimitUtpRate True if `[du]l_limit` should be applied to uTP connections; this option is only available in qBittorent built against libtorrent version 0.16.X and higher
	LimitUtpRate *bool `json:"limit_utp_rate,omitempty"`

	// ListenPort Port for incoming connections
	ListenPort *int32 `json:"listen_port,omitempty"`

	// Locale Currently selected language (e.g. en_GB for English)
	Locale *string `json:"locale,omitempty"`

	// Lsd True if LSD is enabled
	Lsd *bool `json:"lsd,omitempty"`

	// MailNotificationAuthEnabled True if smtp server requires authentication
	MailNotificationAuthEnabled *bool `json:"mail_notification_auth_enabled,omitempty"`

	// MailNotificationEmail e-mail to send notifications to
	MailNotificationEmail *string `json:"mail_notification_email,omitempty"`

	// MailNotificationEnabled True if e-mail notification should be enabled
	MailNotificationEnabled *bool `json:"mail_notification_enabled,omitempty"`

	// MailNotificationPassword Password for smtp authentication
	MailNotificationPassword *string `json:"mail_notification_password,omitempty"`

	// MailNotificationSender e-mail where notifications should originate from
	MailNotificationSender *string `json:"mail_notification_sender,omitempty"`

	// MailNotificationSmtp smtp server for e-mail notifications
	MailNotificationSmtp *string `json:"mail_notification_smtp,omitempty"`

	// MailNotificationSslEnabled True if smtp server requires SSL connection
	MailNotificationSslEnabled *bool `json:"mail_notification_ssl_enabled,omitempty"`

	// MailNotificationUsername Username for smtp authentication
	MailNotificationUsername *string `json:"mail_notification_username,omitempty"`

	// MaxActiveDownloads Maximum number of active simultaneous downloads
	MaxActiveDownloads *int64 `json:"max_active_downloads,omitempty"`

	// MaxActiveTorrents Maximum number of active simultaneous downloads and uploads
	MaxActiveTorrents *int64 `json:"max_active_torrents,omitempty"`

	// MaxActiveUploads Maximum number of active simultaneous uploads
	MaxActiveUploads *int64 `json:"max_active_uploads,omitempty"`

	// MaxConnec Maximum global number of simultaneous connections
	MaxConnec *int64 `json:"max_connec,omitempty"`

	// MaxConnecPerTorrent Maximum number of simultaneous connections per torrent
	MaxConnecPerTorrent *int64 `json:"max_connec_per_torrent,omitempty"`

	// MaxRatio Get the global share ratio limit
	MaxRatio *float32 `json:"max_ratio,omitempty"`

	// MaxRatioAct Action performed when a torrent reaches the maximum share ratio. See list of possible values here below.
	//
	// | Value | Description    |
	// | ----- | -------------- |
	// | 0     | Pause torrent  |
	// | 1     | Remove torrent |
	MaxRatioAct *SetPreferencesMaxRatioAct `json:"max_ratio_act,omitempty"`

	// MaxRatioEnabled True if share ratio limit is enabled
	MaxRatioEnabled *bool `json:"max_ratio_enabled,omitempty"`

	// MaxSeedingTime Number of minutes to seed a torrent
	MaxSeedingTime *int64 `json:"max_seeding_time,omitempty"`

	// MaxSeedingTimeEnabled True enables max seeding time
	MaxSeedingTimeEnabled *bool `json:"max_seeding_time_enabled,omitempty"`

	// MaxUploads Maximum number of upload slots
	MaxUploads *int64 `json:"max_uploads,omitempty"`

	// MaxUploadsPerTorrent Maximum number of upload slots per torrent
	MaxUploadsPerTorrent *int64 `json:"max_uploads_per_torrent,omitempty"`

	// OutgoingPortsMax Maximal outgoing port (0: Disabled)
	OutgoingPortsMax *int32 `json:"outgoing_ports_max,omitempty"`

	// OutgoingPortsMin Minimal outgoing port (0: Disabled)
	OutgoingPortsMin *int32 `json:"outgoing_ports_min,omitempty"`

	// Pex True if PeX is enabled
	Pex *bool `json:"pex,omitempty"`

	// PreallocateAll True if disk space should be pre-allocated for all files
	PreallocateAll *bool `json:"preallocate_all,omitempty"`

	// ProxyAuthEnabled True proxy requires authentication; doesn't apply to SOCKS4 proxies
	ProxyAuthEnabled *bool `json:"proxy_auth_enabled,omitempty"`

	// ProxyIp Proxy IP address or domain name
	ProxyIp *string `json:"proxy_ip,omitempty"`

	// ProxyPassword Password for proxy authentication
	ProxyPassword *string `json:"proxy_password,omitempty"`

	// ProxyPeerConnections True if peer and web seed connections should be proxified; this option will have any effect only in qBittorent built against libtorrent version 0.16.X and higher
	ProxyPeerConnections *bool `json:"proxy_peer_connections,omitempty"`

	// ProxyPort Proxy port
	ProxyPort *int32 `json:"proxy_port,omitempty"`

	// ProxyTorrentsOnly True if proxy is only used for torrents
	ProxyTorrentsOnly *bool `json:"proxy_torrents_only,omitempty"`

	// ProxyType See list of possible values here below
	//
	// | Value | Description                         |
	// | ----- | ----------------------------------- |
	// | -1    | Proxy is disabled                   |
	// | 0     | Prefer encryption                   |
	// | 1     | HTTP proxy without authentication   |
	// | 2     | SOCKS5 proxy without authentication |
	// | 3     | HTTP proxy with authentication      |
	// | 4     | SOCKS5 proxy with authentication    |
	// | 5     | SOCKS4 proxy without authentication |
	ProxyType *SetPreferencesProxyType `json:"proxy_type,omitempty"`

	// ProxyUsername Username for proxy authentication
	ProxyUsername *string `json:"proxy_username,omitempty"`

	// QueueingEnabled True if torrent queuing is enabled
	QueueingEnabled *bool `json:"queueing_enabled,omitempty"`

	// RandomPort True if the port is randomly selected
	RandomPort *bool `json:"random_port,omitempty"`

	// RecheckCompletedTorrents True rechecks torrents on completion
	RecheckCompletedTorrents *bool `json:"recheck_completed_torrents,omitempty"`

	// ResolvePeerCountries True resolves peer countries
	ResolvePeerCountries *bool `json:"resolve_peer_countries,omitempty"`

	// RssAutoDownloadingEnabled Enable auto-downloading of torrents from the RSS feeds
	RssAutoDownloadingEnabled *bool `json:"rss_auto_downloading_enabled,omitempty"`

	// RssDownloadRepackProperEpisodes For API ≥ v2.5.1: Enable downloading of repack/proper Episodes
	RssDownloadRepackProperEpisodes *bool `json:"rss_download_repack_proper_episodes,omitempty"`

	// RssMaxArticlesPerFeed Max stored articles per RSS feed
	RssMaxArticlesPerFeed *int64 `json:"rss_max_articles_per_feed,omitempty"`

	// RssProcessingEnabled Enable processing of RSS feeds
	RssProcessingEnabled *bool `json:"rss_processing_enabled,omitempty"`

	// RssRefreshInterval RSS refresh interval
	RssRefreshInterval *int64 `json:"rss_refresh_interval,omitempty"`

	// RssSmartEpisodeFilters For API ≥ v2.5.1: List of RSS Smart Episode Filters
	RssSmartEpisodeFilters *string `json:"rss_smart_episode_filters,omitempty"`

	// SavePath Default save path for torrents, separated by slashes
	SavePath *string `json:"save_path,omitempty"`

	// SavePathChangedTmmEnabled True if torrent should be relocated when the default save path changes
	SavePathChangedTmmEnabled *bool `json:"save_path_changed_tmm_enabled,omitempty"`

	// SaveResumeDataInterval Save resume data interval in min
	SaveResumeDataInterval *int64 `json:"save_resume_data_interval,omitempty"`

	// ScanDirs Property: directory to watch for torrent files, value: where torrents loaded from this directory should be downloaded to (see list of possible values below). Slashes are used as path separators; multiple key/value pairs can be specified
	//
	// | Value                  | Description                       |
	// | ---------------------- | --------------------------------- |
	// | 0                      | Download to the monitored folder  |
	// | 1                      | Download to the default save path |
	// | "/path/to/download/to" | Download to this path             |
	ScanDirs *map[string]SetPreferences_ScanDirs_AdditionalProperties `json:"scan_dirs,omitempty"`

	// ScheduleFromHour Scheduler starting hour
	ScheduleFromHour *int32 `json:"schedule_from_hour,omitempty"`

	// ScheduleFromMin Scheduler starting minute
	ScheduleFromMin *int32 `json:"schedule_from_min,omitempty"`

	// ScheduleToHour Scheduler ending hour
	ScheduleToHour *int32 `json:"schedule_to_hour,omitempty"`

	// ScheduleToMin Scheduler ending minute
	ScheduleToMin *int32 `json:"schedule_to_min,omitempty"`

	// SchedulerDays Scheduler days. See possible values here below
	//
	// | Value | Description     |
	// | ----- | --------------- |
	// | 0     | Every day       |
	// | 1     | Every weekday   |
	// | 2     | Every weekend   |
	// | 3     | Every Monday    |
	// | 4     | Every Tuesday   |
	// | 5     | Every Wednesday |
	// | 6     | Every Thursday  |
	// | 7     | Every Friday    |
	// | 8     | Every Saturday  |
	// | 9     | Every Sunday    |
	SchedulerDays *SetPreferencesSchedulerDays `json:"scheduler_days,omitempty"`

	// SchedulerEnabled True if alternative limits should be applied according to schedule
	SchedulerEnabled *bool `json:"scheduler_enabled,omitempty"`

	// SendBufferLowWatermark Send buffer low watermark in KiB
	SendBufferLowWatermark *int64 `json:"send_buffer_low_watermark,omitempty"`

	// SendBufferWatermark Send buffer watermark in KiB
	SendBufferWatermark *int64 `json:"send_buffer_watermark,omitempty"`

	// SendBufferWatermarkFactor Send buffer watermark factor in percent
	SendBufferWatermarkFactor *int32 `json:"send_buffer_watermark_factor,omitempty"`

	// SlowTorrentDlRateThreshold Download rate in KiB/s for a torrent to be considered "slow"
	SlowTorrentDlRateThreshold *int64 `json:"slow_torrent_dl_rate_threshold,omitempty"`

	// SlowTorrentInactiveTimer Seconds a torrent should be inactive before considered "slow"
	SlowTorrentInactiveTimer *int64 `json:"slow_torrent_inactive_timer,omitempty"`

	// SlowTorrentUlRateThreshold Upload rate in KiB/s for a torrent to be considered "slow"
	SlowTorrentUlRateThreshold *int64 `json:"slow_torrent_ul_rate_threshold,omitempty"`

	// SocketBacklogSize Socket backlog size
	SocketBacklogSize *int64 `json:"socket_backlog_size,omitempty"`

	// SslCert For API < v2.0.1: SSL certificate contents (this is a not a path)
	SslCert *string `json:"ssl_cert,omitempty"`

	// SslKey For API < v2.0.1: SSL keyfile contents (this is a not a path)
	SslKey *string `json:"ssl_key,omitempty"`

	// StartPausedEnabled True if torrents should be added in a Paused state
	StartPausedEnabled *bool `json:"start_paused_enabled,omitempty"`

	// StopTrackerTimeout Timeout in seconds for a `stopped` announce request to trackers
	StopTrackerTimeout *int64 `json:"stop_tracker_timeout,omitempty"`

	// TempPath Path for incomplete torrents, separated by slashes
	TempPath *string `json:"temp_path,omitempty"`

	// TempPathEnabled True if folder for incomplete torrents is enabled
	TempPathEnabled *bool `json:"temp_path_enabled,omitempty"`

	// TorrentChangedTmmEnabled True if torrent should be relocated when its Category changes
	TorrentChangedTmmEnabled *bool `json:"torrent_changed_tmm_enabled,omitempty"`

	// UpLimit Global upload speed limit in KiB/s; `-1` means no limit is applied
	UpLimit *int64 `json:"up_limit,omitempty"`

	// UploadChokingAlgorithm Upload choking algorithm used (see list of possible values below)
	//
	// | Value | Description    |
	// | ----- | -------------- |
	// | 0     | Round-robin    |
	// | 1     | Fastest upload |
	// | 2     | Anti-leech     |
	UploadChokingAlgorithm *SetPreferencesUploadChokingAlgorithm `json:"upload_choking_algorithm,omitempty"`

	// UploadSlotsBehavior Upload slots behavior used (see list of possible values below)
	//
	// | Value | Description       |
	// | ----- | ----------------- |
	// | 0     | Fixed slots       |
	// | 1     | Upload rate based |
	UploadSlotsBehavior *SetPreferencesUploadSlotsBehavior `json:"upload_slots_behavior,omitempty"`

	// Upnp True if UPnP/NAT-PMP is enabled
	Upnp *bool `json:"upnp,omitempty"`

	// UpnpLeaseDuration UPnP lease duration (0: Permanent lease)
	UpnpLeaseDuration *int64 `json:"upnp_lease_duration,omitempty"`

	// UseHttps True if WebUI HTTPS access is enabled
	UseHttps *bool `json:"use_https,omitempty"`

	// UtpTcpMixedMode μTP-TCP mixed mode algorithm (see list of possible values below)
	//
	// | Value | Description       |
	// | ----- | ----------------- |
	// | 0     | Prefer TCP        |
	// | 1     | Peer proportional |
	UtpTcpMixedMode *SetPreferencesUtpTcpMixedMode `json:"utp_tcp_mixed_mode,omitempty"`

	// WebUiAddress IP address to use for the WebUI
	WebUiAddress *string `json:"web_ui_address,omitempty"`

	// WebUiBanDuration WebUI access ban duration in seconds
	WebUiBanDuration *int64 `json:"web_ui_ban_duration,omitempty"`

	// WebUiClickjackingProtectionEnabled True if WebUI clickjacking protection is enabled
	WebUiClickjackingProtectionEnabled *bool `json:"web_ui_clickjacking_protection_enabled,omitempty"`

	// WebUiCsrfProtectionEnabled True if WebUI CSRF protection is enabled
	WebUiCsrfProtectionEnabled *bool `json:"web_ui_csrf_protection_enabled,omitempty"`

	// WebUiCustomHttpHeaders For API ≥ v2.5.1: List of custom http headers
	WebUiCustomHttpHeaders *string `json:"web_ui_custom_http_headers,omitempty"`

	// WebUiDomainList Comma-separated list of domains to accept when performing Host header validation
	WebUiDomainList *[]string `json:"web_ui_domain_list,omitempty"`

	// WebUiHostHeaderValidationEnabled True if WebUI host header validation is enabled
	WebUiHostHeaderValidationEnabled *bool `json:"web_ui_host_header_validation_enabled,omitempty"`

	// WebUiHttpsCertPath For API ≥ v2.0.1: Path to SSL certificate
	WebUiHttpsCertPath *string `json:"web_ui_https_cert_path,omitempty"`

	// WebUiHttpsKeyPath For API ≥ v2.0.1: Path to SSL keyfile
	WebUiHttpsKeyPath *string `json:"web_ui_https_key_path,omitempty"`

	// WebUiMaxAuthFailCount Maximum number of authentication failures before WebUI access ban
	WebUiMaxAuthFailCount *int64 `json:"web_ui_max_auth_fail_count,omitempty"`

	// WebUiPassword For API ≥ v2.3.0: Plaintext WebUI password, not readable, write-only. For API < v2.3.0: MD5 hash of WebUI password, hash is generated from the following string: `username:Web UI Access:plain_text_web_ui_password`
	WebUiPassword *string `json:"web_ui_password,omitempty"`

	// WebUiPort WebUI port
	WebUiPort *int32 `json:"web_ui_port,omitempty"`

	// WebUiSecureCookieEnabled True if WebUI cookie `Secure` flag is enabled
	WebUiSecureCookieEnabled *bool `json:"web_ui_secure_cookie_enabled,omitempty"`

	// WebUiSessionTimeout Seconds until WebUI is automatically signed off
	WebUiSessionTimeout *int64 `json:"web_ui_session_timeout,omitempty"`

	// WebUiUpnp True if UPnP is used for the WebUI port
	WebUiUpnp *bool `json:"web_ui_upnp,omitempty"`

	// WebUiUseCustomHttpHeadersEnabled For API ≥ v2.5.1: Enable custom http headers
	WebUiUseCustomHttpHeadersEnabled *bool `json:"web_ui_use_custom_http_headers_enabled,omitempty"`

	// WebUiUsername WebUI username
	WebUiUsername        *string                `json:"web_ui_username,omitempty"`
	AdditionalProperties map[string]interface{} `json:"-"`
}

// SetPreferencesBittorrentProtocol Bittorrent Protocol to use (see list of possible values below)
//
// | Value | Description |
// | ----- | ----------- |
// | 0     | TCP and μTP |
// | 1     | TCP         |
// | 2     | μTP         |
type SetPreferencesBittorrentProtocol int32

// SetPreferencesDyndnsService See list of possible values here below
//
// | Value | Description |
// | ----- | ----------- |
// | 0     | Use DyDNS   |
// | 1     | Use NOIP    |
type SetPreferencesDyndnsService int32

// SetPreferencesEncryption See list of possible values here below
//
// | Value | Description          |
// | ----- | -------------------- |
// | 0     | Prefer encryption    |
// | 1     | Force encryption on  |
// | 2     | Force encryption off |
type SetPreferencesEncryption int32

// SetPreferencesMaxRatioAct Action performed when a torrent reaches the maximum share ratio. See list of possible values here below.
//
// | Value | Description    |
// | ----- | -------------- |
// | 0     | Pause torrent  |
// | 1     | Remove torrent |
type SetPreferencesMaxRatioAct int64

// SetPreferencesProxyType See list of possible values here below
//
// | Value | Description                         |
// | ----- | ----------------------------------- |
// | -1    | Proxy is disabled                   |
// | 0     | Prefer encryption                   |
// | 1     | HTTP proxy without authentication   |
// | 2     | SOCKS5 proxy without authentication |
// | 3     | HTTP proxy with authentication      |
// | 4     | SOCKS5 proxy with authentication    |
// | 5     | SOCKS4 proxy without authentication |
type SetPreferencesProxyType int32

// SetPreferencesScanDirs0 defines model for SetPreferences.ScanDirs.0.
type SetPreferencesScanDirs0 int

// SetPreferencesScanDirs1 defines model for .
type SetPreferencesScanDirs1 = string

// SetPreferences_ScanDirs_AdditionalProperties defines model for SetPreferences.scan_dirs.AdditionalProperties.
type SetPreferences_ScanDirs_AdditionalProperties struct {
	union json.RawMessage
}

// SetPreferencesSchedulerDays Scheduler days. See possible values here below
//
// | Value | Description     |
// | ----- | --------------- |
// | 0     | Every day       |
// | 1     | Every weekday   |
// | 2     | Every weekend   |
// | 3     | Every Monday    |
// | 4     | Every Tuesday   |
// | 5     | Every Wednesday |
// | 6     | Every Thursday  |
// | 7     | Every Friday    |
// | 8     | Every Saturday  |
// | 9     | Every Sunday    |
type SetPreferencesSchedulerDays int32

// SetPreferencesUploadChokingAlgorithm Upload choking algorithm used (see list of possible values below)
//
// | Value | Description    |
// | ----- | -------------- |
// | 0     | Round-robin    |
// | 1     | Fastest upload |
// | 2     | Anti-leech     |
type SetPreferencesUploadChokingAlgorithm int32

// SetPreferencesUploadSlotsBehavior Upload slots behavior used (see list of possible values below)
//
// | Value | Description       |
// | ----- | ----------------- |
// | 0     | Fixed slots       |
// | 1     | Upload rate based |
type SetPreferencesUploadSlotsBehavior int32

// SetPreferencesUtpTcpMixedMode μTP-TCP mixed mode algorithm (see list of possible values below)
//
// | Value | Description       |
// | ----- | ----------------- |
// | 0     | Prefer TCP        |
// | 1     | Peer proportional |
type SetPreferencesUtpTcpMixedMode int32

// SetTorrentsLimit defines model for SetTorrentsLimit.
type SetTorrentsLimit struct {
	Hashes []string `json:"hashes"`
	Limit  *int64   `json:"limit,omitempty"`
}

// SetTorrentsValue defines model for SetTorrentsValue.
type SetTorrentsValue struct {
	Hashes []string `json:"hashes"`

	// Value `value` is a boolean, affects the torrents listed in `hashes`, default is `false`
	Value *bool `json:"value,omitempty"`
}

// TorrentInfo defines model for TorrentInfo.
type TorrentInfo struct {
	// AddedOn Time (Unix Epoch) when the torrent was added to the client
	AddedOn *int64 `json:"added_on,omitempty"`

	// AmountLeft Amount of data left to download (bytes)
	AmountLeft *int64 `json:"amount_left,omitempty"`

	// AutoTmm Whether this torrent is managed by Automatic Torrent Management
	AutoTmm *bool `json:"auto_tmm,omitempty"`

	// Availability Percentage of file pieces currently available
	Availability *float32 `json:"availability,omitempty"`

	// Category Category of the torrent
	Category *string `json:"category,omitempty"`

	// Completed Amount of transfer data completed (bytes)
	Completed *int64 `json:"completed,omitempty"`

	// CompletionOn Time (Unix Epoch) when the torrent completed
	CompletionOn *int64 `json:"completion_on,omitempty"`

	// ContentPath Absolute path of torrent content (root path for multifile torrents, absolute file path for singlefile torrents)
	ContentPath *string `json:"content_path,omitempty"`

	// DlLimit Torrent download speed limit (bytes/s). `-1` if ulimited.
	DlLimit *int64 `json:"dl_limit,omitempty"`

	// Dlspeed Torrent download speed (bytes/s)
	Dlspeed *int64 `json:"dlspeed,omitempty"`

	// Downloaded Amount of data downloaded
	Downloaded *int64 `json:"downloaded,omitempty"`

	// DownloadedSession Amount of data downloaded this session
	DownloadedSession *int64 `json:"downloaded_session,omitempty"`

	// Eta Torrent ETA (seconds)
	Eta *int64 `json:"eta,omitempty"`

	// FLPiecePrio True if first last piece are prioritized
	FLPiecePrio *bool `json:"f_l_piece_prio,omitempty"`

	// ForceStart True if force start is enabled for this torrent
	ForceStart *bool `json:"force_start,omitempty"`

	// Hash Torrent hash
	Hash *string `json:"hash,omitempty"`

	// LastActivity Last time (Unix Epoch) when a chunk was downloaded/uploaded
	LastActivity *int64 `json:"last_activity,omitempty"`

	// MagnetUri Magnet URI corresponding to this torrent
	MagnetUri *string `json:"magnet_uri,omitempty"`

	// MaxRatio Maximum share ratio until torrent is stopped from seeding/uploading
	MaxRatio *float32 `json:"max_ratio,omitempty"`

	// MaxSeedingTime Maximum seeding time (seconds) until torrent is stopped from seeding
	MaxSeedingTime *int64 `json:"max_seeding_time,omitempty"`

	// Name Torrent name
	Name *string `json:"name,omitempty"`

	// NumComplete Number of seeds in the swarm
	NumComplete *int64 `json:"num_complete,omitempty"`

	// NumIncomplete Number of leechers in the swarm
	NumIncomplete *int64 `json:"num_incomplete,omitempty"`

	// NumLeechs Number of leechers connected to
	NumLeechs *int64 `json:"num_leechs,omitempty"`

	// NumSeeds Number of seeds connected to
	NumSeeds *int64 `json:"num_seeds,omitempty"`

	// Priority Torrent priority. Returns -1 if queuing is disabled or torrent is in seed mode
	Priority *int64 `json:"priority,omitempty"`

	// Progress Torrent progress (percentage/100)
	Progress *float32 `json:"progress,omitempty"`

	// Ratio Torrent share ratio. Max ratio value: 9999.
	Ratio *float32 `json:"ratio,omitempty"`

	// RatioLimit TODO (what is different from max_ratio?)
	RatioLimit *float32 `json:"ratio_limit,omitempty"`

	// SavePath Path where this torrent's data is stored
	SavePath *string `json:"save_path,omitempty"`

	// SeedingTime Torrent elapsed time while complete (seconds)
	SeedingTime *int64 `json:"seeding_time,omitempty"`

	// SeedingTimeLimit TODO (what is different from `max_seeding_time`?) seeding_time_limit is a per torrent setting, when Automatic Torrent Management is disabled, furthermore then max_seeding_time is set to seeding_time_limit for this torrent. If Automatic Torrent Management is enabled, the value is -2. And if max_seeding_time is unset it have a default value -1.
	SeedingTimeLimit *int64 `json:"seeding_time_limit,omitempty"`

	// SeenComplete Time (Unix Epoch) when this torrent was last seen complete
	SeenComplete *int64 `json:"seen_complete,omitempty"`

	// SeqDl True if sequential download is enabled
	SeqDl *bool `json:"seq_dl,omitempty"`

	// Size Total size (bytes) of files selected for download
	Size *int64 `json:"size,omitempty"`

	// State Torrent state. See table here below for the possible values
	//
	// | Value              | Description                                                   |
	// | ------------------ | ------------------------------------------------------------- |
	// | error              | Some error occurred, applies to paused torrents               |
	// | missingFiles       | Torrent data files is missing                                 |
	// | uploading          | Torrent is being seeded and data is being transferred         |
	// | pausedUP           | Torrent is paused and has finished downloading                |
	// | queuedUP           | Queuing is enabled and torrent is queued for upload           |
	// | stalledUP          | Torrent is being seeded, but no connection were made          |
	// | checkingUP         | Torrent has finished downloading and is being checked         |
	// | forcedUP           | Torrent is forced to uploading and ignore queue limit         |
	// | allocating         | Torrent is allocating disk space for download                 |
	// | downloading        | Torrent is being downloaded and data is being transferred     |
	// | metaDL             | Torrent has just started downloading and is fetching metadata |
	// | pausedDL           | Torrent is paused and has NOT finished downloading            |
	// | queuedDL           | Queuing is enabled and torrent is queued for download         |
	// | stalledDL          | Torrent is being downloaded, but no connection were made      |
	// | checkingDL         | Same as checkingUP, but torrent has NOT finished downloading  |
	// | forcedDL           | Torrent is forced to downloading to ignore queue limit        |
	// | checkingResumeData | Checking resume data on qBt startup                           |
	// | moving             | Torrent is moving to another location                         |
	// | unknown            | Unknown status                                                |
	State *TorrentInfoState `json:"state,omitempty"`

	// SuperSeeding True if super seeding is enabled
	SuperSeeding *bool `json:"super_seeding,omitempty"`

	// Tags Comma-concatenated tag list of the torrent
	Tags *string `json:"tags,omitempty"`

	// TimeActive Total active time (seconds)
	TimeActive *int64 `json:"time_active,omitempty"`

	// TotalSize Total size (bytes) of all file in this torrent (including unselected ones)
	TotalSize *int64 `json:"total_size,omitempty"`

	// Tracker The first tracker with working status. Returns empty string if no tracker is working.
	Tracker *string `json:"tracker,omitempty"`

	// UpLimit Torrent upload speed limit (bytes/s). `-1` if ulimited.
	UpLimit *int64 `json:"up_limit,omitempty"`

	// Uploaded Amount of data uploaded
	Uploaded *int64 `json:"uploaded,omitempty"`

	// UploadedSession Amount of data uploaded this session
	UploadedSession *int64 `json:"uploaded_session,omitempty"`

	// Upspeed Torrent upload speed (bytes/s)
	Upspeed *int64 `json:"upspeed,omitempty"`
}

// TorrentInfoState Torrent state. See table here below for the possible values
//
// | Value              | Description                                                   |
// | ------------------ | ------------------------------------------------------------- |
// | error              | Some error occurred, applies to paused torrents               |
// | missingFiles       | Torrent data files is missing                                 |
// | uploading          | Torrent is being seeded and data is being transferred         |
// | pausedUP           | Torrent is paused and has finished downloading                |
// | queuedUP           | Queuing is enabled and torrent is queued for upload           |
// | stalledUP          | Torrent is being seeded, but no connection were made          |
// | checkingUP         | Torrent has finished downloading and is being checked         |
// | forcedUP           | Torrent is forced to uploading and ignore queue limit         |
// | allocating         | Torrent is allocating disk space for download                 |
// | downloading        | Torrent is being downloaded and data is being transferred     |
// | metaDL             | Torrent has just started downloading and is fetching metadata |
// | pausedDL           | Torrent is paused and has NOT finished downloading            |
// | queuedDL           | Queuing is enabled and torrent is queued for download         |
// | stalledDL          | Torrent is being downloaded, but no connection were made      |
// | checkingDL         | Same as checkingUP, but torrent has NOT finished downloading  |
// | forcedDL           | Torrent is forced to downloading to ignore queue limit        |
// | checkingResumeData | Checking resume data on qBt startup                           |
// | moving             | Torrent is moving to another location                         |
// | unknown            | Unknown status                                                |
type TorrentInfoState string

// TorrentPeers The response is TODO
type TorrentPeers = map[string]interface{}

// TorrentsCategory defines model for TorrentsCategory.
type TorrentsCategory struct {
	Name     *string `json:"name,omitempty"`
	SavePath *string `json:"savePath,omitempty"`
}

// TorrentsFiles defines model for TorrentsFiles.
type TorrentsFiles struct {
	// Availability Percentage of file pieces currently available (percentage/100)
	Availability *float32 `json:"availability,omitempty"`

	// Index File index
	Index *int64 `json:"index,omitempty"`

	// IsSeed True if file is seeding/complete
	IsSeed *bool `json:"is_seed,omitempty"`

	// Name File name (including relative path)
	Name *string `json:"name,omitempty"`

	// PieceRange The first number is the starting piece index and the second number is the ending piece index (inclusive)
	PieceRange *[]int64 `json:"piece_range,omitempty"`

	// Priority File priority. See possible values here below
	//
	// | Value | Description      |
	// | ----- | ---------------- |
	// | 0     | Do not download  |
	// | 1     | Normal priority  |
	// | 6     | High priority    |
	// | 7     | Maximal priority |
	Priority *TorrentsFilesPriority `json:"priority,omitempty"`

	// Progress File progress (percentage/100)
	Progress *float32 `json:"progress,omitempty"`

	// Size File size (bytes)
	Size *int64 `json:"size,omitempty"`
}

// TorrentsFilesPriority File priority. See possible values here below
//
// | Value | Description      |
// | ----- | ---------------- |
// | 0     | Do not download  |
// | 1     | Normal priority  |
// | 6     | High priority    |
// | 7     | Maximal priority |
type TorrentsFilesPriority int64

// TorrentsLimit defines model for TorrentsLimit.
type TorrentsLimit map[string]int64

// TorrentsProperties The response is:
// - empty, if the torrent hash is invalid
// - otherwise, a JSON object with the following fields
//
// NB: `-1` is returned if the type of the property is integer but its value is not known.
type TorrentsProperties struct {
	// AdditionDate When this torrent was added (unix timestamp)
	AdditionDate *int64 `json:"addition_date,omitempty"`

	// Comment Torrent comment
	Comment *string `json:"comment,omitempty"`

	// CompletionDate Torrent completion date (unix timestamp)
	CompletionDate *int64 `json:"completion_date,omitempty"`

	// CreatedBy Torrent creator
	CreatedBy *string `json:"created_by,omitempty"`

	// CreationDate Torrent creation date (Unix timestamp)
	CreationDate *int64 `json:"creation_date,omitempty"`

	// DlLimit Torrent download limit (bytes/s)
	DlLimit *int64 `json:"dl_limit,omitempty"`

	// DlSpeed Torrent download speed (bytes/second)
	DlSpeed *int64 `json:"dl_speed,omitempty"`

	// DlSpeedAvg Torrent average download speed (bytes/second)
	DlSpeedAvg *int64 `json:"dl_speed_avg,omitempty"`

	// Eta Torrent ETA (seconds)
	Eta *int64 `json:"eta,omitempty"`

	// LastSeen Last seen complete date (unix timestamp)
	LastSeen *int64 `json:"last_seen,omitempty"`

	// NbConnections Torrent connection count
	NbConnections *int64 `json:"nb_connections,omitempty"`

	// NbConnectionsLimit Torrent connection count limit
	NbConnectionsLimit *int64 `json:"nb_connections_limit,omitempty"`

	// Peers Number of peers connected to
	Peers *int64 `json:"peers,omitempty"`

	// PeersTotal Number of peers in the swarm
	PeersTotal *int64 `json:"peers_total,omitempty"`

	// PieceSize Torrent piece size (bytes)
	PieceSize *int64 `json:"piece_size,omitempty"`

	// PiecesHave Number of pieces owned
	PiecesHave *int64 `json:"pieces_have,omitempty"`

	// PiecesNum Number of pieces of the torrent
	PiecesNum *int64 `json:"pieces_num,omitempty"`

	// Reannounce Number of seconds until the next announce
	Reannounce *int64 `json:"reannounce,omitempty"`

	// SavePath Torrent save path
	SavePath *string `json:"save_path,omitempty"`

	// SeedingTime Torrent elapsed time while complete (seconds)
	SeedingTime *int64 `json:"seeding_time,omitempty"`

	// Seeds Number of seeds connected to
	Seeds *int64 `json:"seeds,omitempty"`

	// SeedsTotal Number of seeds in the swarm
	SeedsTotal *int64 `json:"seeds_total,omitempty"`

	// ShareRatio Torrent share ratio
	ShareRatio *float32 `json:"share_ratio,omitempty"`

	// TimeElapsed Torrent elapsed time (seconds)
	TimeElapsed *int64 `json:"time_elapsed,omitempty"`

	// TotalDownloaded Total data downloaded for torrent (bytes)
	TotalDownloaded *int64 `json:"total_downloaded,omitempty"`

	// TotalDownloadedSession Total data downloaded this session (bytes)
	TotalDownloadedSession *int64 `json:"total_downloaded_session,omitempty"`

	// TotalSize Torrent total size (bytes)
	TotalSize *int64 `json:"total_size,omitempty"`

	// TotalUploaded Total data uploaded for torrent (bytes)
	TotalUploaded *int64 `json:"total_uploaded,omitempty"`

	// TotalUploadedSession Total data uploaded this session (bytes)
	TotalUploadedSession *int64 `json:"total_uploaded_session,omitempty"`

	// TotalWasted Total data wasted for torrent (bytes)
	TotalWasted *int64 `json:"total_wasted,omitempty"`

	// UpLimit Torrent upload limit (bytes/s)
	UpLimit *int64 `json:"up_limit,omitempty"`

	// UpSpeed Torrent upload speed (bytes/second)
	UpSpeed *int64 `json:"up_speed,omitempty"`

	// UpSpeedAvg Torrent average upload speed (bytes/second)
	UpSpeedAvg *int64 `json:"up_speed_avg,omitempty"`
}

// TorrentsTags defines model for TorrentsTags.
type TorrentsTags struct {
	Hashes []string  `json:"hashes"`
	Tags   *[]string `json:"tags,omitempty"`
}

// TorrentsTrackers defines model for TorrentsTrackers.
type TorrentsTrackers struct {
	// Msg Tracker message (there is no way of knowing what this message is - it's up to tracker admins)
	Msg *string `json:"msg,omitempty"`

	// NumDownloaded Number of completed downlods for current torrent, as reported by the tracker
	NumDownloaded *int64 `json:"num_downloaded,omitempty"`

	// NumLeeches Number of leeches for current torrent, as reported by the tracker
	NumLeeches *int64 `json:"num_leeches,omitempty"`

	// NumPeers Number of peers for current torrent, as reported by the tracker
	NumPeers *int64 `json:"num_peers,omitempty"`

	// NumSeeds Number of seeds for current torrent, asreported by the tracker
	NumSeeds *int64 `json:"num_seeds,omitempty"`

	// Status Tracker status. See the table below for possible values
	//
	// | Value | Description                                                                        |
	// | ----- | ---------------------------------------------------------------------------------- |
	// | 0     | Tracker is disabled (used for DHT, PeX, and LSD)                                   |
	// | 1     | Tracker has not been contacted yet                                                 |
	// | 2     | Tracker has been contacted and is working                                          |
	// | 3     | Tracker is updating                                                                |
	// | 4     | Tracker has been contacted, but it is not working (or doesn't send proper replies) |
	Status *TorrentsTrackersStatus `json:"status,omitempty"`

	// Tier Tracker priority tier. Lower tier trackers are tried before higher tiers. Tier numbers are valid when `>= 0`, `< 0` is used as placeholder when `tier` does not exist for special entries (such as DHT).
	Tier *int64 `json:"tier,omitempty"`

	// Url Tracker url
	Url *string `json:"url,omitempty"`
}

// TorrentsTrackersStatus Tracker status. See the table below for possible values
//
// | Value | Description                                                                        |
// | ----- | ---------------------------------------------------------------------------------- |
// | 0     | Tracker is disabled (used for DHT, PeX, and LSD)                                   |
// | 1     | Tracker has not been contacted yet                                                 |
// | 2     | Tracker has been contacted and is working                                          |
// | 3     | Tracker is updating                                                                |
// | 4     | Tracker has been contacted, but it is not working (or doesn't send proper replies) |
type TorrentsTrackersStatus int32

// TorrentsWebseeds defines model for TorrentsWebseeds.
type TorrentsWebseeds struct {
	// Url URL of the web seed
	Url *string `json:"url,omitempty"`
}

// TransferInfo The response is a JSON object with the following fields
//
// In addition to the above in partial data requests (see [Get partial data](https://github.com/qbittorrent/qBittorrent/wiki/WebUI-API-(qBittorrent-4.1)#get-partial-data) for more info):
type TransferInfo struct {
	// ConnectionStatus Connection status. See possible values here below
	//
	// Possible values of connection_status:
	// | Value        |
	// | ------------ |
	// | connected    |
	// | firewalled   |
	// | disconnected |
	ConnectionStatus *string `json:"connection_status,omitempty"`

	// DhtNodes DHT nodes connected to
	DhtNodes *int64 `json:"dht_nodes,omitempty"`

	// DlInfoData Data downloaded this session (bytes)
	DlInfoData *int64 `json:"dl_info_data,omitempty"`

	// DlInfoSpeed Global download rate (bytes/s)
	DlInfoSpeed *int64 `json:"dl_info_speed,omitempty"`

	// DlRateLimit Download rate limit (bytes/s)
	DlRateLimit *int64 `json:"dl_rate_limit,omitempty"`

	// Queueing True if torrent queueing is enabled
	Queueing *bool `json:"queueing,omitempty"`

	// RefreshInterval Transfer list refresh interval (milliseconds)
	RefreshInterval *int64 `json:"refresh_interval,omitempty"`

	// UpInfoData Data uploaded this session (bytes)
	UpInfoData *int64 `json:"up_info_data,omitempty"`

	// UpInfoSpeed Global upload rate (bytes/s)
	UpInfoSpeed *int64 `json:"up_info_speed,omitempty"`

	// UpRateLimit Upload rate limit (bytes/s)
	UpRateLimit *int64 `json:"up_rate_limit,omitempty"`

	// UseAltSpeedLimits True if alternative speed limits are enabled
	UseAltSpeedLimits *bool `json:"use_alt_speed_limits,omitempty"`
}

// AppSetPreferencesPostFormdataBody defines parameters for AppSetPreferencesPost.
type AppSetPreferencesPostFormdataBody struct {
	// Json A json object with key-value pairs of the settings you want to change and their new values.
	Json SetPreferences `form:"json" json:"json"`
}

// AuthLoginPostFormdataBody defines parameters for AuthLoginPost.
type AuthLoginPostFormdataBody struct {
	Password string `form:"password" json:"password"`
	Username string `form:"username" json:"username"`
}

// AuthLoginPostParams defines parameters for AuthLoginPost.
type AuthLoginPostParams struct {
	Referer *string `json:"Referer,omitempty"`
	Origin  *string `json:"Origin,omitempty"`
}

// LogMainPostFormdataBody defines parameters for LogMainPost.
type LogMainPostFormdataBody struct {
	// Critical Include critical messages (default: `true`)
	Critical bool `form:"critical" json:"critical"`

	// Info Include info messages (default: `true`)
	Info bool `form:"info" json:"info"`

	// LastKnownId Exclude messages with "message id" <= `last_known_id` (default: `-1`)
	LastKnownId int64 `form:"last_known_id" json:"last_known_id"`

	// Normal Include normal messages (default: `true`)
	Normal bool `form:"normal" json:"normal"`

	// Warning Include warning messages (default: `true`)
	Warning bool `form:"warning" json:"warning"`
}

// LogPeersPostFormdataBody defines parameters for LogPeersPost.
type LogPeersPostFormdataBody struct {
	// LastKnownId Exclude messages with "message id" <= `last_known_id` (default: `-1`)
	LastKnownId int64 `form:"last_known_id" json:"last_known_id"`
}

// RssAddFeedPostFormdataBody defines parameters for RssAddFeedPost.
type RssAddFeedPostFormdataBody struct {
	// Path Full path of added folder (e.g. "The Pirate Bay\Top100\Video")
	Path *string `form:"path,omitempty" json:"path,omitempty"`

	// Url URL of RSS feed (e.g. "http://thepiratebay.org/rss//top100/200")
	Url string `form:"url" json:"url"`
}

// RssAddFolderPostFormdataBody defines parameters for RssAddFolderPost.
type RssAddFolderPostFormdataBody struct {
	// Path Full path of added folder (e.g. "The Pirate Bay\Top100")
	Path string `form:"path" json:"path"`
}

// RssItemsPostFormdataBody defines parameters for RssItemsPost.
type RssItemsPostFormdataBody struct {
	// WithData True if you need current feed articles
	WithData *bool `form:"withData,omitempty" json:"withData,omitempty"`
}

// RssMarkAsReadPostFormdataBody defines parameters for RssMarkAsReadPost.
type RssMarkAsReadPostFormdataBody struct {
	// ArticleId ID of article
	ArticleId *string `form:"articleId,omitempty" json:"articleId,omitempty"`

	// ItemPath Current full path of item (e.g. "The Pirate Bay\Top100")
	ItemPath string `form:"itemPath" json:"itemPath"`
}

// RssMatchingArticlesPostFormdataBody defines parameters for RssMatchingArticlesPost.
type RssMatchingArticlesPostFormdataBody struct {
	// RuleName Rule name (e.g. "Linux")
	RuleName string `form:"ruleName" json:"ruleName"`
}

// RssMoveItemPostFormdataBody defines parameters for RssMoveItemPost.
type RssMoveItemPostFormdataBody struct {
	// DestPath New full path of item (e.g. "The Pirate Bay")
	DestPath string `form:"destPath" json:"destPath"`

	// ItemPath Current full path of item (e.g. "The Pirate Bay\Top100")
	ItemPath string `form:"itemPath" json:"itemPath"`
}

// RssRefreshItemPostFormdataBody defines parameters for RssRefreshItemPost.
type RssRefreshItemPostFormdataBody struct {
	// ItemPath Current full path of item (e.g. "The Pirate Bay\Top100")
	ItemPath string `form:"itemPath" json:"itemPath"`
}

// RssRemoveItemPostFormdataBody defines parameters for RssRemoveItemPost.
type RssRemoveItemPostFormdataBody struct {
	// Path Full path of removed item (e.g. "The Pirate Bay\Top100")
	Path string `form:"path" json:"path"`
}

// RssRemoveRulePostFormdataBody defines parameters for RssRemoveRulePost.
type RssRemoveRulePostFormdataBody struct {
	// RuleName Rule name (e.g. "Punisher")
	RuleName string `form:"ruleName" json:"ruleName"`
}

// RssRenameRulePostFormdataBody defines parameters for RssRenameRulePost.
type RssRenameRulePostFormdataBody struct {
	// NewRuleName New rule name (e.g. "The Punisher")
	NewRuleName string `form:"newRuleName" json:"newRuleName"`

	// RuleName Rule name (e.g. "Punisher")
	RuleName string `form:"ruleName" json:"ruleName"`
}

// RssSetRulePostFormdataBody defines parameters for RssSetRulePost.
type RssSetRulePostFormdataBody struct {
	// RuleDef JSON encoded rule definition
	//
	// Rule definition is JSON encoded dictionary with the following fields:
	// | Field                     | Type   | Description                                             |
	// | ------------------------- | ------ | ------------------------------------------------------- |
	// | enabled                   | bool   | Whether the rule is enabled                             |
	// | mustContain               | string | The substring that the torrent name must contain        |
	// | mustNotContain            | string | The substring that the torrent name must not contain    |
	// | useRegex                  | bool   | Enable regex mode in "mustContain" and "mustNotContain" |
	// | episodeFilter             | string | Episode filter definition                               |
	// | smartFilter               | bool   | Enable smart episode filter                             |
	// | previouslyMatchedEpisodes | list   | The list of episode IDs already matched by smart filter |
	// | affectedFeeds             | list   | The feed URLs the rule applied to                       |
	// | ignoreDays                | number | Ignore sunsequent rule matches                          |
	// | lastMatch                 | string | The rule last match time                                |
	// | addPaused                 | bool   | Add matched torrent in paused mode                      |
	// | assignedCategory          | string | Assign category to the torrent                          |
	// | savePath                  | string | Save torrent to the given directory                     |
	RuleDef RssRuleDef `form:"ruleDef" json:"ruleDef"`

	// RuleName Rule name (e.g. "Punisher")
	RuleName string `form:"ruleName" json:"ruleName"`
}

// SearchDeletePostFormdataBody defines parameters for SearchDeletePost.
type SearchDeletePostFormdataBody struct {
	// Id ID of the search job
	Id float32 `form:"id" json:"id"`
}

// SearchEnablePluginPostFormdataBody defines parameters for SearchEnablePluginPost.
type SearchEnablePluginPostFormdataBody struct {
	// Enable Whether the plugins should be enabled
	Enable bool `form:"enable" json:"enable"`

	// Names Name of the plugin to enable/disable (e.g. "legittorrents"). Supports multiple names separated by `|`
	Names []string `form:"names" json:"names"`
}

// SearchInstallPluginPostFormdataBody defines parameters for SearchInstallPluginPost.
type SearchInstallPluginPostFormdataBody struct {
	// Sources Url or file path of the plugin to install (e.g. "https://raw.githubusercontent.com/qbittorrent/search-plugins/master/nova3/engines/legittorrents.py"). Supports multiple sources separated by `|`
	Sources []string `form:"sources" json:"sources"`
}

// SearchResultsPostFormdataBody defines parameters for SearchResultsPost.
type SearchResultsPostFormdataBody struct {
	// Id ID of the search job
	Id *float32 `form:"id,omitempty" json:"id,omitempty"`

	// Limit max number of results to return. 0 or negative means no limit
	Limit *float32 `form:"limit,omitempty" json:"limit,omitempty"`

	// Offset result to start at. A negative number means count backwards (e.g. -2 returns the 2 most recent results)
	Offset *float32 `form:"offset,omitempty" json:"offset,omitempty"`
}

// SearchStartPostFormdataBody defines parameters for SearchStartPost.
type SearchStartPostFormdataBody struct {
	// Category Categories to limit your search to (e.g. "legittorrents"). Available categories depend on the specified `plugins`. Also supports `all`
	Category []string `form:"category" json:"category"`

	// Pattern Pattern to search for (e.g. "Ubuntu 18.04")
	Pattern string `form:"pattern" json:"pattern"`

	// Plugins Plugins to use for searching (e.g. "legittorrents"). Supports multiple plugins separated by `|`. Also supports `all` and `enabled`
	Plugins []string `form:"plugins" json:"plugins"`
}

// SearchStatusPostFormdataBody defines parameters for SearchStatusPost.
type SearchStatusPostFormdataBody struct {
	// Id ID of the search job. If not specified, all search jobs are returned
	Id *float32 `form:"id,omitempty" json:"id,omitempty"`
}

// SearchStopPostFormdataBody defines parameters for SearchStopPost.
type SearchStopPostFormdataBody = struct {
}

// SearchUninstallPluginPostFormdataBody defines parameters for SearchUninstallPluginPost.
type SearchUninstallPluginPostFormdataBody struct {
	// Names Name of the plugin to uninstall (e.g. "legittorrents"). Supports multiple names separated by `|`
	Names []string `form:"names" json:"names"`
}

// SyncMaindataPostFormdataBody defines parameters for SyncMaindataPost.
type SyncMaindataPostFormdataBody struct {
	// Rid Response ID. If not provided, `rid=0` will be assumed. If the given `rid` is different from the one of last server reply, `full_update` will be `true` (see the server reply details for more info)
	Rid *int64 `form:"rid,omitempty" json:"rid,omitempty"`
}

// SyncTorrentPeersPostFormdataBody defines parameters for SyncTorrentPeersPost.
type SyncTorrentPeersPostFormdataBody struct {
	// Hash Torrent hash
	Hash string `form:"hash" json:"hash"`

	// Rid Response ID. If not provided, `rid=0` will be assumed. If the given `rid` is different from the one of last server reply, `full_update` will be `true` (see the server reply details for more info)
	Rid *int64 `form:"rid,omitempty" json:"rid,omitempty"`
}

// TorrentsAddPostMultipartBody defines parameters for TorrentsAddPost.
type TorrentsAddPostMultipartBody struct {
	union json.RawMessage
}

// TorrentsAddPeersPostFormdataBody defines parameters for TorrentsAddPeersPost.
type TorrentsAddPeersPostFormdataBody struct {
	// Hashes The hash of the torrent, or multiple hashes separated by a pipe `|`
	Hashes []string `form:"hashes" json:"hashes"`

	// Peers The peer to add, or multiple peers separated by a pipe `|`. Each peer is a colon-separated `host:port`
	Peers []string `form:"peers" json:"peers"`
}

// TorrentsAddTrackersPostFormdataBody defines parameters for TorrentsAddTrackersPost.
type TorrentsAddTrackersPostFormdataBody struct {
	Hash string `form:"hash" json:"hash"`
	Urls string `form:"urls" json:"urls"`
}

// TorrentsCreateCategoryPostFormdataBody defines parameters for TorrentsCreateCategoryPost.
type TorrentsCreateCategoryPostFormdataBody = struct {
}

// TorrentsCreateTagsPostFormdataBody defines parameters for TorrentsCreateTagsPost.
type TorrentsCreateTagsPostFormdataBody struct {
	// Tags `tags` is a list of tags you want to create. Can contain multiple tags separated by `,`.
	Tags []string `form:"tags" json:"tags"`
}

// TorrentsDeletePostFormdataBody defines parameters for TorrentsDeletePost.
type TorrentsDeletePostFormdataBody struct {
	// DeleteFiles If set to `true`, the downloaded data will also be deleted, otherwise has no effect.
	DeleteFiles *bool    `form:"deleteFiles,omitempty" json:"deleteFiles,omitempty"`
	Hashes      []string `form:"hashes" json:"hashes"`
}

// TorrentsDeleteTagsPostFormdataBody defines parameters for TorrentsDeleteTagsPost.
type TorrentsDeleteTagsPostFormdataBody struct {
	// Tags `tags` is a list of tags you want to delete. Can contain multiple tags separated by `,`.
	Tags []string `form:"tags" json:"tags"`
}

// TorrentsEditCategoryPostFormdataBody defines parameters for TorrentsEditCategoryPost.
type TorrentsEditCategoryPostFormdataBody = struct {
}

// TorrentsEditTrackerPostFormdataBody defines parameters for TorrentsEditTrackerPost.
type TorrentsEditTrackerPostFormdataBody struct {
	// Hash The hash of the torrent
	Hash string `form:"hash" json:"hash"`

	// NewUrl The new URL to replace the `origUrl`
	NewUrl string `form:"newUrl" json:"newUrl"`

	// OrigUrl The tracker URL you want to edit
	OrigUrl string `form:"origUrl" json:"origUrl"`
}

// TorrentsFilePrioPostFormdataBody defines parameters for TorrentsFilePrioPost.
type TorrentsFilePrioPostFormdataBody struct {
	// Hash The hash of the torrent
	Hash string `form:"hash" json:"hash"`

	// Id File ids, separated by `|`
	Id []int64 `form:"id" json:"id"`

	// Priority File priority to set (consult [torrent contents API](https://github.com/qbittorrent/qBittorrent/wiki/WebUI-API-(qBittorrent-4.1)#get-torrent-contents) for possible values)
	Priority TorrentsFilePrioPostFormdataBodyPriority `form:"priority" json:"priority"`
}

// TorrentsFilePrioPostFormdataBodyPriority defines parameters for TorrentsFilePrioPost.
type TorrentsFilePrioPostFormdataBodyPriority int32

// TorrentsFilesPostFormdataBody defines parameters for TorrentsFilesPost.
type TorrentsFilesPostFormdataBody struct {
	// Hash The hash of the torrent you want to get the contents of
	Hash string `form:"hash" json:"hash"`

	// Indexes The indexes of the files you want to retrieve. `indexes` can contain multiple values separated by `|`.
	Indexes *[]string `form:"indexes,omitempty" json:"indexes,omitempty"`
}

// TorrentsInfoPostFormdataBody defines parameters for TorrentsInfoPost.
type TorrentsInfoPostFormdataBody struct {
	// Category Get torrents with the given category (empty string means "without category"; no "category" parameter means "any category" <- broken until [#11748](https://github.com/qbittorrent/qBittorrent/issues/11748) is resolved). Remember to URL-encode the category name. For example, `My category` becomes `My%20category`
	Category *string `form:"category,omitempty" json:"category,omitempty"`

	// Filter Filter torrent list by state. Allowed state filters: `all`, `downloading`, `seeding`, `completed`, `paused`, `active`, `inactive`, `resumed`, `stalled`, `stalled_uploading`, `stalled_downloading`, `errored`
	Filter *TorrentsInfoPostFormdataBodyFilter `form:"filter,omitempty" json:"filter,omitempty"`

	// Hashes Filter by hashes. Can contain multiple hashes separated by `|`
	Hashes *[]string `form:"hashes,omitempty" json:"hashes,omitempty"`

	// Limit Limit the number of torrents returned
	Limit *int64 `form:"limit,omitempty" json:"limit,omitempty"`

	// Offset Set offset (if less than 0, offset from end)
	Offset *int64 `form:"offset,omitempty" json:"offset,omitempty"`

	// Reverse Enable reverse sorting. Defaults to `false`
	Reverse *bool `form:"reverse,omitempty" json:"reverse,omitempty"`

	// Sort Sort torrents by given key. They can be sorted using any field of the response's JSON array (which are documented below) as the sort key.
	Sort *string `form:"sort,omitempty" json:"sort,omitempty"`

	// Tag Get torrents with the given tag (empty string means "without tag"; no "tag" parameter means "any tag". Remember to URL-encode the category name. For example, `My tag` becomes `My%20tag`
	Tag *string `form:"tag,omitempty" json:"tag,omitempty"`
}

// TorrentsInfoPostFormdataBodyFilter defines parameters for TorrentsInfoPost.
type TorrentsInfoPostFormdataBodyFilter string

// TorrentsPieceHashesPostFormdataBody defines parameters for TorrentsPieceHashesPost.
type TorrentsPieceHashesPostFormdataBody struct {
	// Hash The hash of the torrent you want to get the pieces' hashes of
	Hash string `form:"hash" json:"hash"`
}

// TorrentsPieceStatesPostFormdataBody defines parameters for TorrentsPieceStatesPost.
type TorrentsPieceStatesPostFormdataBody struct {
	// Hash The hash of the torrent you want to get the pieces' states of
	Hash string `form:"hash" json:"hash"`
}

// TorrentsPropertiesPostFormdataBody defines parameters for TorrentsPropertiesPost.
type TorrentsPropertiesPostFormdataBody struct {
	// Hash The hash of the torrent you want to get the generic properties of
	Hash string `form:"hash" json:"hash"`
}

// TorrentsRemoveCategoriesPostFormdataBody defines parameters for TorrentsRemoveCategoriesPost.
type TorrentsRemoveCategoriesPostFormdataBody struct {
	// Categories `categories` can contain multiple cateogies separated by `\n` (%0A urlencoded)
	Categories string `form:"categories" json:"categories"`
}

// TorrentsRemoveTrackersPostFormdataBody defines parameters for TorrentsRemoveTrackersPost.
type TorrentsRemoveTrackersPostFormdataBody struct {
	// Hash The hash of the torrent
	Hash string `form:"hash" json:"hash"`

	// Urls URLs to remove, separated by `|`
	Urls []string `form:"urls" json:"urls"`
}

// TorrentsRenamePostFormdataBody defines parameters for TorrentsRenamePost.
type TorrentsRenamePostFormdataBody struct {
	Hash string `form:"hash" json:"hash"`
	Name string `form:"name" json:"name"`
}

// TorrentsSetAutoManagementPostFormdataBody defines parameters for TorrentsSetAutoManagementPost.
type TorrentsSetAutoManagementPostFormdataBody struct {
	// Enable `enable` is a boolean, affects the torrents listed in `hashes`, default is `false`
	Enable *bool    `form:"enable,omitempty" json:"enable,omitempty"`
	Hashes []string `form:"hashes" json:"hashes"`
}

// TorrentsSetCategoryPostFormdataBody defines parameters for TorrentsSetCategoryPost.
type TorrentsSetCategoryPostFormdataBody struct {
	// Category `category` is the torrent category you want to set.
	Category *string  `form:"category,omitempty" json:"category,omitempty"`
	Hashes   []string `form:"hashes" json:"hashes"`
}

// TorrentsSetLocationPostFormdataBody defines parameters for TorrentsSetLocationPost.
type TorrentsSetLocationPostFormdataBody struct {
	Hashes []string `form:"hashes" json:"hashes"`

	// Location `location` is the location to download the torrent to. If the location doesn't exist, the torrent's location is unchanged.
	Location *string `form:"location,omitempty" json:"location,omitempty"`
}

// TorrentsSetShareLimitsPostFormdataBody defines parameters for TorrentsSetShareLimitsPost.
type TorrentsSetShareLimitsPostFormdataBody struct {
	Hashes []string `form:"hashes" json:"hashes"`

	// RatioLimit `ratioLimit` is the max ratio the torrent should be seeded until. `-2` means the global limit should be used, -1 means no limit.
	RatioLimit *float32 `form:"ratioLimit,omitempty" json:"ratioLimit,omitempty"`

	// SeedingTimeLimit `seedingTimeLimit` is the max amount of time the torrent should be seeded. `-2` means the global limit should be used, `-1` means no limit.
	SeedingTimeLimit *float32 `form:"seedingTimeLimit,omitempty" json:"seedingTimeLimit,omitempty"`
}

// TorrentsTrackersPostFormdataBody defines parameters for TorrentsTrackersPost.
type TorrentsTrackersPostFormdataBody struct {
	// Hash The hash of the torrent you want to get the trackers of
	Hash string `form:"hash" json:"hash"`
}

// TorrentWebseedsPostFormdataBody defines parameters for TorrentWebseedsPost.
type TorrentWebseedsPostFormdataBody struct {
	// Hash The hash of the torrent you want to get the webseeds of
	Hash string `form:"hash" json:"hash"`
}

// TransferBanPeersPostFormdataBody defines parameters for TransferBanPeersPost.
type TransferBanPeersPostFormdataBody struct {
	// Peers The peer to ban, or multiple peers separated by a pipe `|`. Each peer is a colon-separated `host:port`
	Peers *[]string `form:"peers,omitempty" json:"peers,omitempty"`
}

// TransferSetDownloadLimitPostFormdataBody defines parameters for TransferSetDownloadLimitPost.
type TransferSetDownloadLimitPostFormdataBody struct {
	// Limit The global download speed limit to set in bytes/second
	Limit *int64 `form:"limit,omitempty" json:"limit,omitempty"`
}

// TransferSetUploadLimitPostFormdataBody defines parameters for TransferSetUploadLimitPost.
type TransferSetUploadLimitPostFormdataBody struct {
	// Limit The global upload speed limit to set in bytes/second
	Limit *int64 `form:"limit,omitempty" json:"limit,omitempty"`
}

// AppSetPreferencesPostFormdataRequestBody defines body for AppSetPreferencesPost for application/x-www-form-urlencoded ContentType.
type AppSetPreferencesPostFormdataRequestBody AppSetPreferencesPostFormdataBody

// AuthLoginPostFormdataRequestBody defines body for AuthLoginPost for application/x-www-form-urlencoded ContentType.
type AuthLoginPostFormdataRequestBody AuthLoginPostFormdataBody

// LogMainPostFormdataRequestBody defines body for LogMainPost for application/x-www-form-urlencoded ContentType.
type LogMainPostFormdataRequestBody LogMainPostFormdataBody

// LogPeersPostFormdataRequestBody defines body for LogPeersPost for application/x-www-form-urlencoded ContentType.
type LogPeersPostFormdataRequestBody LogPeersPostFormdataBody

// RssAddFeedPostFormdataRequestBody defines body for RssAddFeedPost for application/x-www-form-urlencoded ContentType.
type RssAddFeedPostFormdataRequestBody RssAddFeedPostFormdataBody

// RssAddFolderPostFormdataRequestBody defines body for RssAddFolderPost for application/x-www-form-urlencoded ContentType.
type RssAddFolderPostFormdataRequestBody RssAddFolderPostFormdataBody

// RssItemsPostFormdataRequestBody defines body for RssItemsPost for application/x-www-form-urlencoded ContentType.
type RssItemsPostFormdataRequestBody RssItemsPostFormdataBody

// RssMarkAsReadPostFormdataRequestBody defines body for RssMarkAsReadPost for application/x-www-form-urlencoded ContentType.
type RssMarkAsReadPostFormdataRequestBody RssMarkAsReadPostFormdataBody

// RssMatchingArticlesPostFormdataRequestBody defines body for RssMatchingArticlesPost for application/x-www-form-urlencoded ContentType.
type RssMatchingArticlesPostFormdataRequestBody RssMatchingArticlesPostFormdataBody

// RssMoveItemPostFormdataRequestBody defines body for RssMoveItemPost for application/x-www-form-urlencoded ContentType.
type RssMoveItemPostFormdataRequestBody RssMoveItemPostFormdataBody

// RssRefreshItemPostFormdataRequestBody defines body for RssRefreshItemPost for application/x-www-form-urlencoded ContentType.
type RssRefreshItemPostFormdataRequestBody RssRefreshItemPostFormdataBody

// RssRemoveItemPostFormdataRequestBody defines body for RssRemoveItemPost for application/x-www-form-urlencoded ContentType.
type RssRemoveItemPostFormdataRequestBody RssRemoveItemPostFormdataBody

// RssRemoveRulePostFormdataRequestBody defines body for RssRemoveRulePost for application/x-www-form-urlencoded ContentType.
type RssRemoveRulePostFormdataRequestBody RssRemoveRulePostFormdataBody

// RssRenameRulePostFormdataRequestBody defines body for RssRenameRulePost for application/x-www-form-urlencoded ContentType.
type RssRenameRulePostFormdataRequestBody RssRenameRulePostFormdataBody

// RssSetRulePostFormdataRequestBody defines body for RssSetRulePost for application/x-www-form-urlencoded ContentType.
type RssSetRulePostFormdataRequestBody RssSetRulePostFormdataBody

// SearchDeletePostFormdataRequestBody defines body for SearchDeletePost for application/x-www-form-urlencoded ContentType.
type SearchDeletePostFormdataRequestBody SearchDeletePostFormdataBody

// SearchEnablePluginPostFormdataRequestBody defines body for SearchEnablePluginPost for application/x-www-form-urlencoded ContentType.
type SearchEnablePluginPostFormdataRequestBody SearchEnablePluginPostFormdataBody

// SearchInstallPluginPostFormdataRequestBody defines body for SearchInstallPluginPost for application/x-www-form-urlencoded ContentType.
type SearchInstallPluginPostFormdataRequestBody SearchInstallPluginPostFormdataBody

// SearchResultsPostFormdataRequestBody defines body for SearchResultsPost for application/x-www-form-urlencoded ContentType.
type SearchResultsPostFormdataRequestBody SearchResultsPostFormdataBody

// SearchStartPostFormdataRequestBody defines body for SearchStartPost for application/x-www-form-urlencoded ContentType.
type SearchStartPostFormdataRequestBody SearchStartPostFormdataBody

// SearchStatusPostFormdataRequestBody defines body for SearchStatusPost for application/x-www-form-urlencoded ContentType.
type SearchStatusPostFormdataRequestBody SearchStatusPostFormdataBody

// SearchStopPostFormdataRequestBody defines body for SearchStopPost for application/x-www-form-urlencoded ContentType.
type SearchStopPostFormdataRequestBody = SearchStopPostFormdataBody

// SearchUninstallPluginPostFormdataRequestBody defines body for SearchUninstallPluginPost for application/x-www-form-urlencoded ContentType.
type SearchUninstallPluginPostFormdataRequestBody SearchUninstallPluginPostFormdataBody

// SyncMaindataPostFormdataRequestBody defines body for SyncMaindataPost for application/x-www-form-urlencoded ContentType.
type SyncMaindataPostFormdataRequestBody SyncMaindataPostFormdataBody

// SyncTorrentPeersPostFormdataRequestBody defines body for SyncTorrentPeersPost for application/x-www-form-urlencoded ContentType.
type SyncTorrentPeersPostFormdataRequestBody SyncTorrentPeersPostFormdataBody

// TorrentsAddPostMultipartRequestBody defines body for TorrentsAddPost for multipart/form-data ContentType.
type TorrentsAddPostMultipartRequestBody TorrentsAddPostMultipartBody

// TorrentsAddPeersPostFormdataRequestBody defines body for TorrentsAddPeersPost for application/x-www-form-urlencoded ContentType.
type TorrentsAddPeersPostFormdataRequestBody TorrentsAddPeersPostFormdataBody

// TorrentsAddTagsPostFormdataRequestBody defines body for TorrentsAddTagsPost for application/x-www-form-urlencoded ContentType.
type TorrentsAddTagsPostFormdataRequestBody = TorrentsTags

// TorrentsAddTrackersPostFormdataRequestBody defines body for TorrentsAddTrackersPost for application/x-www-form-urlencoded ContentType.
type TorrentsAddTrackersPostFormdataRequestBody TorrentsAddTrackersPostFormdataBody

// TorrentsBottomPrioPostFormdataRequestBody defines body for TorrentsBottomPrioPost for application/x-www-form-urlencoded ContentType.
type TorrentsBottomPrioPostFormdataRequestBody = Hashes

// TorrentsCreateCategoryPostFormdataRequestBody defines body for TorrentsCreateCategoryPost for application/x-www-form-urlencoded ContentType.
type TorrentsCreateCategoryPostFormdataRequestBody = TorrentsCreateCategoryPostFormdataBody

// TorrentsCreateTagsPostFormdataRequestBody defines body for TorrentsCreateTagsPost for application/x-www-form-urlencoded ContentType.
type TorrentsCreateTagsPostFormdataRequestBody TorrentsCreateTagsPostFormdataBody

// TorrentsDecreasePrioPostFormdataRequestBody defines body for TorrentsDecreasePrioPost for application/x-www-form-urlencoded ContentType.
type TorrentsDecreasePrioPostFormdataRequestBody = Hashes

// TorrentsDeletePostFormdataRequestBody defines body for TorrentsDeletePost for application/x-www-form-urlencoded ContentType.
type TorrentsDeletePostFormdataRequestBody TorrentsDeletePostFormdataBody

// TorrentsDeleteTagsPostFormdataRequestBody defines body for TorrentsDeleteTagsPost for application/x-www-form-urlencoded ContentType.
type TorrentsDeleteTagsPostFormdataRequestBody TorrentsDeleteTagsPostFormdataBody

// TorrentsDownloadLimitPostFormdataRequestBody defines body for TorrentsDownloadLimitPost for application/x-www-form-urlencoded ContentType.
type TorrentsDownloadLimitPostFormdataRequestBody = Hashes

// TorrentsEditCategoryPostFormdataRequestBody defines body for TorrentsEditCategoryPost for application/x-www-form-urlencoded ContentType.
type TorrentsEditCategoryPostFormdataRequestBody = TorrentsEditCategoryPostFormdataBody

// TorrentsEditTrackerPostFormdataRequestBody defines body for TorrentsEditTrackerPost for application/x-www-form-urlencoded ContentType.
type TorrentsEditTrackerPostFormdataRequestBody TorrentsEditTrackerPostFormdataBody

// TorrentsFilePrioPostFormdataRequestBody defines body for TorrentsFilePrioPost for application/x-www-form-urlencoded ContentType.
type TorrentsFilePrioPostFormdataRequestBody TorrentsFilePrioPostFormdataBody

// TorrentsFilesPostFormdataRequestBody defines body for TorrentsFilesPost for application/x-www-form-urlencoded ContentType.
type TorrentsFilesPostFormdataRequestBody TorrentsFilesPostFormdataBody

// TorrentsIncreasePrioPostFormdataRequestBody defines body for TorrentsIncreasePrioPost for application/x-www-form-urlencoded ContentType.
type TorrentsIncreasePrioPostFormdataRequestBody = Hashes

// TorrentsInfoPostFormdataRequestBody defines body for TorrentsInfoPost for application/x-www-form-urlencoded ContentType.
type TorrentsInfoPostFormdataRequestBody TorrentsInfoPostFormdataBody

// TorrentsPausePostFormdataRequestBody defines body for TorrentsPausePost for application/x-www-form-urlencoded ContentType.
type TorrentsPausePostFormdataRequestBody = Hashes

// TorrentsPieceHashesPostFormdataRequestBody defines body for TorrentsPieceHashesPost for application/x-www-form-urlencoded ContentType.
type TorrentsPieceHashesPostFormdataRequestBody TorrentsPieceHashesPostFormdataBody

// TorrentsPieceStatesPostFormdataRequestBody defines body for TorrentsPieceStatesPost for application/x-www-form-urlencoded ContentType.
type TorrentsPieceStatesPostFormdataRequestBody TorrentsPieceStatesPostFormdataBody

// TorrentsPropertiesPostFormdataRequestBody defines body for TorrentsPropertiesPost for application/x-www-form-urlencoded ContentType.
type TorrentsPropertiesPostFormdataRequestBody TorrentsPropertiesPostFormdataBody

// TorrentsReannouncePostFormdataRequestBody defines body for TorrentsReannouncePost for application/x-www-form-urlencoded ContentType.
type TorrentsReannouncePostFormdataRequestBody = Hashes

// TorrentsRecheckPostFormdataRequestBody defines body for TorrentsRecheckPost for application/x-www-form-urlencoded ContentType.
type TorrentsRecheckPostFormdataRequestBody = Hashes

// TorrentsRemoveCategoriesPostFormdataRequestBody defines body for TorrentsRemoveCategoriesPost for application/x-www-form-urlencoded ContentType.
type TorrentsRemoveCategoriesPostFormdataRequestBody TorrentsRemoveCategoriesPostFormdataBody

// TorrentsRemoveTagsPostFormdataRequestBody defines body for TorrentsRemoveTagsPost for application/x-www-form-urlencoded ContentType.
type TorrentsRemoveTagsPostFormdataRequestBody = TorrentsTags

// TorrentsRemoveTrackersPostFormdataRequestBody defines body for TorrentsRemoveTrackersPost for application/x-www-form-urlencoded ContentType.
type TorrentsRemoveTrackersPostFormdataRequestBody TorrentsRemoveTrackersPostFormdataBody

// TorrentsRenamePostFormdataRequestBody defines body for TorrentsRenamePost for application/x-www-form-urlencoded ContentType.
type TorrentsRenamePostFormdataRequestBody TorrentsRenamePostFormdataBody

// TorrentsRenameFilePostFormdataRequestBody defines body for TorrentsRenameFilePost for application/x-www-form-urlencoded ContentType.
type TorrentsRenameFilePostFormdataRequestBody = RenameTorrentFiles

// TorrentsRenameFolderPostFormdataRequestBody defines body for TorrentsRenameFolderPost for application/x-www-form-urlencoded ContentType.
type TorrentsRenameFolderPostFormdataRequestBody = RenameTorrentFiles

// TorrentsResumePostFormdataRequestBody defines body for TorrentsResumePost for application/x-www-form-urlencoded ContentType.
type TorrentsResumePostFormdataRequestBody = Hashes

// TorrentsSetAutoManagementPostFormdataRequestBody defines body for TorrentsSetAutoManagementPost for application/x-www-form-urlencoded ContentType.
type TorrentsSetAutoManagementPostFormdataRequestBody TorrentsSetAutoManagementPostFormdataBody

// TorrentsSetCategoryPostFormdataRequestBody defines body for TorrentsSetCategoryPost for application/x-www-form-urlencoded ContentType.
type TorrentsSetCategoryPostFormdataRequestBody TorrentsSetCategoryPostFormdataBody

// TorrentsSetDownloadLimitPostFormdataRequestBody defines body for TorrentsSetDownloadLimitPost for application/x-www-form-urlencoded ContentType.
type TorrentsSetDownloadLimitPostFormdataRequestBody = SetTorrentsLimit

// TorrentsSetForceStartPostFormdataRequestBody defines body for TorrentsSetForceStartPost for application/x-www-form-urlencoded ContentType.
type TorrentsSetForceStartPostFormdataRequestBody = SetTorrentsValue

// TorrentsSetLocationPostFormdataRequestBody defines body for TorrentsSetLocationPost for application/x-www-form-urlencoded ContentType.
type TorrentsSetLocationPostFormdataRequestBody TorrentsSetLocationPostFormdataBody

// TorrentsSetShareLimitsPostFormdataRequestBody defines body for TorrentsSetShareLimitsPost for application/x-www-form-urlencoded ContentType.
type TorrentsSetShareLimitsPostFormdataRequestBody TorrentsSetShareLimitsPostFormdataBody

// TorrentsSetSuperSeedingPostFormdataRequestBody defines body for TorrentsSetSuperSeedingPost for application/x-www-form-urlencoded ContentType.
type TorrentsSetSuperSeedingPostFormdataRequestBody = SetTorrentsValue

// TorrentsSetUploadLimitPostFormdataRequestBody defines body for TorrentsSetUploadLimitPost for application/x-www-form-urlencoded ContentType.
type TorrentsSetUploadLimitPostFormdataRequestBody = SetTorrentsLimit

// TorrentsToggleFirstLastPiecePrioPostFormdataRequestBody defines body for TorrentsToggleFirstLastPiecePrioPost for application/x-www-form-urlencoded ContentType.
type TorrentsToggleFirstLastPiecePrioPostFormdataRequestBody = Hashes

// TorrentsToggleSequentialDownloadPostFormdataRequestBody defines body for TorrentsToggleSequentialDownloadPost for application/x-www-form-urlencoded ContentType.
type TorrentsToggleSequentialDownloadPostFormdataRequestBody = Hashes

// TorrentsTopPrioPostFormdataRequestBody defines body for TorrentsTopPrioPost for application/x-www-form-urlencoded ContentType.
type TorrentsTopPrioPostFormdataRequestBody = Hashes

// TorrentsTrackersPostFormdataRequestBody defines body for TorrentsTrackersPost for application/x-www-form-urlencoded ContentType.
type TorrentsTrackersPostFormdataRequestBody TorrentsTrackersPostFormdataBody

// TorrentsUploadLimitPostFormdataRequestBody defines body for TorrentsUploadLimitPost for application/x-www-form-urlencoded ContentType.
type TorrentsUploadLimitPostFormdataRequestBody = Hashes

// TorrentWebseedsPostFormdataRequestBody defines body for TorrentWebseedsPost for application/x-www-form-urlencoded ContentType.
type TorrentWebseedsPostFormdataRequestBody TorrentWebseedsPostFormdataBody

// TransferBanPeersPostFormdataRequestBody defines body for TransferBanPeersPost for application/x-www-form-urlencoded ContentType.
type TransferBanPeersPostFormdataRequestBody TransferBanPeersPostFormdataBody

// TransferSetDownloadLimitPostFormdataRequestBody defines body for TransferSetDownloadLimitPost for application/x-www-form-urlencoded ContentType.
type TransferSetDownloadLimitPostFormdataRequestBody TransferSetDownloadLimitPostFormdataBody

// TransferSetUploadLimitPostFormdataRequestBody defines body for TransferSetUploadLimitPost for application/x-www-form-urlencoded ContentType.
type TransferSetUploadLimitPostFormdataRequestBody TransferSetUploadLimitPostFormdataBody

// Getter for additional properties for Preferences. Returns the specified
// element and whether it was found
func (a Preferences) Get(fieldName string) (value interface{}, found bool) {
	if a.AdditionalProperties != nil {
		value, found = a.AdditionalProperties[fieldName]
	}
	return
}

// Setter for additional properties for Preferences
func (a *Preferences) Set(fieldName string, value interface{}) {
	if a.AdditionalProperties == nil {
		a.AdditionalProperties = make(map[string]interface{})
	}
	a.AdditionalProperties[fieldName] = value
}

// Override default JSON handling for Preferences to handle AdditionalProperties
func (a *Preferences) UnmarshalJSON(b []byte) error {
	object := make(map[string]json.RawMessage)
	err := json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["add_trackers"]; found {
		err = json.Unmarshal(raw, &a.AddTrackers)
		if err != nil {
			return fmt.Errorf("error reading 'add_trackers': %w", err)
		}
		delete(object, "add_trackers")
	}

	if raw, found := object["add_trackers_enabled"]; found {
		err = json.Unmarshal(raw, &a.AddTrackersEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'add_trackers_enabled': %w", err)
		}
		delete(object, "add_trackers_enabled")
	}

	if raw, found := object["alt_dl_limit"]; found {
		err = json.Unmarshal(raw, &a.AltDlLimit)
		if err != nil {
			return fmt.Errorf("error reading 'alt_dl_limit': %w", err)
		}
		delete(object, "alt_dl_limit")
	}

	if raw, found := object["alt_up_limit"]; found {
		err = json.Unmarshal(raw, &a.AltUpLimit)
		if err != nil {
			return fmt.Errorf("error reading 'alt_up_limit': %w", err)
		}
		delete(object, "alt_up_limit")
	}

	if raw, found := object["alternative_webui_enabled"]; found {
		err = json.Unmarshal(raw, &a.AlternativeWebuiEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'alternative_webui_enabled': %w", err)
		}
		delete(object, "alternative_webui_enabled")
	}

	if raw, found := object["alternative_webui_path"]; found {
		err = json.Unmarshal(raw, &a.AlternativeWebuiPath)
		if err != nil {
			return fmt.Errorf("error reading 'alternative_webui_path': %w", err)
		}
		delete(object, "alternative_webui_path")
	}

	if raw, found := object["announce_ip"]; found {
		err = json.Unmarshal(raw, &a.AnnounceIp)
		if err != nil {
			return fmt.Errorf("error reading 'announce_ip': %w", err)
		}
		delete(object, "announce_ip")
	}

	if raw, found := object["announce_to_all_tiers"]; found {
		err = json.Unmarshal(raw, &a.AnnounceToAllTiers)
		if err != nil {
			return fmt.Errorf("error reading 'announce_to_all_tiers': %w", err)
		}
		delete(object, "announce_to_all_tiers")
	}

	if raw, found := object["announce_to_all_trackers"]; found {
		err = json.Unmarshal(raw, &a.AnnounceToAllTrackers)
		if err != nil {
			return fmt.Errorf("error reading 'announce_to_all_trackers': %w", err)
		}
		delete(object, "announce_to_all_trackers")
	}

	if raw, found := object["anonymous_mode"]; found {
		err = json.Unmarshal(raw, &a.AnonymousMode)
		if err != nil {
			return fmt.Errorf("error reading 'anonymous_mode': %w", err)
		}
		delete(object, "anonymous_mode")
	}

	if raw, found := object["async_io_threads"]; found {
		err = json.Unmarshal(raw, &a.AsyncIoThreads)
		if err != nil {
			return fmt.Errorf("error reading 'async_io_threads': %w", err)
		}
		delete(object, "async_io_threads")
	}

	if raw, found := object["auto_delete_mode"]; found {
		err = json.Unmarshal(raw, &a.AutoDeleteMode)
		if err != nil {
			return fmt.Errorf("error reading 'auto_delete_mode': %w", err)
		}
		delete(object, "auto_delete_mode")
	}

	if raw, found := object["auto_tmm_enabled"]; found {
		err = json.Unmarshal(raw, &a.AutoTmmEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'auto_tmm_enabled': %w", err)
		}
		delete(object, "auto_tmm_enabled")
	}

	if raw, found := object["autorun_enabled"]; found {
		err = json.Unmarshal(raw, &a.AutorunEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'autorun_enabled': %w", err)
		}
		delete(object, "autorun_enabled")
	}

	if raw, found := object["autorun_program"]; found {
		err = json.Unmarshal(raw, &a.AutorunProgram)
		if err != nil {
			return fmt.Errorf("error reading 'autorun_program': %w", err)
		}
		delete(object, "autorun_program")
	}

	if raw, found := object["banned_IPs"]; found {
		err = json.Unmarshal(raw, &a.BannedIPs)
		if err != nil {
			return fmt.Errorf("error reading 'banned_IPs': %w", err)
		}
		delete(object, "banned_IPs")
	}

	if raw, found := object["bittorrent_protocol"]; found {
		err = json.Unmarshal(raw, &a.BittorrentProtocol)
		if err != nil {
			return fmt.Errorf("error reading 'bittorrent_protocol': %w", err)
		}
		delete(object, "bittorrent_protocol")
	}

	if raw, found := object["bypass_auth_subnet_whitelist"]; found {
		err = json.Unmarshal(raw, &a.BypassAuthSubnetWhitelist)
		if err != nil {
			return fmt.Errorf("error reading 'bypass_auth_subnet_whitelist': %w", err)
		}
		delete(object, "bypass_auth_subnet_whitelist")
	}

	if raw, found := object["bypass_auth_subnet_whitelist_enabled"]; found {
		err = json.Unmarshal(raw, &a.BypassAuthSubnetWhitelistEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'bypass_auth_subnet_whitelist_enabled': %w", err)
		}
		delete(object, "bypass_auth_subnet_whitelist_enabled")
	}

	if raw, found := object["bypass_local_auth"]; found {
		err = json.Unmarshal(raw, &a.BypassLocalAuth)
		if err != nil {
			return fmt.Errorf("error reading 'bypass_local_auth': %w", err)
		}
		delete(object, "bypass_local_auth")
	}

	if raw, found := object["category_changed_tmm_enabled"]; found {
		err = json.Unmarshal(raw, &a.CategoryChangedTmmEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'category_changed_tmm_enabled': %w", err)
		}
		delete(object, "category_changed_tmm_enabled")
	}

	if raw, found := object["checking_memory_use"]; found {
		err = json.Unmarshal(raw, &a.CheckingMemoryUse)
		if err != nil {
			return fmt.Errorf("error reading 'checking_memory_use': %w", err)
		}
		delete(object, "checking_memory_use")
	}

	if raw, found := object["create_subfolder_enabled"]; found {
		err = json.Unmarshal(raw, &a.CreateSubfolderEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'create_subfolder_enabled': %w", err)
		}
		delete(object, "create_subfolder_enabled")
	}

	if raw, found := object["current_interface_address"]; found {
		err = json.Unmarshal(raw, &a.CurrentInterfaceAddress)
		if err != nil {
			return fmt.Errorf("error reading 'current_interface_address': %w", err)
		}
		delete(object, "current_interface_address")
	}

	if raw, found := object["current_network_interface"]; found {
		err = json.Unmarshal(raw, &a.CurrentNetworkInterface)
		if err != nil {
			return fmt.Errorf("error reading 'current_network_interface': %w", err)
		}
		delete(object, "current_network_interface")
	}

	if raw, found := object["dht"]; found {
		err = json.Unmarshal(raw, &a.Dht)
		if err != nil {
			return fmt.Errorf("error reading 'dht': %w", err)
		}
		delete(object, "dht")
	}

	if raw, found := object["disk_cache"]; found {
		err = json.Unmarshal(raw, &a.DiskCache)
		if err != nil {
			return fmt.Errorf("error reading 'disk_cache': %w", err)
		}
		delete(object, "disk_cache")
	}

	if raw, found := object["disk_cache_ttl"]; found {
		err = json.Unmarshal(raw, &a.DiskCacheTtl)
		if err != nil {
			return fmt.Errorf("error reading 'disk_cache_ttl': %w", err)
		}
		delete(object, "disk_cache_ttl")
	}

	if raw, found := object["dl_limit"]; found {
		err = json.Unmarshal(raw, &a.DlLimit)
		if err != nil {
			return fmt.Errorf("error reading 'dl_limit': %w", err)
		}
		delete(object, "dl_limit")
	}

	if raw, found := object["dont_count_slow_torrents"]; found {
		err = json.Unmarshal(raw, &a.DontCountSlowTorrents)
		if err != nil {
			return fmt.Errorf("error reading 'dont_count_slow_torrents': %w", err)
		}
		delete(object, "dont_count_slow_torrents")
	}

	if raw, found := object["dyndns_domain"]; found {
		err = json.Unmarshal(raw, &a.DyndnsDomain)
		if err != nil {
			return fmt.Errorf("error reading 'dyndns_domain': %w", err)
		}
		delete(object, "dyndns_domain")
	}

	if raw, found := object["dyndns_enabled"]; found {
		err = json.Unmarshal(raw, &a.DyndnsEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'dyndns_enabled': %w", err)
		}
		delete(object, "dyndns_enabled")
	}

	if raw, found := object["dyndns_password"]; found {
		err = json.Unmarshal(raw, &a.DyndnsPassword)
		if err != nil {
			return fmt.Errorf("error reading 'dyndns_password': %w", err)
		}
		delete(object, "dyndns_password")
	}

	if raw, found := object["dyndns_service"]; found {
		err = json.Unmarshal(raw, &a.DyndnsService)
		if err != nil {
			return fmt.Errorf("error reading 'dyndns_service': %w", err)
		}
		delete(object, "dyndns_service")
	}

	if raw, found := object["dyndns_username"]; found {
		err = json.Unmarshal(raw, &a.DyndnsUsername)
		if err != nil {
			return fmt.Errorf("error reading 'dyndns_username': %w", err)
		}
		delete(object, "dyndns_username")
	}

	if raw, found := object["embedded_tracker_port"]; found {
		err = json.Unmarshal(raw, &a.EmbeddedTrackerPort)
		if err != nil {
			return fmt.Errorf("error reading 'embedded_tracker_port': %w", err)
		}
		delete(object, "embedded_tracker_port")
	}

	if raw, found := object["enable_coalesce_read_write"]; found {
		err = json.Unmarshal(raw, &a.EnableCoalesceReadWrite)
		if err != nil {
			return fmt.Errorf("error reading 'enable_coalesce_read_write': %w", err)
		}
		delete(object, "enable_coalesce_read_write")
	}

	if raw, found := object["enable_embedded_tracker"]; found {
		err = json.Unmarshal(raw, &a.EnableEmbeddedTracker)
		if err != nil {
			return fmt.Errorf("error reading 'enable_embedded_tracker': %w", err)
		}
		delete(object, "enable_embedded_tracker")
	}

	if raw, found := object["enable_multi_connections_from_same_ip"]; found {
		err = json.Unmarshal(raw, &a.EnableMultiConnectionsFromSameIp)
		if err != nil {
			return fmt.Errorf("error reading 'enable_multi_connections_from_same_ip': %w", err)
		}
		delete(object, "enable_multi_connections_from_same_ip")
	}

	if raw, found := object["enable_os_cache"]; found {
		err = json.Unmarshal(raw, &a.EnableOsCache)
		if err != nil {
			return fmt.Errorf("error reading 'enable_os_cache': %w", err)
		}
		delete(object, "enable_os_cache")
	}

	if raw, found := object["enable_piece_extent_affinity"]; found {
		err = json.Unmarshal(raw, &a.EnablePieceExtentAffinity)
		if err != nil {
			return fmt.Errorf("error reading 'enable_piece_extent_affinity': %w", err)
		}
		delete(object, "enable_piece_extent_affinity")
	}

	if raw, found := object["enable_upload_suggestions"]; found {
		err = json.Unmarshal(raw, &a.EnableUploadSuggestions)
		if err != nil {
			return fmt.Errorf("error reading 'enable_upload_suggestions': %w", err)
		}
		delete(object, "enable_upload_suggestions")
	}

	if raw, found := object["encryption"]; found {
		err = json.Unmarshal(raw, &a.Encryption)
		if err != nil {
			return fmt.Errorf("error reading 'encryption': %w", err)
		}
		delete(object, "encryption")
	}

	if raw, found := object["export_dir"]; found {
		err = json.Unmarshal(raw, &a.ExportDir)
		if err != nil {
			return fmt.Errorf("error reading 'export_dir': %w", err)
		}
		delete(object, "export_dir")
	}

	if raw, found := object["export_dir_fin"]; found {
		err = json.Unmarshal(raw, &a.ExportDirFin)
		if err != nil {
			return fmt.Errorf("error reading 'export_dir_fin': %w", err)
		}
		delete(object, "export_dir_fin")
	}

	if raw, found := object["file_pool_size"]; found {
		err = json.Unmarshal(raw, &a.FilePoolSize)
		if err != nil {
			return fmt.Errorf("error reading 'file_pool_size': %w", err)
		}
		delete(object, "file_pool_size")
	}

	if raw, found := object["incomplete_files_ext"]; found {
		err = json.Unmarshal(raw, &a.IncompleteFilesExt)
		if err != nil {
			return fmt.Errorf("error reading 'incomplete_files_ext': %w", err)
		}
		delete(object, "incomplete_files_ext")
	}

	if raw, found := object["ip_filter_enabled"]; found {
		err = json.Unmarshal(raw, &a.IpFilterEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'ip_filter_enabled': %w", err)
		}
		delete(object, "ip_filter_enabled")
	}

	if raw, found := object["ip_filter_path"]; found {
		err = json.Unmarshal(raw, &a.IpFilterPath)
		if err != nil {
			return fmt.Errorf("error reading 'ip_filter_path': %w", err)
		}
		delete(object, "ip_filter_path")
	}

	if raw, found := object["ip_filter_trackers"]; found {
		err = json.Unmarshal(raw, &a.IpFilterTrackers)
		if err != nil {
			return fmt.Errorf("error reading 'ip_filter_trackers': %w", err)
		}
		delete(object, "ip_filter_trackers")
	}

	if raw, found := object["limit_lan_peers"]; found {
		err = json.Unmarshal(raw, &a.LimitLanPeers)
		if err != nil {
			return fmt.Errorf("error reading 'limit_lan_peers': %w", err)
		}
		delete(object, "limit_lan_peers")
	}

	if raw, found := object["limit_tcp_overhead"]; found {
		err = json.Unmarshal(raw, &a.LimitTcpOverhead)
		if err != nil {
			return fmt.Errorf("error reading 'limit_tcp_overhead': %w", err)
		}
		delete(object, "limit_tcp_overhead")
	}

	if raw, found := object["limit_utp_rate"]; found {
		err = json.Unmarshal(raw, &a.LimitUtpRate)
		if err != nil {
			return fmt.Errorf("error reading 'limit_utp_rate': %w", err)
		}
		delete(object, "limit_utp_rate")
	}

	if raw, found := object["listen_port"]; found {
		err = json.Unmarshal(raw, &a.ListenPort)
		if err != nil {
			return fmt.Errorf("error reading 'listen_port': %w", err)
		}
		delete(object, "listen_port")
	}

	if raw, found := object["locale"]; found {
		err = json.Unmarshal(raw, &a.Locale)
		if err != nil {
			return fmt.Errorf("error reading 'locale': %w", err)
		}
		delete(object, "locale")
	}

	if raw, found := object["lsd"]; found {
		err = json.Unmarshal(raw, &a.Lsd)
		if err != nil {
			return fmt.Errorf("error reading 'lsd': %w", err)
		}
		delete(object, "lsd")
	}

	if raw, found := object["mail_notification_auth_enabled"]; found {
		err = json.Unmarshal(raw, &a.MailNotificationAuthEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'mail_notification_auth_enabled': %w", err)
		}
		delete(object, "mail_notification_auth_enabled")
	}

	if raw, found := object["mail_notification_email"]; found {
		err = json.Unmarshal(raw, &a.MailNotificationEmail)
		if err != nil {
			return fmt.Errorf("error reading 'mail_notification_email': %w", err)
		}
		delete(object, "mail_notification_email")
	}

	if raw, found := object["mail_notification_enabled"]; found {
		err = json.Unmarshal(raw, &a.MailNotificationEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'mail_notification_enabled': %w", err)
		}
		delete(object, "mail_notification_enabled")
	}

	if raw, found := object["mail_notification_password"]; found {
		err = json.Unmarshal(raw, &a.MailNotificationPassword)
		if err != nil {
			return fmt.Errorf("error reading 'mail_notification_password': %w", err)
		}
		delete(object, "mail_notification_password")
	}

	if raw, found := object["mail_notification_sender"]; found {
		err = json.Unmarshal(raw, &a.MailNotificationSender)
		if err != nil {
			return fmt.Errorf("error reading 'mail_notification_sender': %w", err)
		}
		delete(object, "mail_notification_sender")
	}

	if raw, found := object["mail_notification_smtp"]; found {
		err = json.Unmarshal(raw, &a.MailNotificationSmtp)
		if err != nil {
			return fmt.Errorf("error reading 'mail_notification_smtp': %w", err)
		}
		delete(object, "mail_notification_smtp")
	}

	if raw, found := object["mail_notification_ssl_enabled"]; found {
		err = json.Unmarshal(raw, &a.MailNotificationSslEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'mail_notification_ssl_enabled': %w", err)
		}
		delete(object, "mail_notification_ssl_enabled")
	}

	if raw, found := object["mail_notification_username"]; found {
		err = json.Unmarshal(raw, &a.MailNotificationUsername)
		if err != nil {
			return fmt.Errorf("error reading 'mail_notification_username': %w", err)
		}
		delete(object, "mail_notification_username")
	}

	if raw, found := object["max_active_downloads"]; found {
		err = json.Unmarshal(raw, &a.MaxActiveDownloads)
		if err != nil {
			return fmt.Errorf("error reading 'max_active_downloads': %w", err)
		}
		delete(object, "max_active_downloads")
	}

	if raw, found := object["max_active_torrents"]; found {
		err = json.Unmarshal(raw, &a.MaxActiveTorrents)
		if err != nil {
			return fmt.Errorf("error reading 'max_active_torrents': %w", err)
		}
		delete(object, "max_active_torrents")
	}

	if raw, found := object["max_active_uploads"]; found {
		err = json.Unmarshal(raw, &a.MaxActiveUploads)
		if err != nil {
			return fmt.Errorf("error reading 'max_active_uploads': %w", err)
		}
		delete(object, "max_active_uploads")
	}

	if raw, found := object["max_connec"]; found {
		err = json.Unmarshal(raw, &a.MaxConnec)
		if err != nil {
			return fmt.Errorf("error reading 'max_connec': %w", err)
		}
		delete(object, "max_connec")
	}

	if raw, found := object["max_connec_per_torrent"]; found {
		err = json.Unmarshal(raw, &a.MaxConnecPerTorrent)
		if err != nil {
			return fmt.Errorf("error reading 'max_connec_per_torrent': %w", err)
		}
		delete(object, "max_connec_per_torrent")
	}

	if raw, found := object["max_ratio"]; found {
		err = json.Unmarshal(raw, &a.MaxRatio)
		if err != nil {
			return fmt.Errorf("error reading 'max_ratio': %w", err)
		}
		delete(object, "max_ratio")
	}

	if raw, found := object["max_ratio_act"]; found {
		err = json.Unmarshal(raw, &a.MaxRatioAct)
		if err != nil {
			return fmt.Errorf("error reading 'max_ratio_act': %w", err)
		}
		delete(object, "max_ratio_act")
	}

	if raw, found := object["max_ratio_enabled"]; found {
		err = json.Unmarshal(raw, &a.MaxRatioEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'max_ratio_enabled': %w", err)
		}
		delete(object, "max_ratio_enabled")
	}

	if raw, found := object["max_seeding_time"]; found {
		err = json.Unmarshal(raw, &a.MaxSeedingTime)
		if err != nil {
			return fmt.Errorf("error reading 'max_seeding_time': %w", err)
		}
		delete(object, "max_seeding_time")
	}

	if raw, found := object["max_seeding_time_enabled"]; found {
		err = json.Unmarshal(raw, &a.MaxSeedingTimeEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'max_seeding_time_enabled': %w", err)
		}
		delete(object, "max_seeding_time_enabled")
	}

	if raw, found := object["max_uploads"]; found {
		err = json.Unmarshal(raw, &a.MaxUploads)
		if err != nil {
			return fmt.Errorf("error reading 'max_uploads': %w", err)
		}
		delete(object, "max_uploads")
	}

	if raw, found := object["max_uploads_per_torrent"]; found {
		err = json.Unmarshal(raw, &a.MaxUploadsPerTorrent)
		if err != nil {
			return fmt.Errorf("error reading 'max_uploads_per_torrent': %w", err)
		}
		delete(object, "max_uploads_per_torrent")
	}

	if raw, found := object["outgoing_ports_max"]; found {
		err = json.Unmarshal(raw, &a.OutgoingPortsMax)
		if err != nil {
			return fmt.Errorf("error reading 'outgoing_ports_max': %w", err)
		}
		delete(object, "outgoing_ports_max")
	}

	if raw, found := object["outgoing_ports_min"]; found {
		err = json.Unmarshal(raw, &a.OutgoingPortsMin)
		if err != nil {
			return fmt.Errorf("error reading 'outgoing_ports_min': %w", err)
		}
		delete(object, "outgoing_ports_min")
	}

	if raw, found := object["pex"]; found {
		err = json.Unmarshal(raw, &a.Pex)
		if err != nil {
			return fmt.Errorf("error reading 'pex': %w", err)
		}
		delete(object, "pex")
	}

	if raw, found := object["preallocate_all"]; found {
		err = json.Unmarshal(raw, &a.PreallocateAll)
		if err != nil {
			return fmt.Errorf("error reading 'preallocate_all': %w", err)
		}
		delete(object, "preallocate_all")
	}

	if raw, found := object["proxy_auth_enabled"]; found {
		err = json.Unmarshal(raw, &a.ProxyAuthEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'proxy_auth_enabled': %w", err)
		}
		delete(object, "proxy_auth_enabled")
	}

	if raw, found := object["proxy_ip"]; found {
		err = json.Unmarshal(raw, &a.ProxyIp)
		if err != nil {
			return fmt.Errorf("error reading 'proxy_ip': %w", err)
		}
		delete(object, "proxy_ip")
	}

	if raw, found := object["proxy_password"]; found {
		err = json.Unmarshal(raw, &a.ProxyPassword)
		if err != nil {
			return fmt.Errorf("error reading 'proxy_password': %w", err)
		}
		delete(object, "proxy_password")
	}

	if raw, found := object["proxy_peer_connections"]; found {
		err = json.Unmarshal(raw, &a.ProxyPeerConnections)
		if err != nil {
			return fmt.Errorf("error reading 'proxy_peer_connections': %w", err)
		}
		delete(object, "proxy_peer_connections")
	}

	if raw, found := object["proxy_port"]; found {
		err = json.Unmarshal(raw, &a.ProxyPort)
		if err != nil {
			return fmt.Errorf("error reading 'proxy_port': %w", err)
		}
		delete(object, "proxy_port")
	}

	if raw, found := object["proxy_torrents_only"]; found {
		err = json.Unmarshal(raw, &a.ProxyTorrentsOnly)
		if err != nil {
			return fmt.Errorf("error reading 'proxy_torrents_only': %w", err)
		}
		delete(object, "proxy_torrents_only")
	}

	if raw, found := object["proxy_type"]; found {
		err = json.Unmarshal(raw, &a.ProxyType)
		if err != nil {
			return fmt.Errorf("error reading 'proxy_type': %w", err)
		}
		delete(object, "proxy_type")
	}

	if raw, found := object["proxy_username"]; found {
		err = json.Unmarshal(raw, &a.ProxyUsername)
		if err != nil {
			return fmt.Errorf("error reading 'proxy_username': %w", err)
		}
		delete(object, "proxy_username")
	}

	if raw, found := object["queueing_enabled"]; found {
		err = json.Unmarshal(raw, &a.QueueingEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'queueing_enabled': %w", err)
		}
		delete(object, "queueing_enabled")
	}

	if raw, found := object["random_port"]; found {
		err = json.Unmarshal(raw, &a.RandomPort)
		if err != nil {
			return fmt.Errorf("error reading 'random_port': %w", err)
		}
		delete(object, "random_port")
	}

	if raw, found := object["recheck_completed_torrents"]; found {
		err = json.Unmarshal(raw, &a.RecheckCompletedTorrents)
		if err != nil {
			return fmt.Errorf("error reading 'recheck_completed_torrents': %w", err)
		}
		delete(object, "recheck_completed_torrents")
	}

	if raw, found := object["resolve_peer_countries"]; found {
		err = json.Unmarshal(raw, &a.ResolvePeerCountries)
		if err != nil {
			return fmt.Errorf("error reading 'resolve_peer_countries': %w", err)
		}
		delete(object, "resolve_peer_countries")
	}

	if raw, found := object["rss_auto_downloading_enabled"]; found {
		err = json.Unmarshal(raw, &a.RssAutoDownloadingEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'rss_auto_downloading_enabled': %w", err)
		}
		delete(object, "rss_auto_downloading_enabled")
	}

	if raw, found := object["rss_download_repack_proper_episodes"]; found {
		err = json.Unmarshal(raw, &a.RssDownloadRepackProperEpisodes)
		if err != nil {
			return fmt.Errorf("error reading 'rss_download_repack_proper_episodes': %w", err)
		}
		delete(object, "rss_download_repack_proper_episodes")
	}

	if raw, found := object["rss_max_articles_per_feed"]; found {
		err = json.Unmarshal(raw, &a.RssMaxArticlesPerFeed)
		if err != nil {
			return fmt.Errorf("error reading 'rss_max_articles_per_feed': %w", err)
		}
		delete(object, "rss_max_articles_per_feed")
	}

	if raw, found := object["rss_processing_enabled"]; found {
		err = json.Unmarshal(raw, &a.RssProcessingEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'rss_processing_enabled': %w", err)
		}
		delete(object, "rss_processing_enabled")
	}

	if raw, found := object["rss_refresh_interval"]; found {
		err = json.Unmarshal(raw, &a.RssRefreshInterval)
		if err != nil {
			return fmt.Errorf("error reading 'rss_refresh_interval': %w", err)
		}
		delete(object, "rss_refresh_interval")
	}

	if raw, found := object["rss_smart_episode_filters"]; found {
		err = json.Unmarshal(raw, &a.RssSmartEpisodeFilters)
		if err != nil {
			return fmt.Errorf("error reading 'rss_smart_episode_filters': %w", err)
		}
		delete(object, "rss_smart_episode_filters")
	}

	if raw, found := object["save_path"]; found {
		err = json.Unmarshal(raw, &a.SavePath)
		if err != nil {
			return fmt.Errorf("error reading 'save_path': %w", err)
		}
		delete(object, "save_path")
	}

	if raw, found := object["save_path_changed_tmm_enabled"]; found {
		err = json.Unmarshal(raw, &a.SavePathChangedTmmEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'save_path_changed_tmm_enabled': %w", err)
		}
		delete(object, "save_path_changed_tmm_enabled")
	}

	if raw, found := object["save_resume_data_interval"]; found {
		err = json.Unmarshal(raw, &a.SaveResumeDataInterval)
		if err != nil {
			return fmt.Errorf("error reading 'save_resume_data_interval': %w", err)
		}
		delete(object, "save_resume_data_interval")
	}

	if raw, found := object["scan_dirs"]; found {
		err = json.Unmarshal(raw, &a.ScanDirs)
		if err != nil {
			return fmt.Errorf("error reading 'scan_dirs': %w", err)
		}
		delete(object, "scan_dirs")
	}

	if raw, found := object["schedule_from_hour"]; found {
		err = json.Unmarshal(raw, &a.ScheduleFromHour)
		if err != nil {
			return fmt.Errorf("error reading 'schedule_from_hour': %w", err)
		}
		delete(object, "schedule_from_hour")
	}

	if raw, found := object["schedule_from_min"]; found {
		err = json.Unmarshal(raw, &a.ScheduleFromMin)
		if err != nil {
			return fmt.Errorf("error reading 'schedule_from_min': %w", err)
		}
		delete(object, "schedule_from_min")
	}

	if raw, found := object["schedule_to_hour"]; found {
		err = json.Unmarshal(raw, &a.ScheduleToHour)
		if err != nil {
			return fmt.Errorf("error reading 'schedule_to_hour': %w", err)
		}
		delete(object, "schedule_to_hour")
	}

	if raw, found := object["schedule_to_min"]; found {
		err = json.Unmarshal(raw, &a.ScheduleToMin)
		if err != nil {
			return fmt.Errorf("error reading 'schedule_to_min': %w", err)
		}
		delete(object, "schedule_to_min")
	}

	if raw, found := object["scheduler_days"]; found {
		err = json.Unmarshal(raw, &a.SchedulerDays)
		if err != nil {
			return fmt.Errorf("error reading 'scheduler_days': %w", err)
		}
		delete(object, "scheduler_days")
	}

	if raw, found := object["scheduler_enabled"]; found {
		err = json.Unmarshal(raw, &a.SchedulerEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'scheduler_enabled': %w", err)
		}
		delete(object, "scheduler_enabled")
	}

	if raw, found := object["send_buffer_low_watermark"]; found {
		err = json.Unmarshal(raw, &a.SendBufferLowWatermark)
		if err != nil {
			return fmt.Errorf("error reading 'send_buffer_low_watermark': %w", err)
		}
		delete(object, "send_buffer_low_watermark")
	}

	if raw, found := object["send_buffer_watermark"]; found {
		err = json.Unmarshal(raw, &a.SendBufferWatermark)
		if err != nil {
			return fmt.Errorf("error reading 'send_buffer_watermark': %w", err)
		}
		delete(object, "send_buffer_watermark")
	}

	if raw, found := object["send_buffer_watermark_factor"]; found {
		err = json.Unmarshal(raw, &a.SendBufferWatermarkFactor)
		if err != nil {
			return fmt.Errorf("error reading 'send_buffer_watermark_factor': %w", err)
		}
		delete(object, "send_buffer_watermark_factor")
	}

	if raw, found := object["slow_torrent_dl_rate_threshold"]; found {
		err = json.Unmarshal(raw, &a.SlowTorrentDlRateThreshold)
		if err != nil {
			return fmt.Errorf("error reading 'slow_torrent_dl_rate_threshold': %w", err)
		}
		delete(object, "slow_torrent_dl_rate_threshold")
	}

	if raw, found := object["slow_torrent_inactive_timer"]; found {
		err = json.Unmarshal(raw, &a.SlowTorrentInactiveTimer)
		if err != nil {
			return fmt.Errorf("error reading 'slow_torrent_inactive_timer': %w", err)
		}
		delete(object, "slow_torrent_inactive_timer")
	}

	if raw, found := object["slow_torrent_ul_rate_threshold"]; found {
		err = json.Unmarshal(raw, &a.SlowTorrentUlRateThreshold)
		if err != nil {
			return fmt.Errorf("error reading 'slow_torrent_ul_rate_threshold': %w", err)
		}
		delete(object, "slow_torrent_ul_rate_threshold")
	}

	if raw, found := object["socket_backlog_size"]; found {
		err = json.Unmarshal(raw, &a.SocketBacklogSize)
		if err != nil {
			return fmt.Errorf("error reading 'socket_backlog_size': %w", err)
		}
		delete(object, "socket_backlog_size")
	}

	if raw, found := object["ssl_cert"]; found {
		err = json.Unmarshal(raw, &a.SslCert)
		if err != nil {
			return fmt.Errorf("error reading 'ssl_cert': %w", err)
		}
		delete(object, "ssl_cert")
	}

	if raw, found := object["ssl_key"]; found {
		err = json.Unmarshal(raw, &a.SslKey)
		if err != nil {
			return fmt.Errorf("error reading 'ssl_key': %w", err)
		}
		delete(object, "ssl_key")
	}

	if raw, found := object["start_paused_enabled"]; found {
		err = json.Unmarshal(raw, &a.StartPausedEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'start_paused_enabled': %w", err)
		}
		delete(object, "start_paused_enabled")
	}

	if raw, found := object["stop_tracker_timeout"]; found {
		err = json.Unmarshal(raw, &a.StopTrackerTimeout)
		if err != nil {
			return fmt.Errorf("error reading 'stop_tracker_timeout': %w", err)
		}
		delete(object, "stop_tracker_timeout")
	}

	if raw, found := object["temp_path"]; found {
		err = json.Unmarshal(raw, &a.TempPath)
		if err != nil {
			return fmt.Errorf("error reading 'temp_path': %w", err)
		}
		delete(object, "temp_path")
	}

	if raw, found := object["temp_path_enabled"]; found {
		err = json.Unmarshal(raw, &a.TempPathEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'temp_path_enabled': %w", err)
		}
		delete(object, "temp_path_enabled")
	}

	if raw, found := object["torrent_changed_tmm_enabled"]; found {
		err = json.Unmarshal(raw, &a.TorrentChangedTmmEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'torrent_changed_tmm_enabled': %w", err)
		}
		delete(object, "torrent_changed_tmm_enabled")
	}

	if raw, found := object["up_limit"]; found {
		err = json.Unmarshal(raw, &a.UpLimit)
		if err != nil {
			return fmt.Errorf("error reading 'up_limit': %w", err)
		}
		delete(object, "up_limit")
	}

	if raw, found := object["upload_choking_algorithm"]; found {
		err = json.Unmarshal(raw, &a.UploadChokingAlgorithm)
		if err != nil {
			return fmt.Errorf("error reading 'upload_choking_algorithm': %w", err)
		}
		delete(object, "upload_choking_algorithm")
	}

	if raw, found := object["upload_slots_behavior"]; found {
		err = json.Unmarshal(raw, &a.UploadSlotsBehavior)
		if err != nil {
			return fmt.Errorf("error reading 'upload_slots_behavior': %w", err)
		}
		delete(object, "upload_slots_behavior")
	}

	if raw, found := object["upnp"]; found {
		err = json.Unmarshal(raw, &a.Upnp)
		if err != nil {
			return fmt.Errorf("error reading 'upnp': %w", err)
		}
		delete(object, "upnp")
	}

	if raw, found := object["upnp_lease_duration"]; found {
		err = json.Unmarshal(raw, &a.UpnpLeaseDuration)
		if err != nil {
			return fmt.Errorf("error reading 'upnp_lease_duration': %w", err)
		}
		delete(object, "upnp_lease_duration")
	}

	if raw, found := object["use_https"]; found {
		err = json.Unmarshal(raw, &a.UseHttps)
		if err != nil {
			return fmt.Errorf("error reading 'use_https': %w", err)
		}
		delete(object, "use_https")
	}

	if raw, found := object["utp_tcp_mixed_mode"]; found {
		err = json.Unmarshal(raw, &a.UtpTcpMixedMode)
		if err != nil {
			return fmt.Errorf("error reading 'utp_tcp_mixed_mode': %w", err)
		}
		delete(object, "utp_tcp_mixed_mode")
	}

	if raw, found := object["web_ui_address"]; found {
		err = json.Unmarshal(raw, &a.WebUiAddress)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_address': %w", err)
		}
		delete(object, "web_ui_address")
	}

	if raw, found := object["web_ui_ban_duration"]; found {
		err = json.Unmarshal(raw, &a.WebUiBanDuration)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_ban_duration': %w", err)
		}
		delete(object, "web_ui_ban_duration")
	}

	if raw, found := object["web_ui_clickjacking_protection_enabled"]; found {
		err = json.Unmarshal(raw, &a.WebUiClickjackingProtectionEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_clickjacking_protection_enabled': %w", err)
		}
		delete(object, "web_ui_clickjacking_protection_enabled")
	}

	if raw, found := object["web_ui_csrf_protection_enabled"]; found {
		err = json.Unmarshal(raw, &a.WebUiCsrfProtectionEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_csrf_protection_enabled': %w", err)
		}
		delete(object, "web_ui_csrf_protection_enabled")
	}

	if raw, found := object["web_ui_custom_http_headers"]; found {
		err = json.Unmarshal(raw, &a.WebUiCustomHttpHeaders)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_custom_http_headers': %w", err)
		}
		delete(object, "web_ui_custom_http_headers")
	}

	if raw, found := object["web_ui_domain_list"]; found {
		err = json.Unmarshal(raw, &a.WebUiDomainList)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_domain_list': %w", err)
		}
		delete(object, "web_ui_domain_list")
	}

	if raw, found := object["web_ui_host_header_validation_enabled"]; found {
		err = json.Unmarshal(raw, &a.WebUiHostHeaderValidationEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_host_header_validation_enabled': %w", err)
		}
		delete(object, "web_ui_host_header_validation_enabled")
	}

	if raw, found := object["web_ui_https_cert_path"]; found {
		err = json.Unmarshal(raw, &a.WebUiHttpsCertPath)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_https_cert_path': %w", err)
		}
		delete(object, "web_ui_https_cert_path")
	}

	if raw, found := object["web_ui_https_key_path"]; found {
		err = json.Unmarshal(raw, &a.WebUiHttpsKeyPath)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_https_key_path': %w", err)
		}
		delete(object, "web_ui_https_key_path")
	}

	if raw, found := object["web_ui_max_auth_fail_count"]; found {
		err = json.Unmarshal(raw, &a.WebUiMaxAuthFailCount)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_max_auth_fail_count': %w", err)
		}
		delete(object, "web_ui_max_auth_fail_count")
	}

	if raw, found := object["web_ui_port"]; found {
		err = json.Unmarshal(raw, &a.WebUiPort)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_port': %w", err)
		}
		delete(object, "web_ui_port")
	}

	if raw, found := object["web_ui_secure_cookie_enabled"]; found {
		err = json.Unmarshal(raw, &a.WebUiSecureCookieEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_secure_cookie_enabled': %w", err)
		}
		delete(object, "web_ui_secure_cookie_enabled")
	}

	if raw, found := object["web_ui_session_timeout"]; found {
		err = json.Unmarshal(raw, &a.WebUiSessionTimeout)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_session_timeout': %w", err)
		}
		delete(object, "web_ui_session_timeout")
	}

	if raw, found := object["web_ui_upnp"]; found {
		err = json.Unmarshal(raw, &a.WebUiUpnp)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_upnp': %w", err)
		}
		delete(object, "web_ui_upnp")
	}

	if raw, found := object["web_ui_use_custom_http_headers_enabled"]; found {
		err = json.Unmarshal(raw, &a.WebUiUseCustomHttpHeadersEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_use_custom_http_headers_enabled': %w", err)
		}
		delete(object, "web_ui_use_custom_http_headers_enabled")
	}

	if raw, found := object["web_ui_username"]; found {
		err = json.Unmarshal(raw, &a.WebUiUsername)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_username': %w", err)
		}
		delete(object, "web_ui_username")
	}

	if len(object) != 0 {
		a.AdditionalProperties = make(map[string]interface{})
		for fieldName, fieldBuf := range object {
			var fieldVal interface{}
			err := json.Unmarshal(fieldBuf, &fieldVal)
			if err != nil {
				return fmt.Errorf("error unmarshaling field %s: %w", fieldName, err)
			}
			a.AdditionalProperties[fieldName] = fieldVal
		}
	}
	return nil
}

// Override default JSON handling for Preferences to handle AdditionalProperties
func (a Preferences) MarshalJSON() ([]byte, error) {
	var err error
	object := make(map[string]json.RawMessage)

	if a.AddTrackers != nil {
		object["add_trackers"], err = json.Marshal(a.AddTrackers)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'add_trackers': %w", err)
		}
	}

	if a.AddTrackersEnabled != nil {
		object["add_trackers_enabled"], err = json.Marshal(a.AddTrackersEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'add_trackers_enabled': %w", err)
		}
	}

	if a.AltDlLimit != nil {
		object["alt_dl_limit"], err = json.Marshal(a.AltDlLimit)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'alt_dl_limit': %w", err)
		}
	}

	if a.AltUpLimit != nil {
		object["alt_up_limit"], err = json.Marshal(a.AltUpLimit)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'alt_up_limit': %w", err)
		}
	}

	if a.AlternativeWebuiEnabled != nil {
		object["alternative_webui_enabled"], err = json.Marshal(a.AlternativeWebuiEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'alternative_webui_enabled': %w", err)
		}
	}

	if a.AlternativeWebuiPath != nil {
		object["alternative_webui_path"], err = json.Marshal(a.AlternativeWebuiPath)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'alternative_webui_path': %w", err)
		}
	}

	if a.AnnounceIp != nil {
		object["announce_ip"], err = json.Marshal(a.AnnounceIp)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'announce_ip': %w", err)
		}
	}

	if a.AnnounceToAllTiers != nil {
		object["announce_to_all_tiers"], err = json.Marshal(a.AnnounceToAllTiers)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'announce_to_all_tiers': %w", err)
		}
	}

	if a.AnnounceToAllTrackers != nil {
		object["announce_to_all_trackers"], err = json.Marshal(a.AnnounceToAllTrackers)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'announce_to_all_trackers': %w", err)
		}
	}

	if a.AnonymousMode != nil {
		object["anonymous_mode"], err = json.Marshal(a.AnonymousMode)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'anonymous_mode': %w", err)
		}
	}

	if a.AsyncIoThreads != nil {
		object["async_io_threads"], err = json.Marshal(a.AsyncIoThreads)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'async_io_threads': %w", err)
		}
	}

	if a.AutoDeleteMode != nil {
		object["auto_delete_mode"], err = json.Marshal(a.AutoDeleteMode)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'auto_delete_mode': %w", err)
		}
	}

	if a.AutoTmmEnabled != nil {
		object["auto_tmm_enabled"], err = json.Marshal(a.AutoTmmEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'auto_tmm_enabled': %w", err)
		}
	}

	if a.AutorunEnabled != nil {
		object["autorun_enabled"], err = json.Marshal(a.AutorunEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'autorun_enabled': %w", err)
		}
	}

	if a.AutorunProgram != nil {
		object["autorun_program"], err = json.Marshal(a.AutorunProgram)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'autorun_program': %w", err)
		}
	}

	if a.BannedIPs != nil {
		object["banned_IPs"], err = json.Marshal(a.BannedIPs)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'banned_IPs': %w", err)
		}
	}

	if a.BittorrentProtocol != nil {
		object["bittorrent_protocol"], err = json.Marshal(a.BittorrentProtocol)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'bittorrent_protocol': %w", err)
		}
	}

	if a.BypassAuthSubnetWhitelist != nil {
		object["bypass_auth_subnet_whitelist"], err = json.Marshal(a.BypassAuthSubnetWhitelist)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'bypass_auth_subnet_whitelist': %w", err)
		}
	}

	if a.BypassAuthSubnetWhitelistEnabled != nil {
		object["bypass_auth_subnet_whitelist_enabled"], err = json.Marshal(a.BypassAuthSubnetWhitelistEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'bypass_auth_subnet_whitelist_enabled': %w", err)
		}
	}

	if a.BypassLocalAuth != nil {
		object["bypass_local_auth"], err = json.Marshal(a.BypassLocalAuth)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'bypass_local_auth': %w", err)
		}
	}

	if a.CategoryChangedTmmEnabled != nil {
		object["category_changed_tmm_enabled"], err = json.Marshal(a.CategoryChangedTmmEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'category_changed_tmm_enabled': %w", err)
		}
	}

	if a.CheckingMemoryUse != nil {
		object["checking_memory_use"], err = json.Marshal(a.CheckingMemoryUse)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'checking_memory_use': %w", err)
		}
	}

	if a.CreateSubfolderEnabled != nil {
		object["create_subfolder_enabled"], err = json.Marshal(a.CreateSubfolderEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'create_subfolder_enabled': %w", err)
		}
	}

	if a.CurrentInterfaceAddress != nil {
		object["current_interface_address"], err = json.Marshal(a.CurrentInterfaceAddress)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'current_interface_address': %w", err)
		}
	}

	if a.CurrentNetworkInterface != nil {
		object["current_network_interface"], err = json.Marshal(a.CurrentNetworkInterface)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'current_network_interface': %w", err)
		}
	}

	if a.Dht != nil {
		object["dht"], err = json.Marshal(a.Dht)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'dht': %w", err)
		}
	}

	if a.DiskCache != nil {
		object["disk_cache"], err = json.Marshal(a.DiskCache)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'disk_cache': %w", err)
		}
	}

	if a.DiskCacheTtl != nil {
		object["disk_cache_ttl"], err = json.Marshal(a.DiskCacheTtl)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'disk_cache_ttl': %w", err)
		}
	}

	if a.DlLimit != nil {
		object["dl_limit"], err = json.Marshal(a.DlLimit)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'dl_limit': %w", err)
		}
	}

	if a.DontCountSlowTorrents != nil {
		object["dont_count_slow_torrents"], err = json.Marshal(a.DontCountSlowTorrents)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'dont_count_slow_torrents': %w", err)
		}
	}

	if a.DyndnsDomain != nil {
		object["dyndns_domain"], err = json.Marshal(a.DyndnsDomain)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'dyndns_domain': %w", err)
		}
	}

	if a.DyndnsEnabled != nil {
		object["dyndns_enabled"], err = json.Marshal(a.DyndnsEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'dyndns_enabled': %w", err)
		}
	}

	if a.DyndnsPassword != nil {
		object["dyndns_password"], err = json.Marshal(a.DyndnsPassword)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'dyndns_password': %w", err)
		}
	}

	if a.DyndnsService != nil {
		object["dyndns_service"], err = json.Marshal(a.DyndnsService)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'dyndns_service': %w", err)
		}
	}

	if a.DyndnsUsername != nil {
		object["dyndns_username"], err = json.Marshal(a.DyndnsUsername)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'dyndns_username': %w", err)
		}
	}

	if a.EmbeddedTrackerPort != nil {
		object["embedded_tracker_port"], err = json.Marshal(a.EmbeddedTrackerPort)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'embedded_tracker_port': %w", err)
		}
	}

	if a.EnableCoalesceReadWrite != nil {
		object["enable_coalesce_read_write"], err = json.Marshal(a.EnableCoalesceReadWrite)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'enable_coalesce_read_write': %w", err)
		}
	}

	if a.EnableEmbeddedTracker != nil {
		object["enable_embedded_tracker"], err = json.Marshal(a.EnableEmbeddedTracker)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'enable_embedded_tracker': %w", err)
		}
	}

	if a.EnableMultiConnectionsFromSameIp != nil {
		object["enable_multi_connections_from_same_ip"], err = json.Marshal(a.EnableMultiConnectionsFromSameIp)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'enable_multi_connections_from_same_ip': %w", err)
		}
	}

	if a.EnableOsCache != nil {
		object["enable_os_cache"], err = json.Marshal(a.EnableOsCache)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'enable_os_cache': %w", err)
		}
	}

	if a.EnablePieceExtentAffinity != nil {
		object["enable_piece_extent_affinity"], err = json.Marshal(a.EnablePieceExtentAffinity)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'enable_piece_extent_affinity': %w", err)
		}
	}

	if a.EnableUploadSuggestions != nil {
		object["enable_upload_suggestions"], err = json.Marshal(a.EnableUploadSuggestions)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'enable_upload_suggestions': %w", err)
		}
	}

	if a.Encryption != nil {
		object["encryption"], err = json.Marshal(a.Encryption)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'encryption': %w", err)
		}
	}

	if a.ExportDir != nil {
		object["export_dir"], err = json.Marshal(a.ExportDir)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'export_dir': %w", err)
		}
	}

	if a.ExportDirFin != nil {
		object["export_dir_fin"], err = json.Marshal(a.ExportDirFin)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'export_dir_fin': %w", err)
		}
	}

	if a.FilePoolSize != nil {
		object["file_pool_size"], err = json.Marshal(a.FilePoolSize)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'file_pool_size': %w", err)
		}
	}

	if a.IncompleteFilesExt != nil {
		object["incomplete_files_ext"], err = json.Marshal(a.IncompleteFilesExt)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'incomplete_files_ext': %w", err)
		}
	}

	if a.IpFilterEnabled != nil {
		object["ip_filter_enabled"], err = json.Marshal(a.IpFilterEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'ip_filter_enabled': %w", err)
		}
	}

	if a.IpFilterPath != nil {
		object["ip_filter_path"], err = json.Marshal(a.IpFilterPath)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'ip_filter_path': %w", err)
		}
	}

	if a.IpFilterTrackers != nil {
		object["ip_filter_trackers"], err = json.Marshal(a.IpFilterTrackers)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'ip_filter_trackers': %w", err)
		}
	}

	if a.LimitLanPeers != nil {
		object["limit_lan_peers"], err = json.Marshal(a.LimitLanPeers)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'limit_lan_peers': %w", err)
		}
	}

	if a.LimitTcpOverhead != nil {
		object["limit_tcp_overhead"], err = json.Marshal(a.LimitTcpOverhead)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'limit_tcp_overhead': %w", err)
		}
	}

	if a.LimitUtpRate != nil {
		object["limit_utp_rate"], err = json.Marshal(a.LimitUtpRate)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'limit_utp_rate': %w", err)
		}
	}

	if a.ListenPort != nil {
		object["listen_port"], err = json.Marshal(a.ListenPort)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'listen_port': %w", err)
		}
	}

	if a.Locale != nil {
		object["locale"], err = json.Marshal(a.Locale)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'locale': %w", err)
		}
	}

	if a.Lsd != nil {
		object["lsd"], err = json.Marshal(a.Lsd)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'lsd': %w", err)
		}
	}

	if a.MailNotificationAuthEnabled != nil {
		object["mail_notification_auth_enabled"], err = json.Marshal(a.MailNotificationAuthEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'mail_notification_auth_enabled': %w", err)
		}
	}

	if a.MailNotificationEmail != nil {
		object["mail_notification_email"], err = json.Marshal(a.MailNotificationEmail)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'mail_notification_email': %w", err)
		}
	}

	if a.MailNotificationEnabled != nil {
		object["mail_notification_enabled"], err = json.Marshal(a.MailNotificationEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'mail_notification_enabled': %w", err)
		}
	}

	if a.MailNotificationPassword != nil {
		object["mail_notification_password"], err = json.Marshal(a.MailNotificationPassword)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'mail_notification_password': %w", err)
		}
	}

	if a.MailNotificationSender != nil {
		object["mail_notification_sender"], err = json.Marshal(a.MailNotificationSender)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'mail_notification_sender': %w", err)
		}
	}

	if a.MailNotificationSmtp != nil {
		object["mail_notification_smtp"], err = json.Marshal(a.MailNotificationSmtp)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'mail_notification_smtp': %w", err)
		}
	}

	if a.MailNotificationSslEnabled != nil {
		object["mail_notification_ssl_enabled"], err = json.Marshal(a.MailNotificationSslEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'mail_notification_ssl_enabled': %w", err)
		}
	}

	if a.MailNotificationUsername != nil {
		object["mail_notification_username"], err = json.Marshal(a.MailNotificationUsername)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'mail_notification_username': %w", err)
		}
	}

	if a.MaxActiveDownloads != nil {
		object["max_active_downloads"], err = json.Marshal(a.MaxActiveDownloads)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_active_downloads': %w", err)
		}
	}

	if a.MaxActiveTorrents != nil {
		object["max_active_torrents"], err = json.Marshal(a.MaxActiveTorrents)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_active_torrents': %w", err)
		}
	}

	if a.MaxActiveUploads != nil {
		object["max_active_uploads"], err = json.Marshal(a.MaxActiveUploads)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_active_uploads': %w", err)
		}
	}

	if a.MaxConnec != nil {
		object["max_connec"], err = json.Marshal(a.MaxConnec)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_connec': %w", err)
		}
	}

	if a.MaxConnecPerTorrent != nil {
		object["max_connec_per_torrent"], err = json.Marshal(a.MaxConnecPerTorrent)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_connec_per_torrent': %w", err)
		}
	}

	if a.MaxRatio != nil {
		object["max_ratio"], err = json.Marshal(a.MaxRatio)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_ratio': %w", err)
		}
	}

	if a.MaxRatioAct != nil {
		object["max_ratio_act"], err = json.Marshal(a.MaxRatioAct)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_ratio_act': %w", err)
		}
	}

	if a.MaxRatioEnabled != nil {
		object["max_ratio_enabled"], err = json.Marshal(a.MaxRatioEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_ratio_enabled': %w", err)
		}
	}

	if a.MaxSeedingTime != nil {
		object["max_seeding_time"], err = json.Marshal(a.MaxSeedingTime)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_seeding_time': %w", err)
		}
	}

	if a.MaxSeedingTimeEnabled != nil {
		object["max_seeding_time_enabled"], err = json.Marshal(a.MaxSeedingTimeEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_seeding_time_enabled': %w", err)
		}
	}

	if a.MaxUploads != nil {
		object["max_uploads"], err = json.Marshal(a.MaxUploads)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_uploads': %w", err)
		}
	}

	if a.MaxUploadsPerTorrent != nil {
		object["max_uploads_per_torrent"], err = json.Marshal(a.MaxUploadsPerTorrent)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_uploads_per_torrent': %w", err)
		}
	}

	if a.OutgoingPortsMax != nil {
		object["outgoing_ports_max"], err = json.Marshal(a.OutgoingPortsMax)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'outgoing_ports_max': %w", err)
		}
	}

	if a.OutgoingPortsMin != nil {
		object["outgoing_ports_min"], err = json.Marshal(a.OutgoingPortsMin)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'outgoing_ports_min': %w", err)
		}
	}

	if a.Pex != nil {
		object["pex"], err = json.Marshal(a.Pex)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'pex': %w", err)
		}
	}

	if a.PreallocateAll != nil {
		object["preallocate_all"], err = json.Marshal(a.PreallocateAll)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'preallocate_all': %w", err)
		}
	}

	if a.ProxyAuthEnabled != nil {
		object["proxy_auth_enabled"], err = json.Marshal(a.ProxyAuthEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'proxy_auth_enabled': %w", err)
		}
	}

	if a.ProxyIp != nil {
		object["proxy_ip"], err = json.Marshal(a.ProxyIp)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'proxy_ip': %w", err)
		}
	}

	if a.ProxyPassword != nil {
		object["proxy_password"], err = json.Marshal(a.ProxyPassword)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'proxy_password': %w", err)
		}
	}

	if a.ProxyPeerConnections != nil {
		object["proxy_peer_connections"], err = json.Marshal(a.ProxyPeerConnections)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'proxy_peer_connections': %w", err)
		}
	}

	if a.ProxyPort != nil {
		object["proxy_port"], err = json.Marshal(a.ProxyPort)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'proxy_port': %w", err)
		}
	}

	if a.ProxyTorrentsOnly != nil {
		object["proxy_torrents_only"], err = json.Marshal(a.ProxyTorrentsOnly)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'proxy_torrents_only': %w", err)
		}
	}

	if a.ProxyType != nil {
		object["proxy_type"], err = json.Marshal(a.ProxyType)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'proxy_type': %w", err)
		}
	}

	if a.ProxyUsername != nil {
		object["proxy_username"], err = json.Marshal(a.ProxyUsername)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'proxy_username': %w", err)
		}
	}

	if a.QueueingEnabled != nil {
		object["queueing_enabled"], err = json.Marshal(a.QueueingEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'queueing_enabled': %w", err)
		}
	}

	if a.RandomPort != nil {
		object["random_port"], err = json.Marshal(a.RandomPort)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'random_port': %w", err)
		}
	}

	if a.RecheckCompletedTorrents != nil {
		object["recheck_completed_torrents"], err = json.Marshal(a.RecheckCompletedTorrents)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'recheck_completed_torrents': %w", err)
		}
	}

	if a.ResolvePeerCountries != nil {
		object["resolve_peer_countries"], err = json.Marshal(a.ResolvePeerCountries)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'resolve_peer_countries': %w", err)
		}
	}

	if a.RssAutoDownloadingEnabled != nil {
		object["rss_auto_downloading_enabled"], err = json.Marshal(a.RssAutoDownloadingEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'rss_auto_downloading_enabled': %w", err)
		}
	}

	if a.RssDownloadRepackProperEpisodes != nil {
		object["rss_download_repack_proper_episodes"], err = json.Marshal(a.RssDownloadRepackProperEpisodes)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'rss_download_repack_proper_episodes': %w", err)
		}
	}

	if a.RssMaxArticlesPerFeed != nil {
		object["rss_max_articles_per_feed"], err = json.Marshal(a.RssMaxArticlesPerFeed)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'rss_max_articles_per_feed': %w", err)
		}
	}

	if a.RssProcessingEnabled != nil {
		object["rss_processing_enabled"], err = json.Marshal(a.RssProcessingEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'rss_processing_enabled': %w", err)
		}
	}

	if a.RssRefreshInterval != nil {
		object["rss_refresh_interval"], err = json.Marshal(a.RssRefreshInterval)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'rss_refresh_interval': %w", err)
		}
	}

	if a.RssSmartEpisodeFilters != nil {
		object["rss_smart_episode_filters"], err = json.Marshal(a.RssSmartEpisodeFilters)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'rss_smart_episode_filters': %w", err)
		}
	}

	if a.SavePath != nil {
		object["save_path"], err = json.Marshal(a.SavePath)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'save_path': %w", err)
		}
	}

	if a.SavePathChangedTmmEnabled != nil {
		object["save_path_changed_tmm_enabled"], err = json.Marshal(a.SavePathChangedTmmEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'save_path_changed_tmm_enabled': %w", err)
		}
	}

	if a.SaveResumeDataInterval != nil {
		object["save_resume_data_interval"], err = json.Marshal(a.SaveResumeDataInterval)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'save_resume_data_interval': %w", err)
		}
	}

	if a.ScanDirs != nil {
		object["scan_dirs"], err = json.Marshal(a.ScanDirs)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'scan_dirs': %w", err)
		}
	}

	if a.ScheduleFromHour != nil {
		object["schedule_from_hour"], err = json.Marshal(a.ScheduleFromHour)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'schedule_from_hour': %w", err)
		}
	}

	if a.ScheduleFromMin != nil {
		object["schedule_from_min"], err = json.Marshal(a.ScheduleFromMin)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'schedule_from_min': %w", err)
		}
	}

	if a.ScheduleToHour != nil {
		object["schedule_to_hour"], err = json.Marshal(a.ScheduleToHour)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'schedule_to_hour': %w", err)
		}
	}

	if a.ScheduleToMin != nil {
		object["schedule_to_min"], err = json.Marshal(a.ScheduleToMin)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'schedule_to_min': %w", err)
		}
	}

	if a.SchedulerDays != nil {
		object["scheduler_days"], err = json.Marshal(a.SchedulerDays)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'scheduler_days': %w", err)
		}
	}

	if a.SchedulerEnabled != nil {
		object["scheduler_enabled"], err = json.Marshal(a.SchedulerEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'scheduler_enabled': %w", err)
		}
	}

	if a.SendBufferLowWatermark != nil {
		object["send_buffer_low_watermark"], err = json.Marshal(a.SendBufferLowWatermark)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'send_buffer_low_watermark': %w", err)
		}
	}

	if a.SendBufferWatermark != nil {
		object["send_buffer_watermark"], err = json.Marshal(a.SendBufferWatermark)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'send_buffer_watermark': %w", err)
		}
	}

	if a.SendBufferWatermarkFactor != nil {
		object["send_buffer_watermark_factor"], err = json.Marshal(a.SendBufferWatermarkFactor)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'send_buffer_watermark_factor': %w", err)
		}
	}

	if a.SlowTorrentDlRateThreshold != nil {
		object["slow_torrent_dl_rate_threshold"], err = json.Marshal(a.SlowTorrentDlRateThreshold)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'slow_torrent_dl_rate_threshold': %w", err)
		}
	}

	if a.SlowTorrentInactiveTimer != nil {
		object["slow_torrent_inactive_timer"], err = json.Marshal(a.SlowTorrentInactiveTimer)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'slow_torrent_inactive_timer': %w", err)
		}
	}

	if a.SlowTorrentUlRateThreshold != nil {
		object["slow_torrent_ul_rate_threshold"], err = json.Marshal(a.SlowTorrentUlRateThreshold)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'slow_torrent_ul_rate_threshold': %w", err)
		}
	}

	if a.SocketBacklogSize != nil {
		object["socket_backlog_size"], err = json.Marshal(a.SocketBacklogSize)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'socket_backlog_size': %w", err)
		}
	}

	if a.SslCert != nil {
		object["ssl_cert"], err = json.Marshal(a.SslCert)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'ssl_cert': %w", err)
		}
	}

	if a.SslKey != nil {
		object["ssl_key"], err = json.Marshal(a.SslKey)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'ssl_key': %w", err)
		}
	}

	if a.StartPausedEnabled != nil {
		object["start_paused_enabled"], err = json.Marshal(a.StartPausedEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'start_paused_enabled': %w", err)
		}
	}

	if a.StopTrackerTimeout != nil {
		object["stop_tracker_timeout"], err = json.Marshal(a.StopTrackerTimeout)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'stop_tracker_timeout': %w", err)
		}
	}

	if a.TempPath != nil {
		object["temp_path"], err = json.Marshal(a.TempPath)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'temp_path': %w", err)
		}
	}

	if a.TempPathEnabled != nil {
		object["temp_path_enabled"], err = json.Marshal(a.TempPathEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'temp_path_enabled': %w", err)
		}
	}

	if a.TorrentChangedTmmEnabled != nil {
		object["torrent_changed_tmm_enabled"], err = json.Marshal(a.TorrentChangedTmmEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'torrent_changed_tmm_enabled': %w", err)
		}
	}

	if a.UpLimit != nil {
		object["up_limit"], err = json.Marshal(a.UpLimit)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'up_limit': %w", err)
		}
	}

	if a.UploadChokingAlgorithm != nil {
		object["upload_choking_algorithm"], err = json.Marshal(a.UploadChokingAlgorithm)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'upload_choking_algorithm': %w", err)
		}
	}

	if a.UploadSlotsBehavior != nil {
		object["upload_slots_behavior"], err = json.Marshal(a.UploadSlotsBehavior)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'upload_slots_behavior': %w", err)
		}
	}

	if a.Upnp != nil {
		object["upnp"], err = json.Marshal(a.Upnp)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'upnp': %w", err)
		}
	}

	if a.UpnpLeaseDuration != nil {
		object["upnp_lease_duration"], err = json.Marshal(a.UpnpLeaseDuration)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'upnp_lease_duration': %w", err)
		}
	}

	if a.UseHttps != nil {
		object["use_https"], err = json.Marshal(a.UseHttps)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'use_https': %w", err)
		}
	}

	if a.UtpTcpMixedMode != nil {
		object["utp_tcp_mixed_mode"], err = json.Marshal(a.UtpTcpMixedMode)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'utp_tcp_mixed_mode': %w", err)
		}
	}

	if a.WebUiAddress != nil {
		object["web_ui_address"], err = json.Marshal(a.WebUiAddress)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_address': %w", err)
		}
	}

	if a.WebUiBanDuration != nil {
		object["web_ui_ban_duration"], err = json.Marshal(a.WebUiBanDuration)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_ban_duration': %w", err)
		}
	}

	if a.WebUiClickjackingProtectionEnabled != nil {
		object["web_ui_clickjacking_protection_enabled"], err = json.Marshal(a.WebUiClickjackingProtectionEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_clickjacking_protection_enabled': %w", err)
		}
	}

	if a.WebUiCsrfProtectionEnabled != nil {
		object["web_ui_csrf_protection_enabled"], err = json.Marshal(a.WebUiCsrfProtectionEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_csrf_protection_enabled': %w", err)
		}
	}

	if a.WebUiCustomHttpHeaders != nil {
		object["web_ui_custom_http_headers"], err = json.Marshal(a.WebUiCustomHttpHeaders)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_custom_http_headers': %w", err)
		}
	}

	if a.WebUiDomainList != nil {
		object["web_ui_domain_list"], err = json.Marshal(a.WebUiDomainList)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_domain_list': %w", err)
		}
	}

	if a.WebUiHostHeaderValidationEnabled != nil {
		object["web_ui_host_header_validation_enabled"], err = json.Marshal(a.WebUiHostHeaderValidationEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_host_header_validation_enabled': %w", err)
		}
	}

	if a.WebUiHttpsCertPath != nil {
		object["web_ui_https_cert_path"], err = json.Marshal(a.WebUiHttpsCertPath)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_https_cert_path': %w", err)
		}
	}

	if a.WebUiHttpsKeyPath != nil {
		object["web_ui_https_key_path"], err = json.Marshal(a.WebUiHttpsKeyPath)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_https_key_path': %w", err)
		}
	}

	if a.WebUiMaxAuthFailCount != nil {
		object["web_ui_max_auth_fail_count"], err = json.Marshal(a.WebUiMaxAuthFailCount)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_max_auth_fail_count': %w", err)
		}
	}

	if a.WebUiPort != nil {
		object["web_ui_port"], err = json.Marshal(a.WebUiPort)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_port': %w", err)
		}
	}

	if a.WebUiSecureCookieEnabled != nil {
		object["web_ui_secure_cookie_enabled"], err = json.Marshal(a.WebUiSecureCookieEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_secure_cookie_enabled': %w", err)
		}
	}

	if a.WebUiSessionTimeout != nil {
		object["web_ui_session_timeout"], err = json.Marshal(a.WebUiSessionTimeout)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_session_timeout': %w", err)
		}
	}

	if a.WebUiUpnp != nil {
		object["web_ui_upnp"], err = json.Marshal(a.WebUiUpnp)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_upnp': %w", err)
		}
	}

	if a.WebUiUseCustomHttpHeadersEnabled != nil {
		object["web_ui_use_custom_http_headers_enabled"], err = json.Marshal(a.WebUiUseCustomHttpHeadersEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_use_custom_http_headers_enabled': %w", err)
		}
	}

	if a.WebUiUsername != nil {
		object["web_ui_username"], err = json.Marshal(a.WebUiUsername)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_username': %w", err)
		}
	}

	for fieldName, field := range a.AdditionalProperties {
		object[fieldName], err = json.Marshal(field)
		if err != nil {
			return nil, fmt.Errorf("error marshaling '%s': %w", fieldName, err)
		}
	}
	return json.Marshal(object)
}

// Getter for additional properties for SetPreferences. Returns the specified
// element and whether it was found
func (a SetPreferences) Get(fieldName string) (value interface{}, found bool) {
	if a.AdditionalProperties != nil {
		value, found = a.AdditionalProperties[fieldName]
	}
	return
}

// Setter for additional properties for SetPreferences
func (a *SetPreferences) Set(fieldName string, value interface{}) {
	if a.AdditionalProperties == nil {
		a.AdditionalProperties = make(map[string]interface{})
	}
	a.AdditionalProperties[fieldName] = value
}

// Override default JSON handling for SetPreferences to handle AdditionalProperties
func (a *SetPreferences) UnmarshalJSON(b []byte) error {
	object := make(map[string]json.RawMessage)
	err := json.Unmarshal(b, &object)
	if err != nil {
		return err
	}

	if raw, found := object["add_trackers"]; found {
		err = json.Unmarshal(raw, &a.AddTrackers)
		if err != nil {
			return fmt.Errorf("error reading 'add_trackers': %w", err)
		}
		delete(object, "add_trackers")
	}

	if raw, found := object["add_trackers_enabled"]; found {
		err = json.Unmarshal(raw, &a.AddTrackersEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'add_trackers_enabled': %w", err)
		}
		delete(object, "add_trackers_enabled")
	}

	if raw, found := object["alt_dl_limit"]; found {
		err = json.Unmarshal(raw, &a.AltDlLimit)
		if err != nil {
			return fmt.Errorf("error reading 'alt_dl_limit': %w", err)
		}
		delete(object, "alt_dl_limit")
	}

	if raw, found := object["alt_up_limit"]; found {
		err = json.Unmarshal(raw, &a.AltUpLimit)
		if err != nil {
			return fmt.Errorf("error reading 'alt_up_limit': %w", err)
		}
		delete(object, "alt_up_limit")
	}

	if raw, found := object["alternative_webui_enabled"]; found {
		err = json.Unmarshal(raw, &a.AlternativeWebuiEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'alternative_webui_enabled': %w", err)
		}
		delete(object, "alternative_webui_enabled")
	}

	if raw, found := object["alternative_webui_path"]; found {
		err = json.Unmarshal(raw, &a.AlternativeWebuiPath)
		if err != nil {
			return fmt.Errorf("error reading 'alternative_webui_path': %w", err)
		}
		delete(object, "alternative_webui_path")
	}

	if raw, found := object["announce_ip"]; found {
		err = json.Unmarshal(raw, &a.AnnounceIp)
		if err != nil {
			return fmt.Errorf("error reading 'announce_ip': %w", err)
		}
		delete(object, "announce_ip")
	}

	if raw, found := object["announce_to_all_tiers"]; found {
		err = json.Unmarshal(raw, &a.AnnounceToAllTiers)
		if err != nil {
			return fmt.Errorf("error reading 'announce_to_all_tiers': %w", err)
		}
		delete(object, "announce_to_all_tiers")
	}

	if raw, found := object["announce_to_all_trackers"]; found {
		err = json.Unmarshal(raw, &a.AnnounceToAllTrackers)
		if err != nil {
			return fmt.Errorf("error reading 'announce_to_all_trackers': %w", err)
		}
		delete(object, "announce_to_all_trackers")
	}

	if raw, found := object["anonymous_mode"]; found {
		err = json.Unmarshal(raw, &a.AnonymousMode)
		if err != nil {
			return fmt.Errorf("error reading 'anonymous_mode': %w", err)
		}
		delete(object, "anonymous_mode")
	}

	if raw, found := object["async_io_threads"]; found {
		err = json.Unmarshal(raw, &a.AsyncIoThreads)
		if err != nil {
			return fmt.Errorf("error reading 'async_io_threads': %w", err)
		}
		delete(object, "async_io_threads")
	}

	if raw, found := object["auto_delete_mode"]; found {
		err = json.Unmarshal(raw, &a.AutoDeleteMode)
		if err != nil {
			return fmt.Errorf("error reading 'auto_delete_mode': %w", err)
		}
		delete(object, "auto_delete_mode")
	}

	if raw, found := object["auto_tmm_enabled"]; found {
		err = json.Unmarshal(raw, &a.AutoTmmEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'auto_tmm_enabled': %w", err)
		}
		delete(object, "auto_tmm_enabled")
	}

	if raw, found := object["autorun_enabled"]; found {
		err = json.Unmarshal(raw, &a.AutorunEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'autorun_enabled': %w", err)
		}
		delete(object, "autorun_enabled")
	}

	if raw, found := object["autorun_program"]; found {
		err = json.Unmarshal(raw, &a.AutorunProgram)
		if err != nil {
			return fmt.Errorf("error reading 'autorun_program': %w", err)
		}
		delete(object, "autorun_program")
	}

	if raw, found := object["banned_IPs"]; found {
		err = json.Unmarshal(raw, &a.BannedIPs)
		if err != nil {
			return fmt.Errorf("error reading 'banned_IPs': %w", err)
		}
		delete(object, "banned_IPs")
	}

	if raw, found := object["bittorrent_protocol"]; found {
		err = json.Unmarshal(raw, &a.BittorrentProtocol)
		if err != nil {
			return fmt.Errorf("error reading 'bittorrent_protocol': %w", err)
		}
		delete(object, "bittorrent_protocol")
	}

	if raw, found := object["bypass_auth_subnet_whitelist"]; found {
		err = json.Unmarshal(raw, &a.BypassAuthSubnetWhitelist)
		if err != nil {
			return fmt.Errorf("error reading 'bypass_auth_subnet_whitelist': %w", err)
		}
		delete(object, "bypass_auth_subnet_whitelist")
	}

	if raw, found := object["bypass_auth_subnet_whitelist_enabled"]; found {
		err = json.Unmarshal(raw, &a.BypassAuthSubnetWhitelistEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'bypass_auth_subnet_whitelist_enabled': %w", err)
		}
		delete(object, "bypass_auth_subnet_whitelist_enabled")
	}

	if raw, found := object["bypass_local_auth"]; found {
		err = json.Unmarshal(raw, &a.BypassLocalAuth)
		if err != nil {
			return fmt.Errorf("error reading 'bypass_local_auth': %w", err)
		}
		delete(object, "bypass_local_auth")
	}

	if raw, found := object["category_changed_tmm_enabled"]; found {
		err = json.Unmarshal(raw, &a.CategoryChangedTmmEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'category_changed_tmm_enabled': %w", err)
		}
		delete(object, "category_changed_tmm_enabled")
	}

	if raw, found := object["checking_memory_use"]; found {
		err = json.Unmarshal(raw, &a.CheckingMemoryUse)
		if err != nil {
			return fmt.Errorf("error reading 'checking_memory_use': %w", err)
		}
		delete(object, "checking_memory_use")
	}

	if raw, found := object["create_subfolder_enabled"]; found {
		err = json.Unmarshal(raw, &a.CreateSubfolderEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'create_subfolder_enabled': %w", err)
		}
		delete(object, "create_subfolder_enabled")
	}

	if raw, found := object["current_interface_address"]; found {
		err = json.Unmarshal(raw, &a.CurrentInterfaceAddress)
		if err != nil {
			return fmt.Errorf("error reading 'current_interface_address': %w", err)
		}
		delete(object, "current_interface_address")
	}

	if raw, found := object["current_network_interface"]; found {
		err = json.Unmarshal(raw, &a.CurrentNetworkInterface)
		if err != nil {
			return fmt.Errorf("error reading 'current_network_interface': %w", err)
		}
		delete(object, "current_network_interface")
	}

	if raw, found := object["dht"]; found {
		err = json.Unmarshal(raw, &a.Dht)
		if err != nil {
			return fmt.Errorf("error reading 'dht': %w", err)
		}
		delete(object, "dht")
	}

	if raw, found := object["disk_cache"]; found {
		err = json.Unmarshal(raw, &a.DiskCache)
		if err != nil {
			return fmt.Errorf("error reading 'disk_cache': %w", err)
		}
		delete(object, "disk_cache")
	}

	if raw, found := object["disk_cache_ttl"]; found {
		err = json.Unmarshal(raw, &a.DiskCacheTtl)
		if err != nil {
			return fmt.Errorf("error reading 'disk_cache_ttl': %w", err)
		}
		delete(object, "disk_cache_ttl")
	}

	if raw, found := object["dl_limit"]; found {
		err = json.Unmarshal(raw, &a.DlLimit)
		if err != nil {
			return fmt.Errorf("error reading 'dl_limit': %w", err)
		}
		delete(object, "dl_limit")
	}

	if raw, found := object["dont_count_slow_torrents"]; found {
		err = json.Unmarshal(raw, &a.DontCountSlowTorrents)
		if err != nil {
			return fmt.Errorf("error reading 'dont_count_slow_torrents': %w", err)
		}
		delete(object, "dont_count_slow_torrents")
	}

	if raw, found := object["dyndns_domain"]; found {
		err = json.Unmarshal(raw, &a.DyndnsDomain)
		if err != nil {
			return fmt.Errorf("error reading 'dyndns_domain': %w", err)
		}
		delete(object, "dyndns_domain")
	}

	if raw, found := object["dyndns_enabled"]; found {
		err = json.Unmarshal(raw, &a.DyndnsEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'dyndns_enabled': %w", err)
		}
		delete(object, "dyndns_enabled")
	}

	if raw, found := object["dyndns_password"]; found {
		err = json.Unmarshal(raw, &a.DyndnsPassword)
		if err != nil {
			return fmt.Errorf("error reading 'dyndns_password': %w", err)
		}
		delete(object, "dyndns_password")
	}

	if raw, found := object["dyndns_service"]; found {
		err = json.Unmarshal(raw, &a.DyndnsService)
		if err != nil {
			return fmt.Errorf("error reading 'dyndns_service': %w", err)
		}
		delete(object, "dyndns_service")
	}

	if raw, found := object["dyndns_username"]; found {
		err = json.Unmarshal(raw, &a.DyndnsUsername)
		if err != nil {
			return fmt.Errorf("error reading 'dyndns_username': %w", err)
		}
		delete(object, "dyndns_username")
	}

	if raw, found := object["embedded_tracker_port"]; found {
		err = json.Unmarshal(raw, &a.EmbeddedTrackerPort)
		if err != nil {
			return fmt.Errorf("error reading 'embedded_tracker_port': %w", err)
		}
		delete(object, "embedded_tracker_port")
	}

	if raw, found := object["enable_coalesce_read_write"]; found {
		err = json.Unmarshal(raw, &a.EnableCoalesceReadWrite)
		if err != nil {
			return fmt.Errorf("error reading 'enable_coalesce_read_write': %w", err)
		}
		delete(object, "enable_coalesce_read_write")
	}

	if raw, found := object["enable_embedded_tracker"]; found {
		err = json.Unmarshal(raw, &a.EnableEmbeddedTracker)
		if err != nil {
			return fmt.Errorf("error reading 'enable_embedded_tracker': %w", err)
		}
		delete(object, "enable_embedded_tracker")
	}

	if raw, found := object["enable_multi_connections_from_same_ip"]; found {
		err = json.Unmarshal(raw, &a.EnableMultiConnectionsFromSameIp)
		if err != nil {
			return fmt.Errorf("error reading 'enable_multi_connections_from_same_ip': %w", err)
		}
		delete(object, "enable_multi_connections_from_same_ip")
	}

	if raw, found := object["enable_os_cache"]; found {
		err = json.Unmarshal(raw, &a.EnableOsCache)
		if err != nil {
			return fmt.Errorf("error reading 'enable_os_cache': %w", err)
		}
		delete(object, "enable_os_cache")
	}

	if raw, found := object["enable_piece_extent_affinity"]; found {
		err = json.Unmarshal(raw, &a.EnablePieceExtentAffinity)
		if err != nil {
			return fmt.Errorf("error reading 'enable_piece_extent_affinity': %w", err)
		}
		delete(object, "enable_piece_extent_affinity")
	}

	if raw, found := object["enable_upload_suggestions"]; found {
		err = json.Unmarshal(raw, &a.EnableUploadSuggestions)
		if err != nil {
			return fmt.Errorf("error reading 'enable_upload_suggestions': %w", err)
		}
		delete(object, "enable_upload_suggestions")
	}

	if raw, found := object["encryption"]; found {
		err = json.Unmarshal(raw, &a.Encryption)
		if err != nil {
			return fmt.Errorf("error reading 'encryption': %w", err)
		}
		delete(object, "encryption")
	}

	if raw, found := object["export_dir"]; found {
		err = json.Unmarshal(raw, &a.ExportDir)
		if err != nil {
			return fmt.Errorf("error reading 'export_dir': %w", err)
		}
		delete(object, "export_dir")
	}

	if raw, found := object["export_dir_fin"]; found {
		err = json.Unmarshal(raw, &a.ExportDirFin)
		if err != nil {
			return fmt.Errorf("error reading 'export_dir_fin': %w", err)
		}
		delete(object, "export_dir_fin")
	}

	if raw, found := object["file_pool_size"]; found {
		err = json.Unmarshal(raw, &a.FilePoolSize)
		if err != nil {
			return fmt.Errorf("error reading 'file_pool_size': %w", err)
		}
		delete(object, "file_pool_size")
	}

	if raw, found := object["incomplete_files_ext"]; found {
		err = json.Unmarshal(raw, &a.IncompleteFilesExt)
		if err != nil {
			return fmt.Errorf("error reading 'incomplete_files_ext': %w", err)
		}
		delete(object, "incomplete_files_ext")
	}

	if raw, found := object["ip_filter_enabled"]; found {
		err = json.Unmarshal(raw, &a.IpFilterEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'ip_filter_enabled': %w", err)
		}
		delete(object, "ip_filter_enabled")
	}

	if raw, found := object["ip_filter_path"]; found {
		err = json.Unmarshal(raw, &a.IpFilterPath)
		if err != nil {
			return fmt.Errorf("error reading 'ip_filter_path': %w", err)
		}
		delete(object, "ip_filter_path")
	}

	if raw, found := object["ip_filter_trackers"]; found {
		err = json.Unmarshal(raw, &a.IpFilterTrackers)
		if err != nil {
			return fmt.Errorf("error reading 'ip_filter_trackers': %w", err)
		}
		delete(object, "ip_filter_trackers")
	}

	if raw, found := object["limit_lan_peers"]; found {
		err = json.Unmarshal(raw, &a.LimitLanPeers)
		if err != nil {
			return fmt.Errorf("error reading 'limit_lan_peers': %w", err)
		}
		delete(object, "limit_lan_peers")
	}

	if raw, found := object["limit_tcp_overhead"]; found {
		err = json.Unmarshal(raw, &a.LimitTcpOverhead)
		if err != nil {
			return fmt.Errorf("error reading 'limit_tcp_overhead': %w", err)
		}
		delete(object, "limit_tcp_overhead")
	}

	if raw, found := object["limit_utp_rate"]; found {
		err = json.Unmarshal(raw, &a.LimitUtpRate)
		if err != nil {
			return fmt.Errorf("error reading 'limit_utp_rate': %w", err)
		}
		delete(object, "limit_utp_rate")
	}

	if raw, found := object["listen_port"]; found {
		err = json.Unmarshal(raw, &a.ListenPort)
		if err != nil {
			return fmt.Errorf("error reading 'listen_port': %w", err)
		}
		delete(object, "listen_port")
	}

	if raw, found := object["locale"]; found {
		err = json.Unmarshal(raw, &a.Locale)
		if err != nil {
			return fmt.Errorf("error reading 'locale': %w", err)
		}
		delete(object, "locale")
	}

	if raw, found := object["lsd"]; found {
		err = json.Unmarshal(raw, &a.Lsd)
		if err != nil {
			return fmt.Errorf("error reading 'lsd': %w", err)
		}
		delete(object, "lsd")
	}

	if raw, found := object["mail_notification_auth_enabled"]; found {
		err = json.Unmarshal(raw, &a.MailNotificationAuthEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'mail_notification_auth_enabled': %w", err)
		}
		delete(object, "mail_notification_auth_enabled")
	}

	if raw, found := object["mail_notification_email"]; found {
		err = json.Unmarshal(raw, &a.MailNotificationEmail)
		if err != nil {
			return fmt.Errorf("error reading 'mail_notification_email': %w", err)
		}
		delete(object, "mail_notification_email")
	}

	if raw, found := object["mail_notification_enabled"]; found {
		err = json.Unmarshal(raw, &a.MailNotificationEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'mail_notification_enabled': %w", err)
		}
		delete(object, "mail_notification_enabled")
	}

	if raw, found := object["mail_notification_password"]; found {
		err = json.Unmarshal(raw, &a.MailNotificationPassword)
		if err != nil {
			return fmt.Errorf("error reading 'mail_notification_password': %w", err)
		}
		delete(object, "mail_notification_password")
	}

	if raw, found := object["mail_notification_sender"]; found {
		err = json.Unmarshal(raw, &a.MailNotificationSender)
		if err != nil {
			return fmt.Errorf("error reading 'mail_notification_sender': %w", err)
		}
		delete(object, "mail_notification_sender")
	}

	if raw, found := object["mail_notification_smtp"]; found {
		err = json.Unmarshal(raw, &a.MailNotificationSmtp)
		if err != nil {
			return fmt.Errorf("error reading 'mail_notification_smtp': %w", err)
		}
		delete(object, "mail_notification_smtp")
	}

	if raw, found := object["mail_notification_ssl_enabled"]; found {
		err = json.Unmarshal(raw, &a.MailNotificationSslEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'mail_notification_ssl_enabled': %w", err)
		}
		delete(object, "mail_notification_ssl_enabled")
	}

	if raw, found := object["mail_notification_username"]; found {
		err = json.Unmarshal(raw, &a.MailNotificationUsername)
		if err != nil {
			return fmt.Errorf("error reading 'mail_notification_username': %w", err)
		}
		delete(object, "mail_notification_username")
	}

	if raw, found := object["max_active_downloads"]; found {
		err = json.Unmarshal(raw, &a.MaxActiveDownloads)
		if err != nil {
			return fmt.Errorf("error reading 'max_active_downloads': %w", err)
		}
		delete(object, "max_active_downloads")
	}

	if raw, found := object["max_active_torrents"]; found {
		err = json.Unmarshal(raw, &a.MaxActiveTorrents)
		if err != nil {
			return fmt.Errorf("error reading 'max_active_torrents': %w", err)
		}
		delete(object, "max_active_torrents")
	}

	if raw, found := object["max_active_uploads"]; found {
		err = json.Unmarshal(raw, &a.MaxActiveUploads)
		if err != nil {
			return fmt.Errorf("error reading 'max_active_uploads': %w", err)
		}
		delete(object, "max_active_uploads")
	}

	if raw, found := object["max_connec"]; found {
		err = json.Unmarshal(raw, &a.MaxConnec)
		if err != nil {
			return fmt.Errorf("error reading 'max_connec': %w", err)
		}
		delete(object, "max_connec")
	}

	if raw, found := object["max_connec_per_torrent"]; found {
		err = json.Unmarshal(raw, &a.MaxConnecPerTorrent)
		if err != nil {
			return fmt.Errorf("error reading 'max_connec_per_torrent': %w", err)
		}
		delete(object, "max_connec_per_torrent")
	}

	if raw, found := object["max_ratio"]; found {
		err = json.Unmarshal(raw, &a.MaxRatio)
		if err != nil {
			return fmt.Errorf("error reading 'max_ratio': %w", err)
		}
		delete(object, "max_ratio")
	}

	if raw, found := object["max_ratio_act"]; found {
		err = json.Unmarshal(raw, &a.MaxRatioAct)
		if err != nil {
			return fmt.Errorf("error reading 'max_ratio_act': %w", err)
		}
		delete(object, "max_ratio_act")
	}

	if raw, found := object["max_ratio_enabled"]; found {
		err = json.Unmarshal(raw, &a.MaxRatioEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'max_ratio_enabled': %w", err)
		}
		delete(object, "max_ratio_enabled")
	}

	if raw, found := object["max_seeding_time"]; found {
		err = json.Unmarshal(raw, &a.MaxSeedingTime)
		if err != nil {
			return fmt.Errorf("error reading 'max_seeding_time': %w", err)
		}
		delete(object, "max_seeding_time")
	}

	if raw, found := object["max_seeding_time_enabled"]; found {
		err = json.Unmarshal(raw, &a.MaxSeedingTimeEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'max_seeding_time_enabled': %w", err)
		}
		delete(object, "max_seeding_time_enabled")
	}

	if raw, found := object["max_uploads"]; found {
		err = json.Unmarshal(raw, &a.MaxUploads)
		if err != nil {
			return fmt.Errorf("error reading 'max_uploads': %w", err)
		}
		delete(object, "max_uploads")
	}

	if raw, found := object["max_uploads_per_torrent"]; found {
		err = json.Unmarshal(raw, &a.MaxUploadsPerTorrent)
		if err != nil {
			return fmt.Errorf("error reading 'max_uploads_per_torrent': %w", err)
		}
		delete(object, "max_uploads_per_torrent")
	}

	if raw, found := object["outgoing_ports_max"]; found {
		err = json.Unmarshal(raw, &a.OutgoingPortsMax)
		if err != nil {
			return fmt.Errorf("error reading 'outgoing_ports_max': %w", err)
		}
		delete(object, "outgoing_ports_max")
	}

	if raw, found := object["outgoing_ports_min"]; found {
		err = json.Unmarshal(raw, &a.OutgoingPortsMin)
		if err != nil {
			return fmt.Errorf("error reading 'outgoing_ports_min': %w", err)
		}
		delete(object, "outgoing_ports_min")
	}

	if raw, found := object["pex"]; found {
		err = json.Unmarshal(raw, &a.Pex)
		if err != nil {
			return fmt.Errorf("error reading 'pex': %w", err)
		}
		delete(object, "pex")
	}

	if raw, found := object["preallocate_all"]; found {
		err = json.Unmarshal(raw, &a.PreallocateAll)
		if err != nil {
			return fmt.Errorf("error reading 'preallocate_all': %w", err)
		}
		delete(object, "preallocate_all")
	}

	if raw, found := object["proxy_auth_enabled"]; found {
		err = json.Unmarshal(raw, &a.ProxyAuthEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'proxy_auth_enabled': %w", err)
		}
		delete(object, "proxy_auth_enabled")
	}

	if raw, found := object["proxy_ip"]; found {
		err = json.Unmarshal(raw, &a.ProxyIp)
		if err != nil {
			return fmt.Errorf("error reading 'proxy_ip': %w", err)
		}
		delete(object, "proxy_ip")
	}

	if raw, found := object["proxy_password"]; found {
		err = json.Unmarshal(raw, &a.ProxyPassword)
		if err != nil {
			return fmt.Errorf("error reading 'proxy_password': %w", err)
		}
		delete(object, "proxy_password")
	}

	if raw, found := object["proxy_peer_connections"]; found {
		err = json.Unmarshal(raw, &a.ProxyPeerConnections)
		if err != nil {
			return fmt.Errorf("error reading 'proxy_peer_connections': %w", err)
		}
		delete(object, "proxy_peer_connections")
	}

	if raw, found := object["proxy_port"]; found {
		err = json.Unmarshal(raw, &a.ProxyPort)
		if err != nil {
			return fmt.Errorf("error reading 'proxy_port': %w", err)
		}
		delete(object, "proxy_port")
	}

	if raw, found := object["proxy_torrents_only"]; found {
		err = json.Unmarshal(raw, &a.ProxyTorrentsOnly)
		if err != nil {
			return fmt.Errorf("error reading 'proxy_torrents_only': %w", err)
		}
		delete(object, "proxy_torrents_only")
	}

	if raw, found := object["proxy_type"]; found {
		err = json.Unmarshal(raw, &a.ProxyType)
		if err != nil {
			return fmt.Errorf("error reading 'proxy_type': %w", err)
		}
		delete(object, "proxy_type")
	}

	if raw, found := object["proxy_username"]; found {
		err = json.Unmarshal(raw, &a.ProxyUsername)
		if err != nil {
			return fmt.Errorf("error reading 'proxy_username': %w", err)
		}
		delete(object, "proxy_username")
	}

	if raw, found := object["queueing_enabled"]; found {
		err = json.Unmarshal(raw, &a.QueueingEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'queueing_enabled': %w", err)
		}
		delete(object, "queueing_enabled")
	}

	if raw, found := object["random_port"]; found {
		err = json.Unmarshal(raw, &a.RandomPort)
		if err != nil {
			return fmt.Errorf("error reading 'random_port': %w", err)
		}
		delete(object, "random_port")
	}

	if raw, found := object["recheck_completed_torrents"]; found {
		err = json.Unmarshal(raw, &a.RecheckCompletedTorrents)
		if err != nil {
			return fmt.Errorf("error reading 'recheck_completed_torrents': %w", err)
		}
		delete(object, "recheck_completed_torrents")
	}

	if raw, found := object["resolve_peer_countries"]; found {
		err = json.Unmarshal(raw, &a.ResolvePeerCountries)
		if err != nil {
			return fmt.Errorf("error reading 'resolve_peer_countries': %w", err)
		}
		delete(object, "resolve_peer_countries")
	}

	if raw, found := object["rss_auto_downloading_enabled"]; found {
		err = json.Unmarshal(raw, &a.RssAutoDownloadingEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'rss_auto_downloading_enabled': %w", err)
		}
		delete(object, "rss_auto_downloading_enabled")
	}

	if raw, found := object["rss_download_repack_proper_episodes"]; found {
		err = json.Unmarshal(raw, &a.RssDownloadRepackProperEpisodes)
		if err != nil {
			return fmt.Errorf("error reading 'rss_download_repack_proper_episodes': %w", err)
		}
		delete(object, "rss_download_repack_proper_episodes")
	}

	if raw, found := object["rss_max_articles_per_feed"]; found {
		err = json.Unmarshal(raw, &a.RssMaxArticlesPerFeed)
		if err != nil {
			return fmt.Errorf("error reading 'rss_max_articles_per_feed': %w", err)
		}
		delete(object, "rss_max_articles_per_feed")
	}

	if raw, found := object["rss_processing_enabled"]; found {
		err = json.Unmarshal(raw, &a.RssProcessingEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'rss_processing_enabled': %w", err)
		}
		delete(object, "rss_processing_enabled")
	}

	if raw, found := object["rss_refresh_interval"]; found {
		err = json.Unmarshal(raw, &a.RssRefreshInterval)
		if err != nil {
			return fmt.Errorf("error reading 'rss_refresh_interval': %w", err)
		}
		delete(object, "rss_refresh_interval")
	}

	if raw, found := object["rss_smart_episode_filters"]; found {
		err = json.Unmarshal(raw, &a.RssSmartEpisodeFilters)
		if err != nil {
			return fmt.Errorf("error reading 'rss_smart_episode_filters': %w", err)
		}
		delete(object, "rss_smart_episode_filters")
	}

	if raw, found := object["save_path"]; found {
		err = json.Unmarshal(raw, &a.SavePath)
		if err != nil {
			return fmt.Errorf("error reading 'save_path': %w", err)
		}
		delete(object, "save_path")
	}

	if raw, found := object["save_path_changed_tmm_enabled"]; found {
		err = json.Unmarshal(raw, &a.SavePathChangedTmmEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'save_path_changed_tmm_enabled': %w", err)
		}
		delete(object, "save_path_changed_tmm_enabled")
	}

	if raw, found := object["save_resume_data_interval"]; found {
		err = json.Unmarshal(raw, &a.SaveResumeDataInterval)
		if err != nil {
			return fmt.Errorf("error reading 'save_resume_data_interval': %w", err)
		}
		delete(object, "save_resume_data_interval")
	}

	if raw, found := object["scan_dirs"]; found {
		err = json.Unmarshal(raw, &a.ScanDirs)
		if err != nil {
			return fmt.Errorf("error reading 'scan_dirs': %w", err)
		}
		delete(object, "scan_dirs")
	}

	if raw, found := object["schedule_from_hour"]; found {
		err = json.Unmarshal(raw, &a.ScheduleFromHour)
		if err != nil {
			return fmt.Errorf("error reading 'schedule_from_hour': %w", err)
		}
		delete(object, "schedule_from_hour")
	}

	if raw, found := object["schedule_from_min"]; found {
		err = json.Unmarshal(raw, &a.ScheduleFromMin)
		if err != nil {
			return fmt.Errorf("error reading 'schedule_from_min': %w", err)
		}
		delete(object, "schedule_from_min")
	}

	if raw, found := object["schedule_to_hour"]; found {
		err = json.Unmarshal(raw, &a.ScheduleToHour)
		if err != nil {
			return fmt.Errorf("error reading 'schedule_to_hour': %w", err)
		}
		delete(object, "schedule_to_hour")
	}

	if raw, found := object["schedule_to_min"]; found {
		err = json.Unmarshal(raw, &a.ScheduleToMin)
		if err != nil {
			return fmt.Errorf("error reading 'schedule_to_min': %w", err)
		}
		delete(object, "schedule_to_min")
	}

	if raw, found := object["scheduler_days"]; found {
		err = json.Unmarshal(raw, &a.SchedulerDays)
		if err != nil {
			return fmt.Errorf("error reading 'scheduler_days': %w", err)
		}
		delete(object, "scheduler_days")
	}

	if raw, found := object["scheduler_enabled"]; found {
		err = json.Unmarshal(raw, &a.SchedulerEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'scheduler_enabled': %w", err)
		}
		delete(object, "scheduler_enabled")
	}

	if raw, found := object["send_buffer_low_watermark"]; found {
		err = json.Unmarshal(raw, &a.SendBufferLowWatermark)
		if err != nil {
			return fmt.Errorf("error reading 'send_buffer_low_watermark': %w", err)
		}
		delete(object, "send_buffer_low_watermark")
	}

	if raw, found := object["send_buffer_watermark"]; found {
		err = json.Unmarshal(raw, &a.SendBufferWatermark)
		if err != nil {
			return fmt.Errorf("error reading 'send_buffer_watermark': %w", err)
		}
		delete(object, "send_buffer_watermark")
	}

	if raw, found := object["send_buffer_watermark_factor"]; found {
		err = json.Unmarshal(raw, &a.SendBufferWatermarkFactor)
		if err != nil {
			return fmt.Errorf("error reading 'send_buffer_watermark_factor': %w", err)
		}
		delete(object, "send_buffer_watermark_factor")
	}

	if raw, found := object["slow_torrent_dl_rate_threshold"]; found {
		err = json.Unmarshal(raw, &a.SlowTorrentDlRateThreshold)
		if err != nil {
			return fmt.Errorf("error reading 'slow_torrent_dl_rate_threshold': %w", err)
		}
		delete(object, "slow_torrent_dl_rate_threshold")
	}

	if raw, found := object["slow_torrent_inactive_timer"]; found {
		err = json.Unmarshal(raw, &a.SlowTorrentInactiveTimer)
		if err != nil {
			return fmt.Errorf("error reading 'slow_torrent_inactive_timer': %w", err)
		}
		delete(object, "slow_torrent_inactive_timer")
	}

	if raw, found := object["slow_torrent_ul_rate_threshold"]; found {
		err = json.Unmarshal(raw, &a.SlowTorrentUlRateThreshold)
		if err != nil {
			return fmt.Errorf("error reading 'slow_torrent_ul_rate_threshold': %w", err)
		}
		delete(object, "slow_torrent_ul_rate_threshold")
	}

	if raw, found := object["socket_backlog_size"]; found {
		err = json.Unmarshal(raw, &a.SocketBacklogSize)
		if err != nil {
			return fmt.Errorf("error reading 'socket_backlog_size': %w", err)
		}
		delete(object, "socket_backlog_size")
	}

	if raw, found := object["ssl_cert"]; found {
		err = json.Unmarshal(raw, &a.SslCert)
		if err != nil {
			return fmt.Errorf("error reading 'ssl_cert': %w", err)
		}
		delete(object, "ssl_cert")
	}

	if raw, found := object["ssl_key"]; found {
		err = json.Unmarshal(raw, &a.SslKey)
		if err != nil {
			return fmt.Errorf("error reading 'ssl_key': %w", err)
		}
		delete(object, "ssl_key")
	}

	if raw, found := object["start_paused_enabled"]; found {
		err = json.Unmarshal(raw, &a.StartPausedEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'start_paused_enabled': %w", err)
		}
		delete(object, "start_paused_enabled")
	}

	if raw, found := object["stop_tracker_timeout"]; found {
		err = json.Unmarshal(raw, &a.StopTrackerTimeout)
		if err != nil {
			return fmt.Errorf("error reading 'stop_tracker_timeout': %w", err)
		}
		delete(object, "stop_tracker_timeout")
	}

	if raw, found := object["temp_path"]; found {
		err = json.Unmarshal(raw, &a.TempPath)
		if err != nil {
			return fmt.Errorf("error reading 'temp_path': %w", err)
		}
		delete(object, "temp_path")
	}

	if raw, found := object["temp_path_enabled"]; found {
		err = json.Unmarshal(raw, &a.TempPathEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'temp_path_enabled': %w", err)
		}
		delete(object, "temp_path_enabled")
	}

	if raw, found := object["torrent_changed_tmm_enabled"]; found {
		err = json.Unmarshal(raw, &a.TorrentChangedTmmEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'torrent_changed_tmm_enabled': %w", err)
		}
		delete(object, "torrent_changed_tmm_enabled")
	}

	if raw, found := object["up_limit"]; found {
		err = json.Unmarshal(raw, &a.UpLimit)
		if err != nil {
			return fmt.Errorf("error reading 'up_limit': %w", err)
		}
		delete(object, "up_limit")
	}

	if raw, found := object["upload_choking_algorithm"]; found {
		err = json.Unmarshal(raw, &a.UploadChokingAlgorithm)
		if err != nil {
			return fmt.Errorf("error reading 'upload_choking_algorithm': %w", err)
		}
		delete(object, "upload_choking_algorithm")
	}

	if raw, found := object["upload_slots_behavior"]; found {
		err = json.Unmarshal(raw, &a.UploadSlotsBehavior)
		if err != nil {
			return fmt.Errorf("error reading 'upload_slots_behavior': %w", err)
		}
		delete(object, "upload_slots_behavior")
	}

	if raw, found := object["upnp"]; found {
		err = json.Unmarshal(raw, &a.Upnp)
		if err != nil {
			return fmt.Errorf("error reading 'upnp': %w", err)
		}
		delete(object, "upnp")
	}

	if raw, found := object["upnp_lease_duration"]; found {
		err = json.Unmarshal(raw, &a.UpnpLeaseDuration)
		if err != nil {
			return fmt.Errorf("error reading 'upnp_lease_duration': %w", err)
		}
		delete(object, "upnp_lease_duration")
	}

	if raw, found := object["use_https"]; found {
		err = json.Unmarshal(raw, &a.UseHttps)
		if err != nil {
			return fmt.Errorf("error reading 'use_https': %w", err)
		}
		delete(object, "use_https")
	}

	if raw, found := object["utp_tcp_mixed_mode"]; found {
		err = json.Unmarshal(raw, &a.UtpTcpMixedMode)
		if err != nil {
			return fmt.Errorf("error reading 'utp_tcp_mixed_mode': %w", err)
		}
		delete(object, "utp_tcp_mixed_mode")
	}

	if raw, found := object["web_ui_address"]; found {
		err = json.Unmarshal(raw, &a.WebUiAddress)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_address': %w", err)
		}
		delete(object, "web_ui_address")
	}

	if raw, found := object["web_ui_ban_duration"]; found {
		err = json.Unmarshal(raw, &a.WebUiBanDuration)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_ban_duration': %w", err)
		}
		delete(object, "web_ui_ban_duration")
	}

	if raw, found := object["web_ui_clickjacking_protection_enabled"]; found {
		err = json.Unmarshal(raw, &a.WebUiClickjackingProtectionEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_clickjacking_protection_enabled': %w", err)
		}
		delete(object, "web_ui_clickjacking_protection_enabled")
	}

	if raw, found := object["web_ui_csrf_protection_enabled"]; found {
		err = json.Unmarshal(raw, &a.WebUiCsrfProtectionEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_csrf_protection_enabled': %w", err)
		}
		delete(object, "web_ui_csrf_protection_enabled")
	}

	if raw, found := object["web_ui_custom_http_headers"]; found {
		err = json.Unmarshal(raw, &a.WebUiCustomHttpHeaders)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_custom_http_headers': %w", err)
		}
		delete(object, "web_ui_custom_http_headers")
	}

	if raw, found := object["web_ui_domain_list"]; found {
		err = json.Unmarshal(raw, &a.WebUiDomainList)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_domain_list': %w", err)
		}
		delete(object, "web_ui_domain_list")
	}

	if raw, found := object["web_ui_host_header_validation_enabled"]; found {
		err = json.Unmarshal(raw, &a.WebUiHostHeaderValidationEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_host_header_validation_enabled': %w", err)
		}
		delete(object, "web_ui_host_header_validation_enabled")
	}

	if raw, found := object["web_ui_https_cert_path"]; found {
		err = json.Unmarshal(raw, &a.WebUiHttpsCertPath)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_https_cert_path': %w", err)
		}
		delete(object, "web_ui_https_cert_path")
	}

	if raw, found := object["web_ui_https_key_path"]; found {
		err = json.Unmarshal(raw, &a.WebUiHttpsKeyPath)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_https_key_path': %w", err)
		}
		delete(object, "web_ui_https_key_path")
	}

	if raw, found := object["web_ui_max_auth_fail_count"]; found {
		err = json.Unmarshal(raw, &a.WebUiMaxAuthFailCount)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_max_auth_fail_count': %w", err)
		}
		delete(object, "web_ui_max_auth_fail_count")
	}

	if raw, found := object["web_ui_password"]; found {
		err = json.Unmarshal(raw, &a.WebUiPassword)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_password': %w", err)
		}
		delete(object, "web_ui_password")
	}

	if raw, found := object["web_ui_port"]; found {
		err = json.Unmarshal(raw, &a.WebUiPort)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_port': %w", err)
		}
		delete(object, "web_ui_port")
	}

	if raw, found := object["web_ui_secure_cookie_enabled"]; found {
		err = json.Unmarshal(raw, &a.WebUiSecureCookieEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_secure_cookie_enabled': %w", err)
		}
		delete(object, "web_ui_secure_cookie_enabled")
	}

	if raw, found := object["web_ui_session_timeout"]; found {
		err = json.Unmarshal(raw, &a.WebUiSessionTimeout)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_session_timeout': %w", err)
		}
		delete(object, "web_ui_session_timeout")
	}

	if raw, found := object["web_ui_upnp"]; found {
		err = json.Unmarshal(raw, &a.WebUiUpnp)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_upnp': %w", err)
		}
		delete(object, "web_ui_upnp")
	}

	if raw, found := object["web_ui_use_custom_http_headers_enabled"]; found {
		err = json.Unmarshal(raw, &a.WebUiUseCustomHttpHeadersEnabled)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_use_custom_http_headers_enabled': %w", err)
		}
		delete(object, "web_ui_use_custom_http_headers_enabled")
	}

	if raw, found := object["web_ui_username"]; found {
		err = json.Unmarshal(raw, &a.WebUiUsername)
		if err != nil {
			return fmt.Errorf("error reading 'web_ui_username': %w", err)
		}
		delete(object, "web_ui_username")
	}

	if len(object) != 0 {
		a.AdditionalProperties = make(map[string]interface{})
		for fieldName, fieldBuf := range object {
			var fieldVal interface{}
			err := json.Unmarshal(fieldBuf, &fieldVal)
			if err != nil {
				return fmt.Errorf("error unmarshaling field %s: %w", fieldName, err)
			}
			a.AdditionalProperties[fieldName] = fieldVal
		}
	}
	return nil
}

// Override default JSON handling for SetPreferences to handle AdditionalProperties
func (a SetPreferences) MarshalJSON() ([]byte, error) {
	var err error
	object := make(map[string]json.RawMessage)

	if a.AddTrackers != nil {
		object["add_trackers"], err = json.Marshal(a.AddTrackers)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'add_trackers': %w", err)
		}
	}

	if a.AddTrackersEnabled != nil {
		object["add_trackers_enabled"], err = json.Marshal(a.AddTrackersEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'add_trackers_enabled': %w", err)
		}
	}

	if a.AltDlLimit != nil {
		object["alt_dl_limit"], err = json.Marshal(a.AltDlLimit)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'alt_dl_limit': %w", err)
		}
	}

	if a.AltUpLimit != nil {
		object["alt_up_limit"], err = json.Marshal(a.AltUpLimit)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'alt_up_limit': %w", err)
		}
	}

	if a.AlternativeWebuiEnabled != nil {
		object["alternative_webui_enabled"], err = json.Marshal(a.AlternativeWebuiEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'alternative_webui_enabled': %w", err)
		}
	}

	if a.AlternativeWebuiPath != nil {
		object["alternative_webui_path"], err = json.Marshal(a.AlternativeWebuiPath)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'alternative_webui_path': %w", err)
		}
	}

	if a.AnnounceIp != nil {
		object["announce_ip"], err = json.Marshal(a.AnnounceIp)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'announce_ip': %w", err)
		}
	}

	if a.AnnounceToAllTiers != nil {
		object["announce_to_all_tiers"], err = json.Marshal(a.AnnounceToAllTiers)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'announce_to_all_tiers': %w", err)
		}
	}

	if a.AnnounceToAllTrackers != nil {
		object["announce_to_all_trackers"], err = json.Marshal(a.AnnounceToAllTrackers)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'announce_to_all_trackers': %w", err)
		}
	}

	if a.AnonymousMode != nil {
		object["anonymous_mode"], err = json.Marshal(a.AnonymousMode)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'anonymous_mode': %w", err)
		}
	}

	if a.AsyncIoThreads != nil {
		object["async_io_threads"], err = json.Marshal(a.AsyncIoThreads)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'async_io_threads': %w", err)
		}
	}

	if a.AutoDeleteMode != nil {
		object["auto_delete_mode"], err = json.Marshal(a.AutoDeleteMode)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'auto_delete_mode': %w", err)
		}
	}

	if a.AutoTmmEnabled != nil {
		object["auto_tmm_enabled"], err = json.Marshal(a.AutoTmmEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'auto_tmm_enabled': %w", err)
		}
	}

	if a.AutorunEnabled != nil {
		object["autorun_enabled"], err = json.Marshal(a.AutorunEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'autorun_enabled': %w", err)
		}
	}

	if a.AutorunProgram != nil {
		object["autorun_program"], err = json.Marshal(a.AutorunProgram)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'autorun_program': %w", err)
		}
	}

	if a.BannedIPs != nil {
		object["banned_IPs"], err = json.Marshal(a.BannedIPs)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'banned_IPs': %w", err)
		}
	}

	if a.BittorrentProtocol != nil {
		object["bittorrent_protocol"], err = json.Marshal(a.BittorrentProtocol)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'bittorrent_protocol': %w", err)
		}
	}

	if a.BypassAuthSubnetWhitelist != nil {
		object["bypass_auth_subnet_whitelist"], err = json.Marshal(a.BypassAuthSubnetWhitelist)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'bypass_auth_subnet_whitelist': %w", err)
		}
	}

	if a.BypassAuthSubnetWhitelistEnabled != nil {
		object["bypass_auth_subnet_whitelist_enabled"], err = json.Marshal(a.BypassAuthSubnetWhitelistEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'bypass_auth_subnet_whitelist_enabled': %w", err)
		}
	}

	if a.BypassLocalAuth != nil {
		object["bypass_local_auth"], err = json.Marshal(a.BypassLocalAuth)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'bypass_local_auth': %w", err)
		}
	}

	if a.CategoryChangedTmmEnabled != nil {
		object["category_changed_tmm_enabled"], err = json.Marshal(a.CategoryChangedTmmEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'category_changed_tmm_enabled': %w", err)
		}
	}

	if a.CheckingMemoryUse != nil {
		object["checking_memory_use"], err = json.Marshal(a.CheckingMemoryUse)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'checking_memory_use': %w", err)
		}
	}

	if a.CreateSubfolderEnabled != nil {
		object["create_subfolder_enabled"], err = json.Marshal(a.CreateSubfolderEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'create_subfolder_enabled': %w", err)
		}
	}

	if a.CurrentInterfaceAddress != nil {
		object["current_interface_address"], err = json.Marshal(a.CurrentInterfaceAddress)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'current_interface_address': %w", err)
		}
	}

	if a.CurrentNetworkInterface != nil {
		object["current_network_interface"], err = json.Marshal(a.CurrentNetworkInterface)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'current_network_interface': %w", err)
		}
	}

	if a.Dht != nil {
		object["dht"], err = json.Marshal(a.Dht)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'dht': %w", err)
		}
	}

	if a.DiskCache != nil {
		object["disk_cache"], err = json.Marshal(a.DiskCache)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'disk_cache': %w", err)
		}
	}

	if a.DiskCacheTtl != nil {
		object["disk_cache_ttl"], err = json.Marshal(a.DiskCacheTtl)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'disk_cache_ttl': %w", err)
		}
	}

	if a.DlLimit != nil {
		object["dl_limit"], err = json.Marshal(a.DlLimit)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'dl_limit': %w", err)
		}
	}

	if a.DontCountSlowTorrents != nil {
		object["dont_count_slow_torrents"], err = json.Marshal(a.DontCountSlowTorrents)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'dont_count_slow_torrents': %w", err)
		}
	}

	if a.DyndnsDomain != nil {
		object["dyndns_domain"], err = json.Marshal(a.DyndnsDomain)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'dyndns_domain': %w", err)
		}
	}

	if a.DyndnsEnabled != nil {
		object["dyndns_enabled"], err = json.Marshal(a.DyndnsEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'dyndns_enabled': %w", err)
		}
	}

	if a.DyndnsPassword != nil {
		object["dyndns_password"], err = json.Marshal(a.DyndnsPassword)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'dyndns_password': %w", err)
		}
	}

	if a.DyndnsService != nil {
		object["dyndns_service"], err = json.Marshal(a.DyndnsService)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'dyndns_service': %w", err)
		}
	}

	if a.DyndnsUsername != nil {
		object["dyndns_username"], err = json.Marshal(a.DyndnsUsername)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'dyndns_username': %w", err)
		}
	}

	if a.EmbeddedTrackerPort != nil {
		object["embedded_tracker_port"], err = json.Marshal(a.EmbeddedTrackerPort)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'embedded_tracker_port': %w", err)
		}
	}

	if a.EnableCoalesceReadWrite != nil {
		object["enable_coalesce_read_write"], err = json.Marshal(a.EnableCoalesceReadWrite)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'enable_coalesce_read_write': %w", err)
		}
	}

	if a.EnableEmbeddedTracker != nil {
		object["enable_embedded_tracker"], err = json.Marshal(a.EnableEmbeddedTracker)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'enable_embedded_tracker': %w", err)
		}
	}

	if a.EnableMultiConnectionsFromSameIp != nil {
		object["enable_multi_connections_from_same_ip"], err = json.Marshal(a.EnableMultiConnectionsFromSameIp)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'enable_multi_connections_from_same_ip': %w", err)
		}
	}

	if a.EnableOsCache != nil {
		object["enable_os_cache"], err = json.Marshal(a.EnableOsCache)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'enable_os_cache': %w", err)
		}
	}

	if a.EnablePieceExtentAffinity != nil {
		object["enable_piece_extent_affinity"], err = json.Marshal(a.EnablePieceExtentAffinity)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'enable_piece_extent_affinity': %w", err)
		}
	}

	if a.EnableUploadSuggestions != nil {
		object["enable_upload_suggestions"], err = json.Marshal(a.EnableUploadSuggestions)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'enable_upload_suggestions': %w", err)
		}
	}

	if a.Encryption != nil {
		object["encryption"], err = json.Marshal(a.Encryption)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'encryption': %w", err)
		}
	}

	if a.ExportDir != nil {
		object["export_dir"], err = json.Marshal(a.ExportDir)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'export_dir': %w", err)
		}
	}

	if a.ExportDirFin != nil {
		object["export_dir_fin"], err = json.Marshal(a.ExportDirFin)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'export_dir_fin': %w", err)
		}
	}

	if a.FilePoolSize != nil {
		object["file_pool_size"], err = json.Marshal(a.FilePoolSize)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'file_pool_size': %w", err)
		}
	}

	if a.IncompleteFilesExt != nil {
		object["incomplete_files_ext"], err = json.Marshal(a.IncompleteFilesExt)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'incomplete_files_ext': %w", err)
		}
	}

	if a.IpFilterEnabled != nil {
		object["ip_filter_enabled"], err = json.Marshal(a.IpFilterEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'ip_filter_enabled': %w", err)
		}
	}

	if a.IpFilterPath != nil {
		object["ip_filter_path"], err = json.Marshal(a.IpFilterPath)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'ip_filter_path': %w", err)
		}
	}

	if a.IpFilterTrackers != nil {
		object["ip_filter_trackers"], err = json.Marshal(a.IpFilterTrackers)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'ip_filter_trackers': %w", err)
		}
	}

	if a.LimitLanPeers != nil {
		object["limit_lan_peers"], err = json.Marshal(a.LimitLanPeers)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'limit_lan_peers': %w", err)
		}
	}

	if a.LimitTcpOverhead != nil {
		object["limit_tcp_overhead"], err = json.Marshal(a.LimitTcpOverhead)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'limit_tcp_overhead': %w", err)
		}
	}

	if a.LimitUtpRate != nil {
		object["limit_utp_rate"], err = json.Marshal(a.LimitUtpRate)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'limit_utp_rate': %w", err)
		}
	}

	if a.ListenPort != nil {
		object["listen_port"], err = json.Marshal(a.ListenPort)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'listen_port': %w", err)
		}
	}

	if a.Locale != nil {
		object["locale"], err = json.Marshal(a.Locale)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'locale': %w", err)
		}
	}

	if a.Lsd != nil {
		object["lsd"], err = json.Marshal(a.Lsd)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'lsd': %w", err)
		}
	}

	if a.MailNotificationAuthEnabled != nil {
		object["mail_notification_auth_enabled"], err = json.Marshal(a.MailNotificationAuthEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'mail_notification_auth_enabled': %w", err)
		}
	}

	if a.MailNotificationEmail != nil {
		object["mail_notification_email"], err = json.Marshal(a.MailNotificationEmail)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'mail_notification_email': %w", err)
		}
	}

	if a.MailNotificationEnabled != nil {
		object["mail_notification_enabled"], err = json.Marshal(a.MailNotificationEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'mail_notification_enabled': %w", err)
		}
	}

	if a.MailNotificationPassword != nil {
		object["mail_notification_password"], err = json.Marshal(a.MailNotificationPassword)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'mail_notification_password': %w", err)
		}
	}

	if a.MailNotificationSender != nil {
		object["mail_notification_sender"], err = json.Marshal(a.MailNotificationSender)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'mail_notification_sender': %w", err)
		}
	}

	if a.MailNotificationSmtp != nil {
		object["mail_notification_smtp"], err = json.Marshal(a.MailNotificationSmtp)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'mail_notification_smtp': %w", err)
		}
	}

	if a.MailNotificationSslEnabled != nil {
		object["mail_notification_ssl_enabled"], err = json.Marshal(a.MailNotificationSslEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'mail_notification_ssl_enabled': %w", err)
		}
	}

	if a.MailNotificationUsername != nil {
		object["mail_notification_username"], err = json.Marshal(a.MailNotificationUsername)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'mail_notification_username': %w", err)
		}
	}

	if a.MaxActiveDownloads != nil {
		object["max_active_downloads"], err = json.Marshal(a.MaxActiveDownloads)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_active_downloads': %w", err)
		}
	}

	if a.MaxActiveTorrents != nil {
		object["max_active_torrents"], err = json.Marshal(a.MaxActiveTorrents)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_active_torrents': %w", err)
		}
	}

	if a.MaxActiveUploads != nil {
		object["max_active_uploads"], err = json.Marshal(a.MaxActiveUploads)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_active_uploads': %w", err)
		}
	}

	if a.MaxConnec != nil {
		object["max_connec"], err = json.Marshal(a.MaxConnec)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_connec': %w", err)
		}
	}

	if a.MaxConnecPerTorrent != nil {
		object["max_connec_per_torrent"], err = json.Marshal(a.MaxConnecPerTorrent)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_connec_per_torrent': %w", err)
		}
	}

	if a.MaxRatio != nil {
		object["max_ratio"], err = json.Marshal(a.MaxRatio)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_ratio': %w", err)
		}
	}

	if a.MaxRatioAct != nil {
		object["max_ratio_act"], err = json.Marshal(a.MaxRatioAct)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_ratio_act': %w", err)
		}
	}

	if a.MaxRatioEnabled != nil {
		object["max_ratio_enabled"], err = json.Marshal(a.MaxRatioEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_ratio_enabled': %w", err)
		}
	}

	if a.MaxSeedingTime != nil {
		object["max_seeding_time"], err = json.Marshal(a.MaxSeedingTime)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_seeding_time': %w", err)
		}
	}

	if a.MaxSeedingTimeEnabled != nil {
		object["max_seeding_time_enabled"], err = json.Marshal(a.MaxSeedingTimeEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_seeding_time_enabled': %w", err)
		}
	}

	if a.MaxUploads != nil {
		object["max_uploads"], err = json.Marshal(a.MaxUploads)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_uploads': %w", err)
		}
	}

	if a.MaxUploadsPerTorrent != nil {
		object["max_uploads_per_torrent"], err = json.Marshal(a.MaxUploadsPerTorrent)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'max_uploads_per_torrent': %w", err)
		}
	}

	if a.OutgoingPortsMax != nil {
		object["outgoing_ports_max"], err = json.Marshal(a.OutgoingPortsMax)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'outgoing_ports_max': %w", err)
		}
	}

	if a.OutgoingPortsMin != nil {
		object["outgoing_ports_min"], err = json.Marshal(a.OutgoingPortsMin)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'outgoing_ports_min': %w", err)
		}
	}

	if a.Pex != nil {
		object["pex"], err = json.Marshal(a.Pex)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'pex': %w", err)
		}
	}

	if a.PreallocateAll != nil {
		object["preallocate_all"], err = json.Marshal(a.PreallocateAll)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'preallocate_all': %w", err)
		}
	}

	if a.ProxyAuthEnabled != nil {
		object["proxy_auth_enabled"], err = json.Marshal(a.ProxyAuthEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'proxy_auth_enabled': %w", err)
		}
	}

	if a.ProxyIp != nil {
		object["proxy_ip"], err = json.Marshal(a.ProxyIp)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'proxy_ip': %w", err)
		}
	}

	if a.ProxyPassword != nil {
		object["proxy_password"], err = json.Marshal(a.ProxyPassword)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'proxy_password': %w", err)
		}
	}

	if a.ProxyPeerConnections != nil {
		object["proxy_peer_connections"], err = json.Marshal(a.ProxyPeerConnections)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'proxy_peer_connections': %w", err)
		}
	}

	if a.ProxyPort != nil {
		object["proxy_port"], err = json.Marshal(a.ProxyPort)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'proxy_port': %w", err)
		}
	}

	if a.ProxyTorrentsOnly != nil {
		object["proxy_torrents_only"], err = json.Marshal(a.ProxyTorrentsOnly)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'proxy_torrents_only': %w", err)
		}
	}

	if a.ProxyType != nil {
		object["proxy_type"], err = json.Marshal(a.ProxyType)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'proxy_type': %w", err)
		}
	}

	if a.ProxyUsername != nil {
		object["proxy_username"], err = json.Marshal(a.ProxyUsername)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'proxy_username': %w", err)
		}
	}

	if a.QueueingEnabled != nil {
		object["queueing_enabled"], err = json.Marshal(a.QueueingEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'queueing_enabled': %w", err)
		}
	}

	if a.RandomPort != nil {
		object["random_port"], err = json.Marshal(a.RandomPort)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'random_port': %w", err)
		}
	}

	if a.RecheckCompletedTorrents != nil {
		object["recheck_completed_torrents"], err = json.Marshal(a.RecheckCompletedTorrents)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'recheck_completed_torrents': %w", err)
		}
	}

	if a.ResolvePeerCountries != nil {
		object["resolve_peer_countries"], err = json.Marshal(a.ResolvePeerCountries)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'resolve_peer_countries': %w", err)
		}
	}

	if a.RssAutoDownloadingEnabled != nil {
		object["rss_auto_downloading_enabled"], err = json.Marshal(a.RssAutoDownloadingEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'rss_auto_downloading_enabled': %w", err)
		}
	}

	if a.RssDownloadRepackProperEpisodes != nil {
		object["rss_download_repack_proper_episodes"], err = json.Marshal(a.RssDownloadRepackProperEpisodes)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'rss_download_repack_proper_episodes': %w", err)
		}
	}

	if a.RssMaxArticlesPerFeed != nil {
		object["rss_max_articles_per_feed"], err = json.Marshal(a.RssMaxArticlesPerFeed)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'rss_max_articles_per_feed': %w", err)
		}
	}

	if a.RssProcessingEnabled != nil {
		object["rss_processing_enabled"], err = json.Marshal(a.RssProcessingEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'rss_processing_enabled': %w", err)
		}
	}

	if a.RssRefreshInterval != nil {
		object["rss_refresh_interval"], err = json.Marshal(a.RssRefreshInterval)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'rss_refresh_interval': %w", err)
		}
	}

	if a.RssSmartEpisodeFilters != nil {
		object["rss_smart_episode_filters"], err = json.Marshal(a.RssSmartEpisodeFilters)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'rss_smart_episode_filters': %w", err)
		}
	}

	if a.SavePath != nil {
		object["save_path"], err = json.Marshal(a.SavePath)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'save_path': %w", err)
		}
	}

	if a.SavePathChangedTmmEnabled != nil {
		object["save_path_changed_tmm_enabled"], err = json.Marshal(a.SavePathChangedTmmEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'save_path_changed_tmm_enabled': %w", err)
		}
	}

	if a.SaveResumeDataInterval != nil {
		object["save_resume_data_interval"], err = json.Marshal(a.SaveResumeDataInterval)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'save_resume_data_interval': %w", err)
		}
	}

	if a.ScanDirs != nil {
		object["scan_dirs"], err = json.Marshal(a.ScanDirs)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'scan_dirs': %w", err)
		}
	}

	if a.ScheduleFromHour != nil {
		object["schedule_from_hour"], err = json.Marshal(a.ScheduleFromHour)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'schedule_from_hour': %w", err)
		}
	}

	if a.ScheduleFromMin != nil {
		object["schedule_from_min"], err = json.Marshal(a.ScheduleFromMin)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'schedule_from_min': %w", err)
		}
	}

	if a.ScheduleToHour != nil {
		object["schedule_to_hour"], err = json.Marshal(a.ScheduleToHour)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'schedule_to_hour': %w", err)
		}
	}

	if a.ScheduleToMin != nil {
		object["schedule_to_min"], err = json.Marshal(a.ScheduleToMin)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'schedule_to_min': %w", err)
		}
	}

	if a.SchedulerDays != nil {
		object["scheduler_days"], err = json.Marshal(a.SchedulerDays)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'scheduler_days': %w", err)
		}
	}

	if a.SchedulerEnabled != nil {
		object["scheduler_enabled"], err = json.Marshal(a.SchedulerEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'scheduler_enabled': %w", err)
		}
	}

	if a.SendBufferLowWatermark != nil {
		object["send_buffer_low_watermark"], err = json.Marshal(a.SendBufferLowWatermark)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'send_buffer_low_watermark': %w", err)
		}
	}

	if a.SendBufferWatermark != nil {
		object["send_buffer_watermark"], err = json.Marshal(a.SendBufferWatermark)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'send_buffer_watermark': %w", err)
		}
	}

	if a.SendBufferWatermarkFactor != nil {
		object["send_buffer_watermark_factor"], err = json.Marshal(a.SendBufferWatermarkFactor)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'send_buffer_watermark_factor': %w", err)
		}
	}

	if a.SlowTorrentDlRateThreshold != nil {
		object["slow_torrent_dl_rate_threshold"], err = json.Marshal(a.SlowTorrentDlRateThreshold)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'slow_torrent_dl_rate_threshold': %w", err)
		}
	}

	if a.SlowTorrentInactiveTimer != nil {
		object["slow_torrent_inactive_timer"], err = json.Marshal(a.SlowTorrentInactiveTimer)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'slow_torrent_inactive_timer': %w", err)
		}
	}

	if a.SlowTorrentUlRateThreshold != nil {
		object["slow_torrent_ul_rate_threshold"], err = json.Marshal(a.SlowTorrentUlRateThreshold)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'slow_torrent_ul_rate_threshold': %w", err)
		}
	}

	if a.SocketBacklogSize != nil {
		object["socket_backlog_size"], err = json.Marshal(a.SocketBacklogSize)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'socket_backlog_size': %w", err)
		}
	}

	if a.SslCert != nil {
		object["ssl_cert"], err = json.Marshal(a.SslCert)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'ssl_cert': %w", err)
		}
	}

	if a.SslKey != nil {
		object["ssl_key"], err = json.Marshal(a.SslKey)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'ssl_key': %w", err)
		}
	}

	if a.StartPausedEnabled != nil {
		object["start_paused_enabled"], err = json.Marshal(a.StartPausedEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'start_paused_enabled': %w", err)
		}
	}

	if a.StopTrackerTimeout != nil {
		object["stop_tracker_timeout"], err = json.Marshal(a.StopTrackerTimeout)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'stop_tracker_timeout': %w", err)
		}
	}

	if a.TempPath != nil {
		object["temp_path"], err = json.Marshal(a.TempPath)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'temp_path': %w", err)
		}
	}

	if a.TempPathEnabled != nil {
		object["temp_path_enabled"], err = json.Marshal(a.TempPathEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'temp_path_enabled': %w", err)
		}
	}

	if a.TorrentChangedTmmEnabled != nil {
		object["torrent_changed_tmm_enabled"], err = json.Marshal(a.TorrentChangedTmmEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'torrent_changed_tmm_enabled': %w", err)
		}
	}

	if a.UpLimit != nil {
		object["up_limit"], err = json.Marshal(a.UpLimit)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'up_limit': %w", err)
		}
	}

	if a.UploadChokingAlgorithm != nil {
		object["upload_choking_algorithm"], err = json.Marshal(a.UploadChokingAlgorithm)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'upload_choking_algorithm': %w", err)
		}
	}

	if a.UploadSlotsBehavior != nil {
		object["upload_slots_behavior"], err = json.Marshal(a.UploadSlotsBehavior)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'upload_slots_behavior': %w", err)
		}
	}

	if a.Upnp != nil {
		object["upnp"], err = json.Marshal(a.Upnp)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'upnp': %w", err)
		}
	}

	if a.UpnpLeaseDuration != nil {
		object["upnp_lease_duration"], err = json.Marshal(a.UpnpLeaseDuration)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'upnp_lease_duration': %w", err)
		}
	}

	if a.UseHttps != nil {
		object["use_https"], err = json.Marshal(a.UseHttps)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'use_https': %w", err)
		}
	}

	if a.UtpTcpMixedMode != nil {
		object["utp_tcp_mixed_mode"], err = json.Marshal(a.UtpTcpMixedMode)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'utp_tcp_mixed_mode': %w", err)
		}
	}

	if a.WebUiAddress != nil {
		object["web_ui_address"], err = json.Marshal(a.WebUiAddress)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_address': %w", err)
		}
	}

	if a.WebUiBanDuration != nil {
		object["web_ui_ban_duration"], err = json.Marshal(a.WebUiBanDuration)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_ban_duration': %w", err)
		}
	}

	if a.WebUiClickjackingProtectionEnabled != nil {
		object["web_ui_clickjacking_protection_enabled"], err = json.Marshal(a.WebUiClickjackingProtectionEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_clickjacking_protection_enabled': %w", err)
		}
	}

	if a.WebUiCsrfProtectionEnabled != nil {
		object["web_ui_csrf_protection_enabled"], err = json.Marshal(a.WebUiCsrfProtectionEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_csrf_protection_enabled': %w", err)
		}
	}

	if a.WebUiCustomHttpHeaders != nil {
		object["web_ui_custom_http_headers"], err = json.Marshal(a.WebUiCustomHttpHeaders)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_custom_http_headers': %w", err)
		}
	}

	if a.WebUiDomainList != nil {
		object["web_ui_domain_list"], err = json.Marshal(a.WebUiDomainList)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_domain_list': %w", err)
		}
	}

	if a.WebUiHostHeaderValidationEnabled != nil {
		object["web_ui_host_header_validation_enabled"], err = json.Marshal(a.WebUiHostHeaderValidationEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_host_header_validation_enabled': %w", err)
		}
	}

	if a.WebUiHttpsCertPath != nil {
		object["web_ui_https_cert_path"], err = json.Marshal(a.WebUiHttpsCertPath)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_https_cert_path': %w", err)
		}
	}

	if a.WebUiHttpsKeyPath != nil {
		object["web_ui_https_key_path"], err = json.Marshal(a.WebUiHttpsKeyPath)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_https_key_path': %w", err)
		}
	}

	if a.WebUiMaxAuthFailCount != nil {
		object["web_ui_max_auth_fail_count"], err = json.Marshal(a.WebUiMaxAuthFailCount)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_max_auth_fail_count': %w", err)
		}
	}

	if a.WebUiPassword != nil {
		object["web_ui_password"], err = json.Marshal(a.WebUiPassword)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_password': %w", err)
		}
	}

	if a.WebUiPort != nil {
		object["web_ui_port"], err = json.Marshal(a.WebUiPort)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_port': %w", err)
		}
	}

	if a.WebUiSecureCookieEnabled != nil {
		object["web_ui_secure_cookie_enabled"], err = json.Marshal(a.WebUiSecureCookieEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_secure_cookie_enabled': %w", err)
		}
	}

	if a.WebUiSessionTimeout != nil {
		object["web_ui_session_timeout"], err = json.Marshal(a.WebUiSessionTimeout)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_session_timeout': %w", err)
		}
	}

	if a.WebUiUpnp != nil {
		object["web_ui_upnp"], err = json.Marshal(a.WebUiUpnp)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_upnp': %w", err)
		}
	}

	if a.WebUiUseCustomHttpHeadersEnabled != nil {
		object["web_ui_use_custom_http_headers_enabled"], err = json.Marshal(a.WebUiUseCustomHttpHeadersEnabled)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_use_custom_http_headers_enabled': %w", err)
		}
	}

	if a.WebUiUsername != nil {
		object["web_ui_username"], err = json.Marshal(a.WebUiUsername)
		if err != nil {
			return nil, fmt.Errorf("error marshaling 'web_ui_username': %w", err)
		}
	}

	for fieldName, field := range a.AdditionalProperties {
		object[fieldName], err = json.Marshal(field)
		if err != nil {
			return nil, fmt.Errorf("error marshaling '%s': %w", fieldName, err)
		}
	}
	return json.Marshal(object)
}

// AsPreferencesScanDirs0 returns the union data inside the Preferences_ScanDirs_AdditionalProperties as a PreferencesScanDirs0
func (t Preferences_ScanDirs_AdditionalProperties) AsPreferencesScanDirs0() (PreferencesScanDirs0, error) {
	var body PreferencesScanDirs0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPreferencesScanDirs0 overwrites any union data inside the Preferences_ScanDirs_AdditionalProperties as the provided PreferencesScanDirs0
func (t *Preferences_ScanDirs_AdditionalProperties) FromPreferencesScanDirs0(v PreferencesScanDirs0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePreferencesScanDirs0 performs a merge with any union data inside the Preferences_ScanDirs_AdditionalProperties, using the provided PreferencesScanDirs0
func (t *Preferences_ScanDirs_AdditionalProperties) MergePreferencesScanDirs0(v PreferencesScanDirs0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsPreferencesScanDirs1 returns the union data inside the Preferences_ScanDirs_AdditionalProperties as a PreferencesScanDirs1
func (t Preferences_ScanDirs_AdditionalProperties) AsPreferencesScanDirs1() (PreferencesScanDirs1, error) {
	var body PreferencesScanDirs1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromPreferencesScanDirs1 overwrites any union data inside the Preferences_ScanDirs_AdditionalProperties as the provided PreferencesScanDirs1
func (t *Preferences_ScanDirs_AdditionalProperties) FromPreferencesScanDirs1(v PreferencesScanDirs1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergePreferencesScanDirs1 performs a merge with any union data inside the Preferences_ScanDirs_AdditionalProperties, using the provided PreferencesScanDirs1
func (t *Preferences_ScanDirs_AdditionalProperties) MergePreferencesScanDirs1(v PreferencesScanDirs1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t Preferences_ScanDirs_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *Preferences_ScanDirs_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}

// AsSetPreferencesScanDirs0 returns the union data inside the SetPreferences_ScanDirs_AdditionalProperties as a SetPreferencesScanDirs0
func (t SetPreferences_ScanDirs_AdditionalProperties) AsSetPreferencesScanDirs0() (SetPreferencesScanDirs0, error) {
	var body SetPreferencesScanDirs0
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromSetPreferencesScanDirs0 overwrites any union data inside the SetPreferences_ScanDirs_AdditionalProperties as the provided SetPreferencesScanDirs0
func (t *SetPreferences_ScanDirs_AdditionalProperties) FromSetPreferencesScanDirs0(v SetPreferencesScanDirs0) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeSetPreferencesScanDirs0 performs a merge with any union data inside the SetPreferences_ScanDirs_AdditionalProperties, using the provided SetPreferencesScanDirs0
func (t *SetPreferences_ScanDirs_AdditionalProperties) MergeSetPreferencesScanDirs0(v SetPreferencesScanDirs0) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

// AsSetPreferencesScanDirs1 returns the union data inside the SetPreferences_ScanDirs_AdditionalProperties as a SetPreferencesScanDirs1
func (t SetPreferences_ScanDirs_AdditionalProperties) AsSetPreferencesScanDirs1() (SetPreferencesScanDirs1, error) {
	var body SetPreferencesScanDirs1
	err := json.Unmarshal(t.union, &body)
	return body, err
}

// FromSetPreferencesScanDirs1 overwrites any union data inside the SetPreferences_ScanDirs_AdditionalProperties as the provided SetPreferencesScanDirs1
func (t *SetPreferences_ScanDirs_AdditionalProperties) FromSetPreferencesScanDirs1(v SetPreferencesScanDirs1) error {
	b, err := json.Marshal(v)
	t.union = b
	return err
}

// MergeSetPreferencesScanDirs1 performs a merge with any union data inside the SetPreferences_ScanDirs_AdditionalProperties, using the provided SetPreferencesScanDirs1
func (t *SetPreferences_ScanDirs_AdditionalProperties) MergeSetPreferencesScanDirs1(v SetPreferencesScanDirs1) error {
	b, err := json.Marshal(v)
	if err != nil {
		return err
	}

	merged, err := runtime.JSONMerge(t.union, b)
	t.union = merged
	return err
}

func (t SetPreferences_ScanDirs_AdditionalProperties) MarshalJSON() ([]byte, error) {
	b, err := t.union.MarshalJSON()
	return b, err
}

func (t *SetPreferences_ScanDirs_AdditionalProperties) UnmarshalJSON(b []byte) error {
	err := t.union.UnmarshalJSON(b)
	return err
}
